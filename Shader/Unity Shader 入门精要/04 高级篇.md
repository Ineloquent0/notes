高级篇涵盖了一些 Shader 的高级用法，例如，如何实现屏幕特效、利用法线和深度缓冲，以及非真实感渲染等，同时，我们还会介绍一些针对移动平台的优化技巧。


# 第12章 屏幕后处理效果

**屏幕后处理效果（screen post-processing effects）** 是游戏中实现屏幕特效的常见方法。

可参考文档：
* [Unity Image Effects](https://docs.unity3d.com/510/Documentation/Manual/comp-ImageEffects.html)
* [GPU Gems 3](https://developer.nvidia.com/gpugems/gpugems3/contributors)



## 12.1 建立一个基本的屏幕后处理脚本系统

屏幕后处理通常指在渲染完整个场景得到屏幕图像后，再对这个图像进行一系列操作，实现各种屏幕特效。如景深（Depth of Field）、运动模糊（Motion Blur）等。

**OnRenderImage** 函数是 Unity 内置的渲染管线中的一个函数，用于得到渲染后的屏幕图像，即抓取屏幕。它的函数声明如下：
```
// Unity 会把当前渲染得到的图像存储在第一个参数对应的源渲染纹理中，
// 通过函数中的一系列操作后，再把目标渲染纹理显示到屏幕上
MonoBehaviour.OnRenderImage(RenderTexture src, RenderTexture dest)
```

**Graphics.Blit** 函数可以实现图像的拷贝，并对图像进行一些操作。它有3种函数声明：
```
// src: 源纹理
// dest: 目标渲染纹理，如果为 null，则渲染到屏幕上
public static void Blit(Texture src, RenderTexture dest)

// mat: 材质，用于对图像进行操作
// pass: 默认为 -1，将会调用 Shader 内的所有 Pass。否则，只会调用给定索引的 Pass
public static void Blit(Texture src, RnederTexture dest, Material mat, int pass = -1)

public static void Blit(Texture src, Material mat, int pass = -1)
```

默认情况下，OnRenderImage 函数会在所有不透明和透明的 Pass 执行完毕后被调用，以便对场景中所有游戏对象都产生影响。但有时，会希望在不透明的 Pass 执行完毕后立即调用 OnRenderImage 函数，从而不对透明物体产生任何影响。可在 OnRenderImage 函数前添加 **ImageEffectOpaque** 属性实现这样的目的。


实现屏幕后处理效果过程：
1. 在摄像机中添加一个用于屏幕后处理的脚本。在脚本中，我们会实现 OnRenderImage 函数来获取当前屏幕的渲染纹理。
2. 调用 Graphics.Blit 函数使用特定的 Shader 对当前图像进行处理，再把返回的渲染纹理显示到屏幕上。
3. 对于复杂的屏幕特效，可能需要多次调用 Graphics.Blit 函数来对上一步输出结果进行下一步处理。


在进行屏幕后处理之前，我们需要检查一系列条件是否满足（如平台是否支持渲染纹理和屏幕特效，是否支持当前Shader等）。为此我们创建了一个用于屏幕后处理效果的基类 PostEffectsBase.cs。

```
using System.Collections;
using System.Collections.Generic;
using UnityEngine;

// 编辑器状态下运行
[ExecuteInEditMode]
// 需要在相机上添加组件
[RequireComponent(typeof(Camera))]
public class PostEffectsBase : MonoBehaviour
{
    private void Start()
    {
        CheckResources();
    }


    /// <summary>
    /// 检查各种资源和条件是否满足
    /// </summary>
    protected void CheckResources()
    {
        bool isSupported = CheckSupport();

        if (!isSupported)
        {
            NotSupported();
        }
    }

    /// <summary>
    /// 检查平台是否支持
    /// </summary>
    protected bool CheckSupport()
    {
        if(!SystemInfo.supportsImageEffects || !SystemInfo.supportsRenderTextures)
        {
			Debug.LogWarning("This platform does not support image effects or render textures.");
			return false;
		}
		
		return true;
    }

    /// <summary>
    /// 平台不支持时的处理
    /// </summary>
    protected void NotSupported()
    {
        enabled = false;
    }

    /// <summary>
    /// 每个屏幕后处理效果通常需要指定一个Shader来创建一个用于处理渲染纹理的材质
    /// </summary>
    /// <param name="shader">该特效需要使用的Shader</param>
    /// <param name="material">后处理的材质</param>
    /// <returns>Shader可用的话则返回该Shader对应的材质，否则返回null</returns>
    protected Material CheckShaderAndCreateMaterial(Shader shader, Material material)
    {
        if (shader == null)
            return null;

        if (shader.isSupported && material && material.shader == shader)
            return material;
        
        if (!shader.isSupported)
            return null;
        else{
            material = new Material(shader);
            material.hideFlags = HideFlags.DontSave;
            if(material)
                return material;
        }
        return null;
    }
}
```



## 12.2 调整屏幕的亮度、饱和度和对比度

新建 C# 脚本 BrightnessSaturationAndContrast.cs，并继承 12.1 节中的基类：

``` csharp
using UnityEngine;

public class BrightnessSaturationAndContrast : PostEffectsBase
{
    public Shader briSatConShader;
    private Material briSatConMaterial;
    public Material material
    {
        get
        {
            briSatConMaterial = CheckShaderAndCreateMaterial(briSatConShader, briSatConMaterial);
            return briSatConMaterial;
        }
    }

    // 提供调整亮度、饱和度、对比度的参数
    [Range(0.0f, 3.0f)]
    public float brightness = 1.0f;

    [Range(0.0f, 3.0f)]
    public float saturation = 1.0f;

    [Range(0.0f, 3.0f)]
    public float contrast = 1.0f;


    private void OnRenderImage(RenderTexture src, RenderTexture dest)
    {
        // 检查材质是否可用，如果可用，就把参数传递给材质，再调用 Graphics.Blit 进行处理
        // 否则直接把原图显示到屏幕上
        if (material != null)
        {
            material.SetFloat("_Brightness", brightness);
            material.SetFloat("_Saturation", saturation);
            material.SetFloat("_Contrast", contrast);
            Graphics.Blit(src, dest, material);
        }
        else
        {
            Graphics.Blit(src, dest);
        }
    }
}

```

新建 Shader 命名为 Chapter12-BrightnessSaturationAndContrast ：

```
Shader "Unity Shaders Book/Chapter 12/Brightness Saturation And Contrast"
{
    Properties
    {
        _MainTex ("Texture", 2D) = "white" {}
        _Brightness ("Brightness", Float) = 1
        _Saturation ("Saturation", Float) = 1
        _Contrast ("Contrast", Float) = 1
    }
    SubShader
    {
        // 定义用于屏幕后处理的 Pass
        Pass
        {
            // 屏幕后处理 Shader 的“标配”
            ZTest Always  Cull Off  ZWrite Off


            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            
            #include "UnityCG.cginc"


            struct v2f
            {
                float2 uv : TEXCOORD0;
                float4 vertex : SV_POSITION;
            };

            sampler2D _MainTex;
            half _Brightness;
            half _Saturation;
            half _Contrast;

            v2f vert (appdata_img v)
            {
                v2f o;
                o.vertex = UnityObjectToClipPos(v.vertex);
                o.uv = v.texcoord;
                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                fixed4 renderTex = tex2D(_MainTex, i.uv);

                // 亮度
                fixed3 finalColor = renderTex.rgb * _Brightness;

                // 计算饱和度
                // 饱和度为0时，颜色为黑白
                fixed luminance = dot(finalColor, fixed3(0.2125, 0.7154, 0.0721));
                fixed3 luminanceColor = fixed3(luminance, luminance, luminance);
                finalColor = lerp(luminanceColor, finalColor, _Saturation);

                // 计算对比度
                // 对比度为0时，颜色为灰色
                fixed3 avgColor = fixed3(0.5, 0.5, 0.5);
                finalColor = lerp(avgColor, finalColor, _Contrast);

                return fixed4(finalColor, renderTex.a);
            }
            ENDCG
        }
    }
    // 关闭 Fallback
    FallBack Off
}
```



## 12.3 边缘检测

边缘检测原理是利用一些边缘检测算子对图像进行 **卷积（convolution）** 操作。

### 12.3.1 什么是卷积

在图像处理中，卷积操作指的就是使用一个 **卷积核（kernel）** 对一张图像中的每个像素进行系列操作。卷积核通常是一个四方形网格结构（例如2x2、3x3的方形区域），该区域内每个方格都有一个权重值。
当对图像中的某个像素进行卷积时，我们会把卷积核的中心放置于该像素上，如图12.4所示，翻转核之后再依次计算核中每个元素和其覆盖的图像像素值的乘积并求和，得到的结果就是该位置的新像素值。

![图12.4 卷积核与卷积](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/12.4.jpg)

卷积操作可以实现很多常见的图像处理效果，例如图像模糊、边缘检测等。例如：均值模糊可以使用3x3的卷积核，核内每个元素的值均为1/9。


### 12.3.2 常见的边缘检测算子

如果相邻像素之间存在差别明显的颜色、亮度、纹理等属性，可以认为他们之间有一条边界，这种相邻像素之间的差异用 **梯度（gradient）** 来表示。边缘处的梯度绝对值会比较大，基于这样的理解，有几种不同的边缘检测算子被先后提出来。

![图12.5 3种常见的边缘检测算子](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/12.5.jpg)

它们都包含了两个方向的卷积核，分别用于检测水平方向和竖直方向上的边缘信息。在进行边缘检测时，我们需要对每个像素分别进行一次卷积计算，得到两个方向上的梯度值 Gx 和 Gy，而整体的梯度可按下面的公式计算而得：

$$
G = \sqrt{G_x^2 + G_y^2}
$$

由于上述计算包含了开根号操作，出于性能考虑，我们有时会使用绝对值操作来代替开根号操作：

$$
G = |G_x| + |G_y|
$$

当得到梯度 G 后，我们就可以根据此来判断哪些像素对应了边缘（梯度值越大，越有可能是边缘点）。


### 12.3.3 实现

新建脚本 EdgeDetection.cs，并继承 12.1 节中的基类：

``` csharp
using UnityEngine;

public class EdgeDetection : PostEffectsBase
{
    public Shader edgeDetectShader;

    private Material edgeDetectMaterial;
    public Material material{
        get{
            edgeDetectMaterial = CheckShaderAndCreateMaterial(edgeDetectShader, edgeDetectMaterial);
            return edgeDetectMaterial;
        }
    }

    // 提供用于调整边缘线强度、描边颜色以及背景颜色的参数
    // 当 edgesOnly 为 1.0 时，仅显示边缘线，不显示原渲染图像，否则边缘线会叠加到原渲染图像上
    [Range(0.0f, 1.0f)]
    public float edgeOnly = 0.0f;
    public Color edgeColor = Color.black;
    public Color backgroundColor = Color.white;

    private void OnRenderImage(RenderTexture src, RenderTexture dest)
    {
        if (material!= null){
            material.SetFloat("_EdgeOnly", edgeOnly);
            material.SetColor("_EdgeColor", edgeColor);
            material.SetColor("_BackgroundColor", backgroundColor);
            Graphics.Blit(src, dest, material);
        }
        else{
            Graphics.Blit(src, dest);
        }
    }
}
```

新建 Shader 命名为 Chapter12-EdgeDetection：

```
Shader "Unity Shaders Book/Chapter 12/Edge Detection"
{
    Properties
    {
        _MainTex ("Texture", 2D) = "white" {}
        _EdgeOnly ("Edge Only", Range(0, 1)) = 0
        _EdgeColor ("Edge Color", Color) = (0, 0, 0, 1)
        _BackgroundColor ("Background Color", Color) = (1, 1, 1, 1)
    }
    SubShader
    {
        // 定义用于屏幕后处理的 Pass
        Pass
        {
            // 屏幕后处理 Shader 的“标配”
            ZTest Always  Cull Off  ZWrite Off

            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            
            #include "UnityCG.cginc"

            sampler2D _MainTex;
            // 主纹理的纹素大小（例如：一张512 * 512的纹理，纹素大小为1/512）
            // 利用纹素，做相邻区域内纹理采样时，计算各相邻区域的纹理坐标
            half4 _MainTex_TexelSize;
            fixed _EdgeOnly;
            fixed4 _EdgeColor;
            fixed4 _BackgroundColor;

            struct v2f
            {
                float4 vertex : SV_POSITION;
                // 定义一个维数为9的数组，对应了Sobel算子采样时需要的9个邻域纹理坐标
                half2 uv[9] : TEXCOORD0;
            };

            v2f vert (appdata_img v)
            {
                v2f o;
                o.vertex = UnityObjectToClipPos(v.vertex);

                // 把计算采样纹理坐标的代码从片元着色器转移到顶点着色器中，可以减少运算，提高性能
                half2 uv = v.texcoord;
                o.uv[0] = uv + half2(-1, -1) * _MainTex_TexelSize.xy;
                o.uv[1] = uv + half2(0, -1) * _MainTex_TexelSize.xy;
                o.uv[2] = uv + half2(1, -1) * _MainTex_TexelSize.xy;
                o.uv[3] = uv + half2(-1, 0) * _MainTex_TexelSize.xy;
                o.uv[4] = uv + half2(0, 0) * _MainTex_TexelSize.xy;
                o.uv[5] = uv + half2(1, 0) * _MainTex_TexelSize.xy;
                o.uv[6] = uv + half2(-1, 1) * _MainTex_TexelSize.xy;
                o.uv[7] = uv + half2(0, 1) * _MainTex_TexelSize.xy;
                o.uv[8] = uv + half2(1, 1) * _MainTex_TexelSize.xy;

                return o;
            }

            // 计算明度
            fixed luminance(fixed3 color){
                return 0.2125 * color.r + 0.7154 * color.g + 0.0721 * color.b;
            }

            half Sobel(v2f i){
                // Sobel算子
                const half Gx[9] = { -1, -2, -1, 
                                     0, 0, 0, 
                                     1, 2, 1 };
                const half Gy[9] = { -1, 0, 1, 
                                     -2, 0, 2,
                                     -1, 0, 1 };
                
                half texColor;
                half edgeX = 0;
                half edgeY = 0;

                // 依次对9个像素进行采样
                for(int it = 0; it < 9; it++){
                    // 计算亮度值，再与卷积核Gx和Gy中对应的权重相乘后，叠加到各自的梯度值上
                    texColor = luminance(tex2D(_MainTex, i.uv[it]).rgb);
                    edgeX += Gx[it] * texColor;
                    edgeY += Gy[it] * texColor;
                }

                // 用1减去两个方向的梯度值的绝对值，得到edge，值越小，表明越可能是边缘点
                half edge = 1 - abs(edgeX) - abs(edgeY);
                return edge;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                // 使用 Sobel 函数计算当前像素的梯度值
                half edge = Sobel(i);

                // 根据梯度值分别计算背景为原图和纯色下的颜色值
                fixed4 withEdgeColor = lerp(_EdgeColor, tex2D(_MainTex, i.uv[4]), edge);
                fixed4 onlyEdgeColor = lerp(_EdgeColor, _BackgroundColor, edge);

                return lerp(withEdgeColor, onlyEdgeColor, _EdgeOnly);
            }
            ENDCG
        }
    }
    // 关闭 Fallback
    FallBack Off
}
```

效果：
<center>
<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/12.3.jpg" alt="图12.3 左图：12.2节得到的结果。右图：进行边缘检测得到的结果"  width=360/>
<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/12.6.jpg" alt="图12.6 只显示边缘的屏幕效果"  width=240 />
</center>


## 12.4 高斯模糊

模糊的实现有很多种方法，例如：
* 均值模糊：卷积核中的各个元素值都相等，且相加等于1，也就是其邻域内各个像素值的平均值。
* 中值模糊：邻域内对所有像素排序后的中值替换掉原颜色。

一个更高级的模糊方法是高斯模糊。效果：
![图12.7 左图：原效果，右图：高斯模糊效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/12.7.jpg)

### 12.4.1 高斯滤波

高斯模糊同样利用了卷积计算，它使用的卷积核名为高斯核。高斯核是一个正方形大小的滤波核，其中每个元素都是基于下面的高斯方程：

$$
G(x,y) = \frac{1}{2\pi\sigma^2}e^{-\frac{(x^2+y^2)}{2\sigma^2}}
$$

* $\sigma$ ：标准方差（一般为1），它控制着高斯核的模糊程度。
* $x$ 和 $y$ ：当前位置到卷积核中心的整数距离。

要构建一个高斯核，我们只需要计算高斯核中各个位置对应的高斯值。为了保证滤波后的图像不会变暗，我们需要对高斯核中的权重进行归一化，即让每个权重除以所有权重的和，这样可以保证所有权重的和为1。因此，高斯函数中 $e$ 前面的系数实际不会对结果有任何影响。

高斯方程很好地模拟了邻域每个像素对当前处理像素的影响程度——距离越近，影响越大。高斯核的维数越高，模糊程度越大。

使用一个 N x N 的高斯核对图像进行卷积滤波，需要进行 N x N x W x H（W、H分别是图像的宽和高）次纹理采样，N 不断增大，采样次数会变得很大。
我们可以把这个二维高斯函数可以拆分成两个一维函数。使用两个一维的高斯核先后对图像进行滤波，得到的结果和直接使用二位高斯核是一样的，但采样次数只需要 2 x N x W x H。

![图12.8 一个5×5大小的高斯核。左图显示了标准方差为1的高斯核的权重分布。我们可以把这个二维高斯核拆分成两个一维的高斯核（右图）](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/12.8.jpg)


在本节,我们将会使用上述 5x5 的高斯核对原图像进行高斯模糊。我们将先后调用两个 Pass：
* 第一个 Pass 将会使用竖直方向的一维高斯核对图像进行滤波；
* 第二个 Pass 再使用水平方向的一维高斯核对图像进行滤波，得到最终的目标图像。

在实现中，我们还将利用图像缩放来进一步提高性能，并通过调整高斯滤波的应用次数来控制模糊程度（次数越多，图像越模糊）。



### 12.4.2 实现

新建脚本 GaussianBlur.cs，并继承 12.1 节中的基类：

``` csharp
using UnityEngine;

public class GaussianBlur : PostEffectsBase
{
    public Shader gaussianBlurShader;

    private Material gaussianBlurMaterial;
    public Material material{
        get{
            gaussianBlurMaterial = CheckShaderAndCreateMaterial(gaussianBlurShader, gaussianBlurMaterial);
            return gaussianBlurMaterial;
        }
    }

    // 提供调整高斯模糊迭代次数、模糊范围、和缩放系数的参数
    [Range(0, 4)]
    public int iterations = 3;

    [Range(0.2f, 3.0f)]
    public float blurSpread = 0.6f;

    // 降采样，值越大，性能越好，但过大可能会造成像素化
    [Range(1, 8)]
    public int downsample = 2;

    // // 版本1
    // public void OnRenderImage(RenderTexture src, RenderTexture dest)
    // {
    //     if (material != null)
    //     {
    //         int rtW = src.width;
    //         int rtH = src.height;

    //         // 分配一块缓冲区，因为高斯模糊需要调用两个 Pass，
    //         // 我们需要使用一块中间缓存存储第一个Pass执行完毕后得到的模糊结果
    //         RenderTexture buffer = RenderTexture.GetTemporary(rtW, rtH, 0);

    //         // 使用Shader中的第一个Pass对src进行处理，并将结果存储在buffer中
    //         Graphics.Blit(src, buffer, material, 0);
    //         // 使用Shader中的第二个Pass对buffer进行处理，返回最终的屏幕图像
    //         Graphics.Blit(buffer, dest, material, 1);

    //         // 释放中间缓存
    //         RenderTexture.ReleaseTemporary(buffer);
    //     }
    //     else
    //     {
    //         Graphics.Blit(src, dest);
    //     }
    // }

    // // 版本2 利用缩放对图像进行降采样，从而减少需要处理的像素数量，提高性能
    // public void OnRenderImage(RenderTexture src, RenderTexture dest)
    // {
    //     if (material != null)
    //     {
    //         // 利用缩放对图像进行降采样，从而减少需要处理的像素数量，提高性能
    //         int rtW = src.width / downsample;
    //         int rtH = src.height / downsample;

    //         // 分配一块缓冲区，因为高斯模糊需要调用两个 Pass，
    //         // 我们需要使用一块中间缓存存储第一个Pass执行完毕后得到的模糊结果
    //         RenderTexture buffer = RenderTexture.GetTemporary(rtW, rtH, 0);
    //         // 双线性过滤，防止降采样后的纹理像素看上去不连贯，丢失严重
    //         buffer.filterMode = FilterMode.Bilinear;

    //         // 使用Shader中的第一个Pass对src进行处理，并将结果存储在buffer中
    //         Graphics.Blit(src, buffer, material, 0);
    //         // 使用Shader中的第二个Pass对buffer进行处理，返回最终的屏幕图像
    //         Graphics.Blit(buffer, dest, material, 1);

    //         // 释放中间缓存
    //         RenderTexture.ReleaseTemporary(buffer);
    //     }
    //     else
    //     {
    //         Graphics.Blit(src, dest);
    //     }
    // }

    // 版本3 考虑了高斯模糊的迭代次数
    public void OnRenderImage(RenderTexture src, RenderTexture dest)
    {
        if (material != null)
        {
            // 利用缩放对图像进行降采样，从而减少需要处理的像素数量，提高性能
            int rtW = src.width / downsample;
            int rtH = src.height / downsample;

            // 分配一块缓冲区，因为高斯模糊需要调用两个 Pass，
            // 我们需要使用一块中间缓存存储第一个Pass执行完毕后得到的模糊结果
            RenderTexture buffer = RenderTexture.GetTemporary(rtW, rtH, 0);
            // 双线性过滤，防止降采样后的纹理像素看上去不连贯，丢失严重
            buffer.filterMode = FilterMode.Bilinear;

            Graphics.Blit(src, buffer);

            for (int i = 0; i < iterations; i++)
            {
                material.SetFloat("_BlurSize", 1.0f + i * blurSpread);

                RenderTexture buffer1 = RenderTexture.GetTemporary(rtW, rtH, 0);

                // 第一个Pass，纵向模糊
                Graphics.Blit(buffer, buffer1, material, 0);

                // 释放buffer，将结果值buffer1存储到buffer中，重新分配buffer1
                RenderTexture.ReleaseTemporary(buffer);
                buffer = buffer1;
                buffer1 = RenderTexture.GetTemporary(rtW, rtH, 0);

                // 第二个Pass，横向模糊
                Graphics.Blit(buffer, buffer1, material, 1);

                RenderTexture.ReleaseTemporary(buffer);
                buffer = buffer1;
            }

            // 最后一步，将模糊后的图像输出到屏幕上
            Graphics.Blit(buffer, dest);
            // 释放中间缓存
            RenderTexture.ReleaseTemporary(buffer);
        }
        else
        {
            Graphics.Blit(src, dest);
        }
    }
}

```

新建 Shader 命名为 Chapter12-GaussianBlur：

```
Shader "Unity Shaders Book/Chapter 12/Gaussian Blur"
{
    Properties
    {
        _MainTex ("Texture", 2D) = "white" {}
        _BlurSize ("Blur Size", Float) = 1
    }
    SubShader
    {
        // 定义可复用的代码块，可在不同Pass中调用
        CGINCLUDE

        #include "UnityCG.cginc"

        sampler2D _MainTex;
        // 主纹理的纹素大小（例如：一张512 * 512的纹理，纹素大小为1/512）
        // 利用纹素，做相邻区域内纹理采样时，计算各相邻区域的纹理坐标
        half4 _MainTex_TexelSize;
        float _BlurSize;

        struct v2f
        {
            float4 vertex : SV_POSITION;
            half2 uv[5] : TEXCOORD0;
        };

        v2f vertBlurVertical (appdata_img v)
        {
            v2f o;
            o.vertex = UnityObjectToClipPos(v.vertex);

            // 把计算采样纹理坐标的代码从片元着色器转移到顶点着色器中，可以减少运算，提高性能
            // 构建一个纵向高斯核
            half2 uv = v.texcoord;
            o.uv[0] = uv;
            // _BlurSize控制邻域像素之间的采样距离，_BlurSize值越大，模糊程度越高，但采样数不会受到影响
            // 但过大的_BlurSize值会造成虚影
            o.uv[1] = uv + float2(0.0, _MainTex_TexelSize.y * 1.0) * _BlurSize;
            o.uv[2] = uv - float2(0.0, _MainTex_TexelSize.y * 1.0) * _BlurSize;
            o.uv[3] = uv + float2(0.0, _MainTex_TexelSize.y * 2.0) * _BlurSize;
            o.uv[4] = uv - float2(0.0, _MainTex_TexelSize.y * 2.0) * _BlurSize;

            return o;
        }

        v2f vertBlurHorizontal (appdata_img v)
        {
            v2f o;
            o.vertex = UnityObjectToClipPos(v.vertex);

            // 把计算采样纹理坐标的代码从片元着色器转移到顶点着色器中，可以减少运算，提高性能
            // 构建一个横向高斯核
            half2 uv = v.texcoord;
            o.uv[0] = uv;
            // _BlurSize控制邻域像素之间的采样距离，_BlurSize值越大，模糊程度越高，但采样数不会受到影响
            // 但过大的_BlurSize值会造成虚影
            o.uv[1] = uv + float2(_MainTex_TexelSize.x * 1.0, 0.0) * _BlurSize;
            o.uv[2] = uv - float2(_MainTex_TexelSize.x * 1.0, 0.0) * _BlurSize;
            o.uv[3] = uv + float2(_MainTex_TexelSize.x * 2.0, 0.0) * _BlurSize;
            o.uv[4] = uv - float2(_MainTex_TexelSize.x * 2.0, 0.0) * _BlurSize;

            return o;
        }

        fixed4 fragBlur (v2f i) : SV_Target
        {
            // 由于对称性，只需记录3个高斯权重
            float weight[3] = {0.4026, 0.2442, 0.0545};

            fixed3 sum = tex2D(_MainTex, i.uv[0]).rgb * weight[0];

            for (int it = 1; it < 3; it++){
                sum += tex2D(_MainTex, i.uv[it*2-1]).rgb * weight[it];
                sum += tex2D(_MainTex, i.uv[it*2]).rgb * weight[it];
            }

            return fixed4(sum, 1.0);
        }

        ENDCG

        // 屏幕后处理 Shader 的“标配”
        ZTest Always  Cull Off  ZWrite Off

        Pass
        {
            NAME "GAUSSIAN_BLUR_VERTICAL"

            CGPROGRAM
            #pragma vertex vertBlurVertical
            #pragma fragment fragBlur
            
            ENDCG
        }
        Pass
        {
            NAME "GAUSSIAN_BLUR_HORIZONTAL"

            CGPROGRAM
            #pragma vertex vertBlurHorizontal
            #pragma fragment fragBlur
            
            ENDCG
        }
    }
    // 关闭 Fallback
    FallBack Off
}
```


## 12.5 Bloom 效果

Bloom 效果是让画面中较亮的区域“扩散”到周围的区域中，造成一种朦胧的效果。

![图12.10 左边为原图，右边为 Bloom 效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/12.10.jpg)

Bloom 的实现非常简单：
1. 首先根据一个阈值提取出图像中的较亮区域，把它们存储在一张渲染纹理中；
2. 利用高斯模糊对这张渲染纹理进行模糊处理，模拟光线扩散的效果；
3. 最后将其和原图像进行混合，得到最终的效果。

新建脚本 Bloom.cs：

``` csharp
using UnityEngine;

public class Bloom : PostEffectsBase
{
    public Shader bloomShader;
    private Material bloomMaterial;
    public Material material
    {
        get
        {
            bloomMaterial = CheckShaderAndCreateMaterial(bloomShader, bloomMaterial);
            return bloomMaterial;
        }
    }

    // 由于 Bloom 效果是建立在高斯模糊的基础上，因此参数几乎与高斯模糊相同。

    // 提供调整高斯模糊迭代次数、模糊范围、和缩放系数的参数
    [Range(0, 4)]
    public int iterations = 3;

    [Range(0.2f, 3.0f)]
    public float blurSpread = 0.6f;

    [Range(1, 8)]
    public int downsample = 2;

    // 控制提取较亮区域时使用的阈值
    [Range(0.0f, 4.0f)]
    public float luminanceThreshold = 0.6f;


    public void OnRenderImage(RenderTexture src, RenderTexture dest)
    {
        if (material != null)
        {
            material.SetFloat("_LuminanceThreshold", luminanceThreshold);
            // 利用缩放对图像进行降采样，从而减少需要处理的像素数量，提高性能
            int rtW = src.width / downsample;
            int rtH = src.height / downsample;

            // 分配一块缓冲区，因为高斯模糊需要调用两个 Pass，
            // 我们需要使用一块中间缓存存储第一个Pass执行完毕后得到的模糊结果
            RenderTexture buffer = RenderTexture.GetTemporary(rtW, rtH, 0);
            // 双线性过滤，防止降采样后的纹理像素看上去不连贯，丢失严重
            buffer.filterMode = FilterMode.Bilinear;

            // 第一个Pass，提取图像中较亮区域
            Graphics.Blit(src, buffer, material, 0);

            for (int i = 0; i < iterations; i++)
            {
                material.SetFloat("_BlurSize", 1.0f + i * blurSpread);

                RenderTexture buffer1 = RenderTexture.GetTemporary(rtW, rtH, 0);

                Graphics.Blit(buffer, buffer1, material, 1);

                RenderTexture.ReleaseTemporary(buffer);
                buffer = buffer1;
                buffer1 = RenderTexture.GetTemporary(rtW, rtH, 0);

                Graphics.Blit(buffer, buffer1, material, 2);

                RenderTexture.ReleaseTemporary(buffer);
                buffer = buffer1;
            }

            // 将 buffer 传递给材质
            material.SetTexture("_Bloom", buffer);
            // 使用 Shader 中的第四个 Pass 来进行最后的混合，将结果存储在目标渲染纹理中
            Graphics.Blit(src, dest, material, 3);

            // 释放临时缓存
            RenderTexture.ReleaseTemporary(buffer);
        }
        else
        {
            Graphics.Blit(src, dest);
        }
    }
}

```

新建 Shader 命名为 Chapter12-Bloom：

```
Shader "Unity Shaders Book/Chapter 12/Bloom"
{
    Properties
    {
        _MainTex ("Texture", 2D) = "white" {}
        _Bloom ("Bloom (RGB)", 2D) = "black" {}
        _LuminanceThreshold ("Luminance Threshold", Float) = 0.5
        _BlurSize ("Blur Size", Float) = 1
    }
    SubShader
    {
        // 定义可复用的代码块，可在不同Pass中调用
        CGINCLUDE

        #include "UnityCG.cginc"

        sampler2D _MainTex;
        // 主纹理的纹素大小（例如：一张512 * 512的纹理，纹素大小为1/512）
        // 利用纹素，做相邻区域内纹理采样时，计算各相邻区域的纹理坐标
        half4 _MainTex_TexelSize;
        sampler2D _Bloom;
        float _LuminanceThreshold;
        float _BlurSize;

        struct v2f
        {
            float4 vertex : SV_POSITION;
            half2 uv : TEXCOORD0;
        };

        // 定义提取较亮区域需要用的顶点片元着色器
        v2f vertExtractBright (appdata_img v)
        {
            v2f o;
            o.vertex = UnityObjectToClipPos(v.vertex);
            o.uv = v.texcoord;

            return o;
        }
        
        fixed luminance(fixed3 color)
        {
            return 0.2125 * color.r + 0.7154 * color.g + 0.0721 * color.b;
        }

        fixed4 fragExtractBright (v2f i) : SV_Target
        {
            fixed4 color = tex2D(_MainTex, i.uv);
            // 将采样得到的亮度值减去阈值，并把结果截取到0-1之间
            fixed val = clamp(luminance(color.rgb) - _LuminanceThreshold, 0.0, 1.0);

            // 把该值和原像素相乘，得到提取后的亮部区域
            return color * val;
        }


        // 定义混合亮部图像和原图像的顶点片元着色器
        struct v2fBloom
        {
            float4 vertex : SV_POSITION;
            half4 uv : TEXCOORD0;
        };

        v2fBloom vertBloom (appdata_img v)
        {
            v2fBloom o;
            o.vertex = UnityObjectToClipPos(v.vertex);
            o.uv.xy = v.texcoord;
            o.uv.zw = v.texcoord;

            #if UNITY_UV_STARTS_AT_TOP
            if (_MainTex_TexelSize.y < 0.0)
                o.uv.w = 1.0 - o.uv.w;
            #endif

            return o;
        }

        fixed4 fragBloom (v2fBloom i) : SV_Target
        {
            return tex2D(_MainTex, i.uv.xy) + tex2D(_Bloom, i.uv.zw);
        }


        ENDCG

        // 屏幕后处理 Shader 的“标配”
        ZTest Always  Cull Off  ZWrite Off

        Pass
        {
            CGPROGRAM
            #pragma vertex vertExtractBright
            #pragma fragment fragExtractBright
            
            ENDCG
        }

        // 通过 UsePass 语义指明上一节中高斯模糊定义的两个 Pass
        UsePass "Unity Shaders Book/Chapter 12/Gaussian Blur/GAUSSIAN_BLUR_VERTICAL"
        UsePass "Unity Shaders Book/Chapter 12/Gaussian Blur/GAUSSIAN_BLUR_HORIZONTAL"
        
        Pass
        {
            CGPROGRAM
            #pragma vertex vertBloom
            #pragma fragment fragBloom
            
            ENDCG
        }
    }
    // 关闭 Fallback
    FallBack Off
}
```


## 12.6 运动模糊

运动模糊是真实世界中相机的一种效果，如果在摄像机曝光时，拍摄场景发生了变化，就会产生模糊的画面。在计算机图像中，由于不存在曝光现象，渲染出来的图像往往都是棱角分明，缺少运动模糊。

运动模糊实现有多种方法：
* **累计缓存（Accumulation Buffer）** ：当物体快速移动产生多张图像后，取它们之间的平均值作为最后的运动模糊图像。然而，这种方法性能消耗很大，因为想要获取多张帧图像往往意味着我们需要在同一帧里渲染多次场景。

* **速度缓存（Velocity Buffer）** ：这个缓存中存储了各个像素当前的运动速度，然后利用该值来决定模糊的方向和大小。


我们将使用类似第一种方法，不需要在一帧中把场景渲染多次，但需要保存之前的渲染结果，不断把当前的渲染图像叠加到之前的渲染图像中，从而产生一种运动轨迹的视觉效果。这种方法性能比累计缓存好，但模糊效果可能会略有影响。

新建脚本 MotionBlur.cs：

``` csharp
using UnityEngine;

public class MotionBlur : PostEffectsBase
{
    public Shader motionBlurShader;
    private Material motionBlurMaterial;
    public Material material
    {
        get
        {
            motionBlurMaterial = CheckShaderAndCreateMaterial(motionBlurShader, motionBlurMaterial);
            return motionBlurMaterial;
        }
    }

    // 定义运动模糊在混合图像时使用的模糊参数
    [Range(0.0f, 0.9f)]
    public float blurAmount = 0.5f;

    // 定义一个 RenderTexture 用于存储之前图像叠加的结果
    private RenderTexture accumulationTexture;

    // 当脚本不运行时，立即销毁 accumulationTexture
    // 因为我们希望下一次开始应用运动模糊时重新叠加图像
    void OnDisable()
    {
        DestroyImmediate(accumulationTexture);
    }

    private void OnRenderImage(RenderTexture src, RenderTexture dest)
    {
        if (material != null)
        {
            // 如果 accumulationTexture 为空，或者大小与 src 不匹配，则创建一个适合当前分辨率的 accumulationTexture
            if (accumulationTexture == null || accumulationTexture.width != src.width || accumulationTexture.height != src.height)
            {
                DestroyImmediate(accumulationTexture);
                accumulationTexture = new RenderTexture(src.width, src.height, 0);
                accumulationTexture.hideFlags = HideFlags.HideAndDontSave;
                Graphics.Blit(src, accumulationTexture);
            }

            // MarkRestoreExpected 函数表明我们需要进行一个渲染纹理的恢复操作
            // 恢复操作：发生在渲染到纹理而该纹理又没有提前清空或销毁的情况
            accumulationTexture.MarkRestoreExpected();

            material.SetFloat("_BlurAmount", 1.0f - blurAmount);

            // 把当前屏幕图像叠加到 accumulationTexture 中
            Graphics.Blit(src, accumulationTexture, material);
            Graphics.Blit(accumulationTexture, dest);
        }
        else
        {
            Graphics.Blit(src, dest);
        }
    }

}
```

新建 Shader 命名为 Chapter12-MotionBlur：

```
Shader "Unity Shaders Book/Chapter 12/Motion Blur"
{
    Properties
    {
        _MainTex ("Texture", 2D) = "white" {}
        _BlurAmount ("Blur Amount", Float) = 1.0
    }
    SubShader
    {
        CGINCLUDE

        #include "UnityCG.cginc"

        sampler2D _MainTex;
        fixed _BlurAmount;

        struct v2f
        {
            float2 uv : TEXCOORD0;
            float4 vertex : SV_POSITION;
        };

        v2f vert (appdata_img v)
        {
            v2f o;
            o.vertex = UnityObjectToClipPos(v.vertex);
            o.uv = v.texcoord;
            return o;
        }

        // 对当前图像进行采样，将其A通道的值设为_BlurAmount，方便后面混合时控制透明通道
        fixed4 fragRGB (v2f i) : SV_Target
        {
            return fixed4(tex2D(_MainTex, i.uv).rgb, _BlurAmount);
        }

        // 直接返回采样结果
        half4 fragA (v2f i) : SV_Target
        {
            return tex2D(_MainTex, i.uv);
        }

        ENDCG

        // 后处理“标配”
        ZTest Always Cull Off ZWrite Off

        // 第一个Pass，更新渲染纹理的RGB通道，
        // 通过_BlurAmount设置A通道来混合图像，但不会把A通道写入渲染纹理
        Pass
        {
            Blend SrcAlpha OneMinusSrcAlpha
            ColorMask RGB

            CGPROGRAM

            #pragma vertex vert
            #pragma fragment fragRGB

            ENDCG
        }

        // 用当前图像的透明通道作为混合后的图像的透明通道
        Pass
        {
            Blend One Zero
            ColorMask A
            
            CGPROGRAM

            #pragma vertex vert
            #pragma fragment fragA

            ENDCG
        }
    }
    FallBack Off
}
```







图片地址：https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/.jpg