中级篇是本书的进阶篇，将讲解Unity中的渲染路径、如何计算光照衰减和阴影、如何使用高级纹理和动画等一系列进阶内容。

# 第9章 更复杂的光照

在前面的学习中，我们的场景中都仅有一个光源且光源类型是平行光(如果你的场景不是这样的话，可能会得到错误的结果)。但在实际的游戏开发过程中，我们往往需要处理数目更多、类型更复杂的光源。更重要的是，我们想要得到阴影。在本章我们就会学习如何在Unity 中实现上面的功能。


## 9.1 Unity 的渲染路径

官方手册：https://docs.unity.cn/cn/2023.2/Manual/RenderingPaths.html

在 Unity 里，**渲染路径（Rendering Path）** 决定了光照是如何应用到 Unity Shader 中的。因此，如果要和光源打交道，我们需要为每个 Pass 指定它使用的渲染路径，只有这样才能让 Unity 知道我们想要哪种渲染路径，然后将光源和处理后的光照信息都放在这些数据里。也就是说，我们只有为 Shader 正确地选择和设置了需要的渲染路径，该 Shader 的光照计算才能被正确执行。

Unity 支持多种类型的渲染路径：
* **前向渲染路径（Forward Rendering Path）** ：Unity 内置渲染管线中的默认渲染路径。这是通用的渲染路径。
* **延迟渲染路径（Deferred Rendering Path）** ：内置渲染管线中具有最大光照和阴影保真度的渲染路径。延迟着色需要 GPU 支持（Unity 5 版本后新的延迟渲染路径代替了原来的延迟渲染路径）
* **顶点照明渲染路径（Vertex Lit Rendering Path）** ：具有最低光照保真度且不支持实时阴影的渲染路径。这是前向渲染路径的子集。（在 Unity 5 版本后基本被弃用）

Unity 2023 中可以在 Edit - Project Settings - Graphics - Tier Settings 中设置默认 Rendering Path。使用多个渲染路径，可以修改相机组件中的 Rendering Path 设置，这样可以覆盖 Project Settings 中的设置。

如果当前的显卡并不支持所选择的渲染路径，Unity 会自动使用更低的渲染路径。

我们可以通过设置 Pass 的 LightMode 标签来指定渲染路径。

```
Pass {
    Tags { "LightMode" = "ForwardBase" }
    // ......
}
```

表9.1 LightMode 标签支持的渲染路径设置选项
 标签名  |  描述
 --- | ---
 Always      | 不管使用哪种渲染路径，该 Pass 总是会被渲染，但不会计算任何光照
 ForwardBase | 用于前向渲染。该 Pass 会计算环境光、最重要的平行光、逐顶点/SH 光源和 Lightmaps
 ForwardAdd  | 用于前向渲染。该 Pass 会计算额外的逐像素光源，每个 Pass 对应一个光源
 Deferred    | 用于延迟渲染。该 Pass 会渲染 G 缓冲(G-bufer)
 ShadowCaster| 把物体的深度信息渲染到阴影映射纹理(shadowmap)或一张深度纹理中
 PrepassBase | 用于遗留的延迟渲染。该 Pass 会渲染法线和高光反射的指数部分
 PrepassFinal| 用于遗留的延迟渲染。该 Pass 通过合并纹理、光照和自发光来渲染得到最后的颜色
 Vertex、VertexLMRGBM 和 VertexLM | 用于遗留的顶点照明渲染路径。

指定渲染路径是我们和 Unity 底层渲染引擎的一次重要的沟通。例如，我们为一个 Pass 设置来前向渲染路径的标签，相当于告诉 Unity 我们准备使用前向渲染，需要把光照属性都按前向渲染的流程准备好。随后，我们可以通过 Unity 提供的内置光照变量来访问这些属性。如果我们没有指定任何渲染路径，那么一些光照变量很可能不会被正确赋值，我们计算出的效果也就很有可能是错误的。


### 9.1.1 前向渲染路径

前向渲染路径是传统的渲染方式，也是我们最常用的一种渲染路径。

#### 1. 前向渲染路径的原理
每进行一次完整的前向渲染，我们需要渲染该对象的渲染图元，并计算两个缓冲区的信息：一个是颜色缓冲区，一个是深度缓冲区。我们利用深度缓冲来决定一个片元是否可见，如果可见就更新颜色缓冲区中的颜色值。我们可以用下面的伪代码来描述前向渲染路径的大致过程:

```
Pass {
    for (each primitive in this model) {
        for (each fragment covered by this primitive) {
            if (failed in depth test) {
                // 如果没有通过深度测试，说明该片元是不可见的
                discard; // 丢弃该片元
            }
            else {
                // 如果该片元可见
                // 就进行光照计算
                float4 color = Shading(materialInfo, pos, normal, lightDir, viewDir);
                // 更新帧缓冲区的颜色值
                writeFrameBuffer(fragment, color);
            }
        }
    }
}
```

#### 2. Unity 中的前向渲染

事实上，一个 Pass 不仅仅可以用来计算逐像素光照，它也可以用来计算逐顶点等其他光照。这取决于光照计算所处流水线阶段以及计算时使用的数学模型。当我们渲染一个物体时，Unity 会计算哪些光源照亮了它，以及这些光源照亮该物体的方式。

在 Unity 中，前向渲染路径有3种处理光照(即照亮物体)的方式：**逐顶点处理、逐像素处理、球谐函数（Spherical Harmonics，SH）处理**。

而决定一个光源使用哪种处理模式取决于它的类型和渲染模式。光源类型指的是该光源是平行光还是其他类型的光源，而光源的渲染模式指的是该光源是否是**重要的（Important）**。如果我们把一个光照的模式设置为 Important，意味着我们告诉 Unity 这个光源很重要，把它当成一个逐像素光源来处理。

在前向渲染中，当我们渲染一个物体时，Unity 会根据场景中各个光源的设置以及这些光源对物体的影响程度（例如，距离该物体的远近、光源强度等）对这些光源进行一个重要度排序。其中，一定数目的光源会按逐像素的方式处理然后最多有4个光源按逐顶点的方式处理，剩下的光源可以按 SH 方式处理。
Unity 使用的判断规则如下：
* 场景中最亮的平行光总是按逐像素处理的。
* 渲染模式被设置成 **Not Important** 的光源，会按逐顶点或者 SH 处理。
* 渲染模式被设置成 **Important** 的光源，会按逐像素处理。
* 如果根据以上规则得到的逐像素光源数量小于 **Quality Setting** 中的逐像素光源数量(Pixel Light Count)，会有更多的光源以逐像素的方式进行渲染。

前向渲染的两种 Pass ： **Base Pass** 和 **Additional Pass**

![图9.4 前向渲染的两种 Pass](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.4.jpg)

图9.4中有几点需要说明的地方：
* 在渲染设置中，我们除了设置了 Pass 的标签外，还使用了 **#pragma multi_compile_fwdbase** 这样的编译指令。这些编译指令会保证 Unity 可以为相应类型的 Pass 生成所有需要的 Shader 变种，这些变种会处理不同条件下的渲染逻辑。通俗来讲，只有分别为 BassPass 和 Additional Pass 使用这两个编译指令，我们才可以在相关的 Pass 中得到一些正确的光照变量，例如光照衰减值等。
* Base Pass 旁边的注释给出了 Base Pass 中支持的一些光照特性。例如在 Base Pass 中，我们可以访问光照纹理（lightmap）。
* Base Pass 中渲染的平行光默认是支持阴影的，而 Additional Pass 中渲染的光源在默认情况下是没有阴影效果的。但我们可以在 Additional Pass 中使用 `#pragma multi_compile_fwdadd_fullshadows` 代替 `#pragma multi_compile_fwdadd` 编译指令，为点光源和聚光灯开启阴影效果，但这需要 Unity 在内部使用更多的 Shader 变种。
* 环境光和自发光也是在 BasePass 中计算的。这是因为，对于一个物体来说，环境光和自发光我们只希望计算一次即可，而如果我们在 Additional Pass中计算这两种光照，就会造成叠加多次环境光和自发光，这不是我们想要的。
* 在 Additional Pass 的渲染设置中，我们还开启和设置了混合模式。这是因为，我们希望每个 Additiona Pass 可以与上一次的光照结果在帧缓存中进行叠加，从而得到最终的有多个光照的渲染效果。如果我们没有开启和设置混合模式，那么 Additional Pass 的渲染结果会覆盖掉之前的渲染结果，看起来就好像该物体只受该光源的影响。通常情况下，我们选择的混合模式是 Blend One One。
* 对于前向渲染来说，一个 Unity Shader 通常会定义一个 Base Pass（Base Pass也可以定义多次，例如需要双面渲染等情况）以及一个 Additional Pass。一个 Base Pass 仅会执行一次（定义了多个 Base Pass 的情况除外），而一个 Additional Pass 会根据影响该物体的其他逐像素光源的数目被多次调用，即每个逐像素光源会执行一次 Additional Pass。

图 9.4 给出的光照计算是通常情况下我们在每种 Pass 中进行的计算。实际上，渲染路径的设置用于告诉 Unity 该 Pass 在前向渲染路径中的位置，然后底层的渲染引擎会进行相关计算并填充一些内置变量(如 _LightColor0 等)。


#### 3. 内置的光照变量和函数

表9.2 前向渲染可以使用的内置光照变量
 名称 | 类型 | 描述
 --- | --- | ---
 _LightColor0 | float4 | 该 Pass 处理的逐像素光源的颜色
 _WorldSpaceLightPos0 | float4 | _WorldSpaceLightPos0.xyz 是该 Pass 处理的逐像素光源的位置。如果该光源是平行光，那么 _WorldSpaceLightPos0.w 是 0 ，其他光源类型 w 值为 1
 _LightMatrix0 | float4x4 | 从世界空间到光源空间的变换矩阵。可以用于采样 cookie 和光强衰减（attenuation）纹理
 unity_4LightPosX0, unity_4LightPosY0, unity_4LightPosZ0 | float4 | 仅用于Base Pass。前4个非重要的点光源在世界空间中的位置
 unity_4LightAtten0 | float4 | 仅用于Base Pass。存储了前4个非重要的点光源的衰减因子
 unity_LightColor | half4[4] | 仅用于Base Pass。存储了前4个非重要的点光源的颜色


表9.3 前向渲染可以使用的内置光照函数
 函数名 | 描述
 --- | ---
 float3 WorldSpaceLightDir(float4 v) | 仅可用于前向渲染中。输入一个模型空间中的顶点位置，返回世界空间中从该点到光源的光照方向，内部实现使用了 UnityWorldSpaceLightDir 函数。没有被归一化
 float3 UnityWorldSpaceLightDir(float4 v) | 仅可用于前向渲染中。输入一个世界空间中的顶点位置，返回世界空间中从该点到光源的光照方向，没有被归一化
 float3 ObjSpaceLightDir(float4 v) | 仅可用于前向渲染中。输入一个模型空间中的顶点位置，返回模型空间中从该点到光源的光照方向，没有被归一化
 float3 Shade4PointLights (...) | 仅可用于前向渲染中。计算四个点光源的光照，它的参数是已经打包进矢量的光照数据，通常就是表 9.2 中的内置变量，如 `unity_4LightPosX0，unity_4LightPosY0，unity_4LightPosZ0，unity_LightColor 和 unity_4LightAtten0` 等。前向渲染通常会使用这个函数来计算逐顶点光照



### 9.1.2 顶点照明渲染路径

顶点照明渲染路径是对硬件配置要求最少、运算性能最高，但同时也是得到的效果最差的一种类型，它不支持那些逐像素才能得到的效果，例如阴影、法线映射、高精度的高光反射等。实际上，它仅仅是前向渲染路径的一个子集，也就是说，所有可以在顶点照明渲染路径中实现的功能都可以在前向渲染路径中完成。

顶点照明渲染路径通常在一个 Pass 中就可以完成对物体的渲染。在这个 Pass 中，我们会计算我们关心的所有光源对该物体的照明，并且这个计算是按逐顶点处理的。在 Unity 5 版本后基本被弃用

在 Unity 中，我们可以在一个顶点照明的 Pass 中最多访问到8个逐顶点光源。如果我们只需要渲染其中两个光源对物体的照明，可以仅使用表 9.4 中内置光照数据的前两个。如果影响该物体的光源数目小于8，那么数组中剩下的光源颜色会设置成黑色。

表9.4 顶点照明渲染路径中可以使用的内置变量
 名称 | 类型 | 描述
 --- | --- | ---
 unity_LightColor | half4[8] | 光源颜色
 unity_LightPosition | float4[8] | xyz 分量是视角空间中的光源位置。如果光源是平行光，那么 w 分量值为 0，其他光源类型 w 分量值为 1
 unity_LightAtten | half4[8] | 光源衰减因子。如果光源是聚光灯，x 分量是 cos(spotAngle/2)，y 分量是 1/cos(spotAngle/4)；如果是其他类型的光源，x 分量是-1，y 分量是1。z 分量是衰减的平方，w 分量是光源范围开根号的结果
 unity_SpotDirection | float4[8] | 如果光源是聚光灯，则这个变量存储了聚光灯的方向。其他类型的光源，这个变量设置为(0, 0, 1, 0)


表9.5 顶点照明渲染路径中可以使用的内置函数
 函数名 | 描述
 --- | ---
 float3 ShadeVertexLights (float4 vertex, float3 normal) | 输入模型空间中的顶点位置和法线，计算四个逐顶点光源的光照以及环境光。内部实现实际上调用了 ShadeVertexlightsFull 函数
 float3 ShadeVertexLightsFull (float4 vertex, float3 normal, int lightCount, bool spotLight) | 输入模型空间中的顶点位置和法线，计算 lightCount 个光源的光照以及环境光。如果 spotLight 值为 true，那么这些光源会被当成聚光灯来处理，虽然结果更精确，但计算更加耗时；否则，按点光源处理



### 9.1.3 延迟渲染路径

#### 1. 延迟渲染的原理

延迟渲染主要包含了两个Pass。在第一个Pass中，我们不进行任何光照计算，而是仅仅计算哪些片元是可见的，这主要是通过深度缓冲技术来实现，当发现一个片元是可见的，我们就把它的相关信息存储到G缓冲区中（Geometry）。然后，在第二个Pass中，我们利用G缓冲区的各个片元信息，例如表面法线、视角方向、漫反射系数等，进行真正的光照计算。

延迟渲染的过程大致可以用下面的伪代码来描述：

```
Pass 1 {
    // 第一个 Pass 不进行真正的光照计算
    // 仅仅把光照计算需要的信息存储到 G 缓冲区中

    for (each primitive in this model) {
        for (each fragment convered by this primitive) {
            if (failed in depth test) {
                // 如果没有通过深度测试，说明该片元是不可见的
                discard;
            }
            else {
                // 如果该片元可见，就把需要的信息存储到 G 缓冲区中
                writeGBuffer(materialInfo, pos, normal);
            }
        }
    }
}

Pass 2 {
    // 利用 G 缓冲中的信息进行真正的光照计算

    for (each pixel in the screen) {
        if (the pixel is valid) {
            // 如果该像素是有效的，读取它对应的 G 缓冲区中的信息
            readGBuffer(pixel, materialInfo, pos, normal);

            // 根据读取到的信息进行光照计算
            float4 color = Shading(materialInfo, pos, normal, lightDir, viewDir);
            // 更新帧缓冲
            writeFrameBuffer(pixel, color);
        }
    }
}
```


#### 2. Unity 中的延迟渲染

Unity 有两种延迟渲染路径，一种是遗留的延迟渲染路径，即 Unity 5 之前使用的延迟渲染路径，而另一种是 Unity 5.x 中使用的延迟渲染路径。如果游戏中使用了大量的实时光照，那么我们可能希望选择延迟渲染路径，但这种路径需要一定的硬件支持。

新旧延迟渲染路径之间的差别很小，只是使用了不同的技术来权衡不同的需求。例如，较旧版本的延迟渲染路径不支持 Unity 5 的基于物理的 Standard Shader。

对于延迟渲染路径来说，它最适合在场景中光源数目很多、如果使用前向渲染会造成性能瓶颈的情况下使用。而且，延迟渲染路径中的每个光源都可以按逐像素的方式处理。但是，延迟染也有一些缺点：
* 不支持真正的抗锯齿（anti-aliasing）功能。
* 不能处理半透明物体。
* 对显卡有一定要求。如果要使用延迟渲染的话，显卡必须支持 MRT（Multiple Render Targets）、Shader Mode 3.0 及以上、深度渲染纹理以及双面的模板缓冲。

当使用延迟渲染时，Unity 要求我们提供两个 Pass：
1. 第一个 Pass 用于渲染 G 缓冲。在这个 Pass 中，我们会把物体的漫反射颜色、高光反射颜色、平滑度、法线、自发光和深度等信息渲染到屏幕空间的G缓冲区中。对于每个物体来说，这个 Pass 仅会执行一次。
2. 第二个 Pass 用于计算真正的光照模型。这个 Pass 会使用上一个 Pass 中渲染的数据来计算最终的光照颜色，再存储到帧缓冲中。

默认的G缓冲区(注意，不同 Unity 版本的渲染纹理存储内容会有所不同)包含了以下几个渲染纹理(Render Texture，RT)：
* RT0：格式是 ARGB32，RGB 通道用于存储漫反射颜色，A 通道没有被使用。
* RT1：格式是 ARGB32，RGB 通道用于存储高光反射颜色，A 通道用于存储高光反射的指数部分。
* RT2：格式是 ARGB2101010，RGB 通道用于存储法线，A 通道没有被使用。
* RT3：格式是 ARGB32(非HDR) 或 ARGBHalf(HDR)，用于存储 自发光+lightmap+反射探针(reflection probes)。
* 深度缓冲和模板缓冲。

当在第二个Pass 中计算光照时，默认情况下仅可以使用 Unity 内置的 Standard 光照模型。如果我们想要使用其他的光照模型，就需要替换掉原有的 Internal-DeferredShading.shader 文件。更详细的信息可以访问官方文档(https://docs.unity3d.com/Manual/RenderTech-DeferredShading.html)。


#### 3. 可访问的内置变量和函数

表9.6 延迟渲染路径中可以使用的内置变量
 名称 | 类型 | 描述
 --- | --- | ---
 _LightColor | float4 | 光源颜色
 _LightMatrix0 | float4x4 | 从世界空间到光源空间的变换矩阵。可以用于采样 cookie 和光强衰减（attenuation）纹理



### 9.1.4 选择哪种渲染路径

[Unity 官方文档](https://docs.unity3d.com/Manual/RenderingPaths.html) 中给出了4种渲染路径的详细比较。

总的来说，我们需要根据游戏发布的目标平台来选择渲染路径。如果当前显卡不支持所选渲染路径，那么 Unity 会自动使用比其低一级的渲染路径。

在本书中，我们主要使用 Unity 的前向渲染路径。



## 9.2 Unity 的光源类型

Unity 一共支持4种光源类型：
* **平行光（Directional Light）**：照亮范围没有限制（如太阳光），几何属性只有方向，可以放在任何位置，没有衰减。
* **点光源（Point Light）**：照亮范围有限，球形范围。有位置属性，方向属性需要用点光源位置减去某点的位置来得到它到该点的方向。有衰减，衰减值可由函数定义。
* **聚光灯（Spot Light）**：照亮范围有限，锥形范围，有位置属性和方向属性，可用于表示由一个特定位置出发、向特定方向延伸的光，方向属性需要用聚光灯位置减去某点的位置来得到它到该点的方向。有衰减，衰减值可由函数定义。
* **面光源（Area Light）**：仅在烘焙时才可发挥作用，不在本节讨论范围

最常使用的光源属性有光源的 **位置、方向、颜色、强度 和 衰减** 这5个属性。

### 在前向渲染中处理不同的光源类型

#### 1. 实践

1. 新建场景 Scene_9_2_2_1，去掉天空盒。
2. 新建 Shader，命名为 Chapter9-ForwardRendering。
3. 右键 Shader，创建材质。
4. 在场景中创建一个胶囊体，将材质赋给它。
5. 为了让物体受多个光源影响，我们再创建一个点光源，其颜色设为绿色。
6. 保存场景。

我们使用 Blinn-Phong 光照模型来计算光照。

```
// Upgrade NOTE: replaced '_LightMatrix0' with 'unity_WorldToLight'

Shader "Unity Shaders Book/Chapter 9/Forward Rendering"
{
    Properties
    {
        _Diffuse ("Diffuse", Color) = (1,1,1,1)
        _Specular ("Specular", Color) = (1,1,1,1)
        _Gloss ("Gloss", Range(8, 256)) = 40
    }
    SubShader
    {
        // 1. 首先定义第一个 Pass——Base Pass
        Pass
        {
            // 设置该 Pass 的渲染路径标签
            Tags {"LightMode"="ForwardBase"}

            CGPROGRAM

            // 使用 #pragma 编译指令保证我们使用光照变量时可以被正确赋值
            #pragma multi_compile_fwdbase

            #pragma vertex vert
            #pragma fragment frag

            #include "Lighting.cginc"

            fixed4 _Diffuse;
            fixed4 _Specular;
            float _Gloss;

            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
            };

            struct v2f
            {
                float4 pos : SV_POSITION;
                float3 worldNormal : TEXCOORD0;
                float3 worldPos : TEXCOORD1;
            };

            v2f vert (a2v v)
            {
                v2f o;
                
                o.pos = UnityObjectToClipPos(v.vertex);
                
                o.worldNormal = UnityObjectToWorldNormal(v.normal);
                o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;

                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                // 2. 计算场景中的环境光
                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

                fixed3 worldNormal = normalize(i.worldNormal);
                fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
                
                // 3. 处理场景中的最重要的平行光
                fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal, worldLightDir));
                
                fixed3 viewDir = normalize(UnityWorldSpaceViewDir(i.worldPos));
                fixed3 halfDir = normalize(worldLightDir + viewDir);
                fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);
                
                // 平行光没有衰减，因此直接令衰减值为 1.0
                fixed atten = 1.0;

                fixed3 color = ambient + (diffuse + specular) * atten;

                return fixed4(color, 1.0);
            }
            ENDCG
        }

        // 4. 定义 Additional Pass
        Pass {
            // 其他逐像素光源
            Tags {"LightMode"="ForwardAdd"}

            Blend One One

            CGPROGRAM

            // 这个指令保证我们在 Additional Pass 中访问到正确的光照变量
            #pragma multi_compile_fwdadd
            
            #pragma vertex vert
            #pragma fragment frag

            #include "Lighting.cginc"
            // 引入了自动光照的宏
			#include "AutoLight.cginc"

            fixed4 _Diffuse;
            fixed4 _Specular;
            float _Gloss;

            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
            };

            struct v2f
            {
                float4 pos : SV_POSITION;
                float3 worldNormal : TEXCOORD0;
                float3 worldPos : TEXCOORD1;
            };

            v2f vert (a2v v)
            {
                v2f o;
                
                o.pos = UnityObjectToClipPos(v.vertex);
                
                o.worldNormal = UnityObjectToWorldNormal(v.normal);
                o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;

                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                // 5. 去掉 Base Pass 中的环境光、自发光、逐顶点光照、SH光照部分

                fixed3 worldNormal = normalize(i.worldNormal);

                // 计算不同光源的方向
                # ifdef USING_DIRECTIONAL_LIGHT
                    fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz);
                # else
                    fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz - i.worldPos.xyz);
                # endif
                
                fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal, worldLightDir));
                
                fixed3 viewDir = normalize(UnityWorldSpaceViewDir(i.worldPos));
                fixed3 halfDir = normalize(worldLightDir + viewDir);
                fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);
                
                // 6. 处理不同光源的衰减
				#ifdef USING_DIRECTIONAL_LIGHT
					fixed atten = 1.0;
				#elif defined (POINT)
                    float3 lightCoord = mul(unity_WorldToLight, float4(i.worldPos, 1)).xyz;
                    fixed atten = tex2D(_LightTexture0, dot(lightCoord, lightCoord).rr).UNITY_ATTEN_CHANNEL;
                #elif defined (SPOT)
                    float4 lightCoord = mul(unity_WorldToLight, float4(i.worldPos, 1));
                    fixed atten = (lightCoord.z > 0) * tex2D(_LightTexture0, lightCoord.xy / lightCoord.w + 0.5).w * tex2D(_LightTextureB0, dot(lightCoord, lightCoord).rr).UNITY_ATTEN_CHANNEL;
                #else
                    fixed atten = 1.0;
				#endif

                fixed3 color = (diffuse + specular) * atten;

                return fixed4(color, 1.0);
            }
            ENDCG
        }
    }
    FallBack "Specular"
}
```

需要注意的是，本节只是为了讲解处理其他类型光源的实现原理，上述代码并不会用于真正的项目中。


#### 2. 实验：Base Pass 和 Additional Pass 的调用

1. 新建场景 Scene_9_2_2_2，去掉天空盒。
2. 调整平行光颜色为绿色。
3. 创建一个胶囊体，将上一节中的材质赋给它。
4. 新建4个点光源，调整它们的颜色为相同的红色。
5. 保存场景。

可以看到图9.10 所示的结果。

![图9.10 使用1个平行光 + 4个点光源照亮一个物体](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.10.jpg)

我们可以在 Window - Analysis - Frame Debugger 中打开**帧调试器（Frame Debugger）** 工具来查看场景的绘制过程。

![图9.11 打开帧调试器查看场景的绘制事件](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.11.jpg)

![图9.12 本例中的6个渲染事件，绘制顺序是从左到右、从上到下进行的](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.12.jpg)

可以注意到，Unity 除了这些点光源的顺序是按照他们的重要程度排序的。在这个例子中，由于所有光源颜色和强度都相同，因此它们的重要度取决于它们距离胶囊体的远近。

对于场景中的一个物体，如果它不在一个光源的光照范围内，Unity 不会为这个物体调用 Pass 来处理这个光源的。

如果逐像素光源的数目很多的话，该物体的 Additional Pass 就会被调用多次，影响性能。我们可以通过把光源的 Render Mode 设为 Not Important 来告诉 Unity，我们不希望把该光源当成逐像素处理。



## 9.3 Unity 的光照衰减

在 9.2 节中，我们提到 Unity 使用一张纹理作为查找表来在片元着色器中计算逐像素光照的衰减。这样的好处在于，计算衰减不依赖于数学公式的复杂性，我们只要使用一个参数值去纹理中采样即可。但使用纹理查找来计算衰减也有一些弊端：
* 需要预处理得到采样纹理，而且纹理的大小也会影响衰减的精度。
* 不直观，同时也不方便，因此一旦把数据存储到查找表中，我们就无法使用其他数学公式来计算衰减。

但由于在这种方法可以在一定程度上提升性能，而且得到的效果在大部分情况下都是良好的，因此 Unity 默认就是使用这种纹理查找的方式来计算逐像素的点光源和聚光灯的衰减。


### 9.3.1 用于光照衰减的纹理

Unity 在内部使用一张名为 _LightTexture0 的纹理来计算光源衰减。需要注意的是，如果我们对该光源使用了 cookie，那么衰减查找纹理是 _LightTextureB0。

我们通常只关心 LightTexture0 对角线上的纹理颜色值,这些值表明了在光源空间中不同位置的点的衰减值。例如，(0, 0) 点表明了与光源位置重合的点的衰减值，而 (1, 1) 点表明了在光源空间中所关心的距离最远的点的衰减。

为了对 _LightTexture0 纹理采样得到给定点到该光源的衰减值，我们首先需要得到该点在光源空间中的位置，这是通过 _LightMatrix0 变换矩阵得到的。我们只需要把 _LightMatrix0 和世界空间中的顶点坐标相乘即可得到光源空间中的相应位置：
`float3 lightCoord = mul(_LightMatrix0, float4(i.worldPos, 1)).xyz;`
然后，我们可以使用这个坐标的模的平方对衰减纹理进行采样，得到衰减值：
`fixed atten = tex2D(_LightTexture0, dot(lightCoord, lightCoord).rr).UNITY_ATTEN_CHANNEL;`

我们使用了光源空间中顶点距离的平方（通过 dot 函数来得到）来对纹理采样，之所以没有使用距离值来采样是因为这种方法可以避免开方操作。


### 9.3.2 使用数学公式计算衰减

下面的代码可以计算光源的线性衰减：

```
float distance = length(_WorldSpaceLightPos0.xyz - i.worldPos.xyz)
fixed atten = 1.0 / distance;
```



## 9.4 Unity 的阴影

为了让场景看起来更加真实，具有深度信息，我们通常希望光源可以把一些物体的阴影投射在其他物体上。

### 9.4.1 阴影是如何实现的

在实时渲染中，我们最常使用的是一种名为 **Shadow Map** 的技术。这种技术理解起来非常简单，它会首先把摄像机的位置放在与光源重合的位置上，那么场景中该光源的阴影区域就是那些摄像机看不到的地方。而Unity就是使用的这种技术。

在前向渲染路径中，如果场景中最重要的平行光开启了阴影，Unity 就会为该光源计算它的阴影映射纹理（shadowmap）。这张阴影映射纹理本质上也是一张深度图，它记录了从该光源的位置出发、能看到的场景中距离它最近的表面位置（深度信息）。

Unity 选择使用一个额外的 Pass 来专门更新光源的阴影映射纹理，这个 Pass 就是 LightMode 标签被设置为 ShadowCaster 的 Pass。这个 Pass 的渲染目标不是帧缓存，而是阴影映射纹理（或深度纹理）。Unity 首先把摄像机放置到光源的位置上，然后调用该 Pass，通过对顶点变换后得到光源空间下的位置，并据此来输出深度信息到阴影映射纹理中。

**传统的阴影映射纹理**：在正常渲染的 Pass 中把顶点位置变换到光源空间下，以得到它在光源空间中的三维位置信息。然后，我们使用 xy 分量对阴影映射纹理进行采样，得到阴影映射纹理中该位置的深度信息。如果该深度值小于该顶点的深度值（通常由 z 分量得到），那么说明该点位于阴影中。

**屏幕空间的阴影映射技术（Screenspace Shadow Map）**：通过调用 LightMode 为 ShadowCaster 的 Pass 来得到可投射阴影的光源的阴影映射纹理以及摄像机的深度纹理。然后，根据光源的阴影映射纹理和摄像机的深度纹理来得到屏幕空间的阴影图。如果摄像机的深度图中记录的表面深度大于转换到阴影映射纹理中的深度值，就说明该表面虽然是可见的，但是却处于该光源的阴影中。
通过这样的方式，阴影图就包含了屏幕空间中所有有阴影的区域。如果我们想要一个物体接收来自其他物体的阴影，只需要在 Shader 中对阴影图进行采样。由于阴影图是屏幕空间下的，因此，我们首先需要把表面坐标从模型空间变换到屏幕空间中，然后使用这个坐标对阴影图进行采样即可。

接收阴影和投射阴影的两个过程：
* 如果我们想要一个物体接收来自其他物体的阴影，就必须在 Shader 中对阴影映射纹理（包括屏幕空间的阴影图）进行采样，把采样结果和最后的光照结果相乘来产生阴影效果。
* 如果我们想要一个物体向其他物体投射阴影，就必须把该物体加入到光源的阴影映射纹理的计算中，从而让其他物体在对阴影映射纹理采样时可以得到该物体的相关信息。在 Unity 中，这个过程是通过为该物体执行 LightMode 为 ShadowCaster 的 Pass 来实现的。如果使用了屏幕空间的投影映射技术，Unity 还会使用这个 Pass 产生一张摄像机的深度纹理。


### 9.4.2 不透明物体的阴影

准备工作：
1. 新建场景 Scene_9_4_2，去掉天空盒。
2. 新建材质 ShadowMat，把 9.2 节中的 Chapter9-ForwardRendering.shader 赋给它。
3. 在场景中创建一个立方体、两个平面，把材质赋给立方体。
4. 保存场景。

#### 1. 让物体投射阴影

在 Unity 中，我们可以设置 Mesh Renderer 组件的 Cast Shadows 和 Receive Shadows 属性来控制该物体是否投射/接收阴影。


我们将正方体和两个平面的 Cast Shadows 和 Receive Shadows 都设为开启，可以发现即使我们未对 Chapter9-ForwardRendering.shader 做任何修改，正方体仍然可以向下面的平面投射阴影。

![图9.17 开启Cast Shadows和Receive Shadows，从而让正方体可以投射和接收阴影](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.17.jpg)

这是因为我们设置了 Fallback 语义：
```
Fallback "Specular"
```

内置的 Specular 同样没有包含 LightMode 为 ShadowCaster 的 Pass，但他的 Fallback 调用的 VertexLit 中包含了这样的 Pass ：

```
Pass
{
    Name "ShadowCaster"
    Tags { "LightMode" = "ShadowCaster" }

    CGPROGRAM
    #pragma vertex vert
    #pragma fragment frag
    #pragma multi_compile_shadowcaster
    #include "UnityCG.cginc"

    struct v2f
    {
        V2F_SHADOW_CASTER;
    };
    
    v2f vert(appdata_base v)
    {
        v2f o;
        TRANSFER_SHADOW_CASTER_NORMALOFFSET(o);
        return o;
    }

    float4 frag(v2f i) : SV_Target
    {
        SHADOW_CASTER_FRAGMENT(i);
    }
    ENDCG
}
```

当然，我们可以不依赖 Fallback，自行在 SubShader 中定义自己的 LightMode 为 ShadowCaster 的 Pass。这种自定义的 Pass 可以让我们更加灵活地控制阴影的产生。但由于这个 Pass 的功能通常是可以在多个 Unity Shader 间通用的，因此直接 Fallback 是一个更加方便的用法。

我们还会发现，右侧的平面即使开启了 Cast Shadows 也没有投影，因为对于内置的平面来说，它只有一个面，背面被剔除了，因此就不会添加到阴影映射纹理中。我们可以将 Cast Shadows 设置为 Two Sided 来允许对物体的所有面都计算阴影信息。

![图9.18 把Cast Shadows设置为Two Sided可以让右侧平面的背光面也产生阴影](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.18.jpg)


#### 2. 让物体接收阴影

新建 Shader 命名为 Chapter9-Shadow，将它赋给正方体的材质。复制 Chapter9-ForwardRendering.shader 中的代码，为了让正方体可以接收阴影，我们需要对代码进行一些修改：

```
// 修改 Base Pass 中的代码
Pass
{
    Tags {"LightMode"="ForwardBase"}

    CGPROGRAM

    #pragma multi_compile_fwdbase

    #pragma vertex vert
    #pragma fragment frag

    #include "Lighting.cginc"
    // 1. 包含新的内置文件，计算阴影时所用的宏都是在这个文件中声明的
    #include "AutoLight.cginc"

    fixed4 _Diffuse;
    fixed4 _Specular;
    float _Gloss;

    struct a2v
    {
        float4 vertex : POSITION;
        float3 normal : NORMAL;
    };

    struct v2f
    {
        float4 pos : SV_POSITION;
        float3 worldNormal : TEXCOORD0;
        float3 worldPos : TEXCOORD1;
        // 2. 在顶点着色器的输出结构体中添加一个内置宏 SHADOW_COORDS
        // 这个宏的参数需要的是下一个可用的插值寄存器的索引值
        SHADOW_COORDS(2)
    };

    v2f vert (a2v v)
    {
        v2f o;
        
        o.pos = UnityObjectToClipPos(v.vertex);
        
        o.worldNormal = UnityObjectToWorldNormal(v.normal);
        o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;

        // 3. 添加一个用于计算上一步中声明的阴影纹理坐标的宏 TRANSFER_SHADOW
        TRANSFER_SHADOW(o);

        return o;
    }

    fixed4 frag (v2f i) : SV_Target
    {
        fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

        fixed3 worldNormal = normalize(i.worldNormal);
        fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
        
        fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal, worldLightDir));
        
        fixed3 viewDir = normalize(UnityWorldSpaceViewDir(i.worldPos));
        fixed3 halfDir = normalize(worldLightDir + viewDir);
        fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);
        
        fixed atten = 1.0;

        // 4. 在计算阴影时，使用宏 SHADOW_ATTENUATION
        fixed shadow = SHADOW_ATTENUATION(i);

        fixed3 color = ambient + (diffuse + specular) * atten * shadow;

        return fixed4(color, 1.0);
    }
    ENDCG
}

```

效果如下：

![图9.19 正方体可以接收来自右侧平面的阴影](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.19.jpg)


### 9.4.3 使用帧调试器查看阴影绘制过程

首先在 Window - Analysis - Frame Debugger 中打开帧调试器。

![图9.20 使用帧调试器查看阴影绘制过程](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.20.jpg)

从图9.20 可以看出，绘制该场景共需要花费 20 个渲染事件。这些渲染事件可以分为 4 个部分：
1. UpdateDepthTexture：更新摄像机的深度纹理。
2. RenderShadowmap：渲染光源的阴影映射纹理。
3. CollectShadows：根据深度纹理和阴影映射纹理得到屏幕空间的阴影图。
4. 绘制渲染结果。

我们首先来看第一部分：更新摄像机的深度纹理：

![图9.21 正方体对深度纹理的更新结果](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.21.jpg)

在图 9.21 中我们可以发现，Unity 调用了 Shader：Unity Shader Book/Chapter9 Shadow pass #3 来更新深度纹理，尽管 Chapter9-Shadow 中我们只定义了两个 Pass，但 Unity 会在它的 Fallback 中找到第三个 Pass，即 LightMode 为 ShadowCaster 的 Pass 来更新摄像机的深度纹理。

* 在第二个部分，即渲染得到平行光的阴影映射纹理的过程中，Unity 也是调用了这个 Pass 来得到光源的阴影映射纹理。
* 在第三个部分中，Unity 会根据之前两步的结果得到屏幕空间的阴影图，如图9.22所示。
* 在最后一个部分中，如果物体所使用的 Shader 包含了对这张阴影图的采样就会得到阴影效果。图9.23 给出了这个部分 Unity 是如何一步步绘制出有阴影的画面效果的。

![图9.22 屏幕空间的阴影图](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.22.jpg)

![图9.23 Unity 绘制屏幕阴影的过程](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.23.jpg)



### 9.4.4 统一管理光照衰减和阴影

如何同时计算光照衰减和阴影？
可以通过内置的 UNITY_LIGHT_ATTENUATION 宏来实现。

准备工作如下：
1. 复制 9.4.2 节中的场景，改名为 Scene_9_4_4。
2. 新建 Shader，命名为 Chapter9-AttenuationAndShadowUseBuildInFunction。
3. 在 Shader 上右键新建材质，将材质赋给正方体。
5. 保存场景。

将 Chapter9-Shadow 中的代码复制到 Chapter9-AttenuationAndShadowUseBuildInFunction 中，并修改片元着色器的代码：

```
    fixed4 frag (v2f i) : SV_Target
    {
        // ......
        
        // 使用内置宏 UNITY_LIGHT_ATTENUATION 计算光照衰减和阴影。
        UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);

        fixed3 color = ambient + (diffuse + specular) * atten;

        return fixed4(color, 1.0);
    }
```

**UNITY_LIGHT_ATTENUATION** 是 Unity 内置的用于计算光照衰减和阴影的宏。
* 第一个参数：存储光照衰减和阴影值相乘后的结果，我们不需要声明 atten 变量，这个宏会自动为我们声明。
* 第二个参数：v2f 结构体，这个参数会传递给 SHADOW_ATTENUATION 宏，用于计算阴影值。
* 第三个参数：世界空间下的顶点位置，这个参数会用于光源空间下的坐标，再对光照衰减纹理采样来得到光照衰减。

由于使用了 UNITY_LIGHT_ATTENUATION，我们的 Base Pass 和 Additional Pass 的代码得以统一——我们不需要在 Base Pass 里单独处理阴影，也不需要在 Additional Pass 中判断光源类型来处理光照衰减。

如果我们希望可以在 Additonal Pass 中添加阴影效果，就需要使用 `#pragma multi_compile_fwdadd_fullshadows` 编译指令来代替 `#pragma multi_compile_fwdadd` 指令。这样一来，Unity也会为这些额外的逐像素光源计算阴影，并传递给Shader。



### 9.4.5 透明度物体的阴影

对于大多数半透明物体来说，把 Fallback 设为 VertexLit 就可以得到正确的阴影。但对于透明物体来说，我们需要小心设置 Fallback。

**透明度测试的阴影**：直接使用 VertexLit 作为回调的话，镂空区域也会投影，看起来和不透明物体一样。我们可以使用 Transparent/Cutout/VertexLit 作为 Fallback 来解决这个问题，它的 ShadowCaster Pass 也计算了透明度测试，它使用了名为 _Cutoff 的属性来进行透明度测试，因此，我们的 Shader 也需要提供 _Cutoff 属性。如果物体是双面的，则需要将物体的 Mesh Renderer 组件中的 Cast Shadows 属性设置为 Two Sided。

```
Shader "Unity Shaders Book/Chapter 9/Alpha Test With Shadow"
{
    Properties
    {
        _Color ("Color", Color) = (1,1,1,1)
        _MainTex ("Main Texture", 2D) = "white" {}
        _Cutoff ("Alpha Cutoff", Range(0,1)) = 0.5
    }
    SubShader
    {
        Tags { "Queue" = "AlphaTest" "IgnoreProjector" = "True" "RenderType" = "TransparentCutout" }

        Pass
        {
            Tags { "LightMode" = "ForwardBase" }

            Cull Off 

            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            
            // 1. 首先包含进需要的头文件
            #include "Lighting.cginc"
            #include "AutoLight.cginc"

            fixed4 _Color;
            sampler2D _MainTex;
            float4 _MainTex_ST;
            fixed _Cutoff;

            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
                float4 texcoord : TEXCOORD0;
            };

            struct v2f
            {
                float4 pos : SV_POSITION;
                float3 worldNormal : TEXCOORD0;
                float3 worldPos : TEXCOORD1;
                float2 uv : TEXCOORD2;
                // 2. 使用内置宏 SHADOW_COORDS(i) 来声明 shadow map 坐标
                SHADOW_COORDS(3)
            };

            v2f vert (a2v v)
            {
                v2f o;
                o.pos = UnityObjectToClipPos(v.vertex);
                
                o.worldNormal = UnityObjectToWorldNormal(v.normal);
                o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
                o.uv = TRANSFORM_TEX(v.texcoord, _MainTex);

                // 3. 使用内置宏 TRANSFER_SHADOW 计算阴影纹理坐标然后传递给片元着色器
                TRANSFER_SHADOW(o)
                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                fixed3 worldNormal = normalize(i.worldNormal);
                fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));

                fixed4 texColor = tex2D(_MainTex, i.uv);

                clip(texColor.a - _Cutoff);

                fixed3 albedo = texColor.rgb * _Color.rgb;
                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo;
                fixed3 diffuse = _LightColor0.rgb * albedo * max(0, dot(worldNormal, worldLightDir));

                // 4. 使用内置宏 UNITY_LIGHT_ATTENUATION 来计算阴影和光照衰减
                UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos)

                fixed3 color = ambient + diffuse * atten;

                return fixed4(color, 1.0);
            }
            ENDCG
        }
    }
    // 5. Transparent/Cutout/VertexLit 的 ShadowCaster Pass 也计算了透明度测试
    // 该 Pass 使用了名为 _Cutoff 的属性来进行透明度测试，因此，我们的 Shader 也需要提供 _Cutoff 属性。
    Fallback "Transparent/Cutout/VertexLit"
}
```

**透明度混合的阴影**：由于透明度混合需要关闭深度写入，由此带来的问题也影响了阴影的生成。总体来说，要想为这些半透明物体产生正确的阴影，需要在每个光源空间下仍然严格按照从后往前的顺序进行渲染，这会让阴影处理变得非常复杂，而且也会影响性能。因此，**在 Unity 中，所有内置的半透明 Shader 是不会产生任何阴影效果的**。当然，我们可以使用一些 dirty trick 来强制为半透明物体生成阴影，这可以通过把它们的 Fallback 设置为 VertexLit、Diffuse 这些不透明物体使用的 Unity Shader，这样 Unity 就会在它的 Fallback 找到一个阴影投射的 Pass （Unity 2023 测试无效）。然后，我们可以通过物体的 Mesh Renderer 组件上的 Cast Shadows 和 Receive Shadows 选项来控制是否需要向其他物体投射或接收阴影。

![图9.27 把使用了透明度混合的Unity Shader的Fallback设置为内置的Transparent/VertexLit。半透明物体不会向下方的平面投射阴影，也不会接收来自右侧平面的阴影，它看起来就像是完全透明一样](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.27.jpg)

![图9.28 把Fallback设为VertexLit来强制为半透明物体生成阴影](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/9.28.jpg)



## 9.5 本书使用的标准 Unity Shader

本书资源的 Assets/Shaders/Common 文件夹下提供了两个这样标准的 Unity Shader——BumpedDiffuse 和 BumpedSpecular。这两个 Unity Shader 都包含了对法线纹理、多光源、光照衰减和阴影的相关处理，唯一不同的是，BumpedDiffuse 使用了 Phong 光照模型，而BumpedSpecular使用了 Blinn-Phong 光照模型。



---------------------------------------------------------------------------



# 第10章 高级纹理

* 立方体纹理（Cubemap）
* 渲染纹理（Render Texture）
* 程序纹理（Procedural Texture）


## 10.1 立方体纹理（Cubemap）

在图形学中，**立方体纹理（Cubemap）** 是 **环境映射（Environment Mapping）** 的一种实现方法。环境映射可以模拟物体周围的环境，而使用了环境映射的物体可以看起来像镀了层金属一样反射出周围的环境。

立方体纹理一共包含了6张图像。对立方体纹理采样我们需要提供一个三维的纹理坐标，这个三维坐标表示了我们在世界空间下的一个 3D 方向。这个方向矢量从立方体的中心出发，向他外部延伸时就会和立方体的 6 个纹理之一相交，而采样得到的结果就是由该交点计算而来的。

立方体纹理也仅可以反射环境，但不能反射使用了该立方体纹理的物体本身。这是因为，立方体纹理不能模拟多次反射的结果，例如两个金属球互相反射的情况。想要得到令人信服的渲染结果，我们应该尽量对凸面体而不要对凹面体使用立方体纹理（因为凹面体会反射自身）。

立方体纹理在实时渲染中有很多应用，最常见的是用于天空盒子（Skybox）以及环境映射。


### 10.1.1 天空盒（Skybox）

天空盒（Skybox）是游戏中用于模拟背景的一种方法。

创建天空盒：
新建材质，将材质的 Shader 设置为 Skybox/6 Sided，然后在 Inspector 面板中设置天空盒纹理。

除了6张纹理属性外还有3个属性：
* Tint Color：天空盒整体的颜色。
* Intensity：天空盒的亮度。
* Rotation：天空盒沿 y 轴的旋转角度。

为场景添加天空盒：
在 Windows > Render Settings > Lighting 中 Environment 栏目下设置天空盒材质。
也可让一些摄像机显示不同的天空盒，为摄像机添加 Skybox 组件可以覆盖掉上面的设置。


### 10.1.2 环境映射（Environment Mapping）

环境映射可以模拟出金属质感的材质。

在Unity 5中，创建用于环境映射的立方体纹理的方法有三种：
1. 直接由一些特殊布局的纹理创建（例如全景图），将该纹理的 Texture Type 设置为 Cubemap；
2. 手动创建一个 Cubemap 资源，再把6张图赋给它，官方推荐使用第一种方法创建 CubeMap；
3. 由脚本生成，利用 Unity 提供的 Camera.RenderToCubemap 函数，该函数可以把从任意位置观察到的图像存储到6张图像中，从而创建该位置对应的立方体纹理。可参考[官方手册](https://docs.unity3d.com/ScriptReference/Camera.RenderToCubemap.html)。

在 Unity 中新建文件夹 Editor，然后在该文件夹下新建脚本 RenderCubemapWizard.cs，代码如下：
``` C#
using UnityEngine;
using UnityEditor;
using System.Collections;

public class RenderCubemapWizard : ScriptableWizard {
	
	public Transform renderFromPosition;
	public Cubemap cubemap;
	
	void OnWizardUpdate () {
		helpString = "Select transform to render from and cubemap to render into";
		isValid = (renderFromPosition != null) && (cubemap != null);
	}
	
	void OnWizardCreate () {
		// create temporary camera for rendering
		GameObject go = new GameObject( "CubemapCamera");
		go.AddComponent<Camera>();
		// place it on the object
		go.transform.position = renderFromPosition.position;
		// render into cubemap		
		go.GetComponent<Camera>().RenderToCubemap(cubemap);
		
		// destroy temporary camera
		DestroyImmediate( go );
	}
	
	[MenuItem("GameObject/Render into Cubemap")]
	static void RenderCubemap () {
		ScriptableWizard.DisplayWizard<RenderCubemapWizard>(
			"Render cubemap", "Render!");
	}
}
```

1. 新建场景，设置好天空盒，然后在场景中创建一个空物体，我们会使用该物体的位置信息渲染立方体纹理。
2. 新建一个用于存储的立方体纹理（在 Project 视图下右键 Create - Legacy - Cubemap 来创建）。为了让脚本可以顺利将图像渲染到该立方体纹理中，我们需要在它的面板中勾选 **Readable** 选项。**Face size** 选项可以设置立方体纹理的分辨率，分辨率越大，效果越好，占用内存也越大。
3. 从 Unity 菜单栏选择 GameObject - Render into Cubemap，打开我们在脚本中实现的用于渲染立方体纹理的窗口，并把第1步中创建的 GameObject 和第2步中创建的 Cubemap 分别拖曳到窗口中的 Render From Position 和 Cubemap 选项，如图 10.5 所示。
4. 单击窗口中的 Render! 按钮，就可以把从该位置观察到的世界空间下的6张图像渲染到 Cubemap 中，如图 10.6 所示。

<center class="half">
<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/10.5.jpg" alt="图10.5 使用脚本创建立方体纹理" width=400/>
<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/10.6.jpg" alt="图10.6 使用脚本渲染立方体纹理" width=220/>
</center>

可以利用环境映射在物体表面模拟反射和折射。


### 10.1.3 反射（Reflection）

使用了反射效果的物体通常看起来就像镀了层金属。想要模拟反射效果很简单，我们只需要通过入射光线的方向和表面法线方向来计算反射方向，再利用反射方向对立方体纹理采样即可。

准备工作：
1. 新建场景 Scene_10_1_3。设置好天空盒。
2. 向场景拖拽一个 Teapot 模型，调整好位置。
3. 新建 Shader 命名为 Chapter10-Reflection。
4. 在 Shader 上右键新建材质，将材质赋给 Teapot。

Shader 代码：
```
Shader "Unity Shaders Book/Chapter 10/Reflection"
{
    Properties
    {
        _Color ("Color", Color) = (1,1,1,1)
        // 1. 首先，声明3个新的属性
        _ReflectColor ("Reflect Color", Color) = (1,1,1,1)
        _ReflectAmount ("Reflect Amount", Range(0,1)) = 0.5
        _Cubemap ("Cubemap", CUBE) = "_Skybox" {}
    }
    SubShader
    {
        Pass
        {
            Tags {"LightMode"="ForwardBase"}

            CGPROGRAM

            #pragma multi_compile_fwdbase

            #pragma vertex vert
            #pragma fragment frag

            #include "Lighting.cginc"
			#include "AutoLight.cginc"

            fixed4 _Color;
            fixed4 _ReflectColor;
            fixed _ReflectAmount;
            samplerCUBE _Cubemap;

            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
            };

            struct v2f
            {
                float4 pos : SV_POSITION;
                float3 worldNormal : TEXCOORD0;
                float3 worldPos : TEXCOORD1;
                float3 worldViewDir : TEXCOORD2;
                float3 worldRefl : TEXCOORD3;
                SHADOW_COORDS(4)
            };

            v2f vert (a2v v)
            {
                v2f o;

                o.pos = UnityObjectToClipPos(v.vertex);
                o.worldNormal = UnityObjectToWorldNormal(v.normal);
                o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
                o.worldViewDir = UnityWorldSpaceViewDir(o.worldPos);

                // 2. 通过使用 reflect 函数计算反射方向
                o.worldRefl = reflect(-o.worldViewDir, o.worldNormal);
                
                TRANSFER_SHADOW(o);
                
                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                fixed3 worldNormal = normalize(i.worldNormal);
                fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
                fixed3 worldViewDir = normalize(i.worldViewDir);

                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

                fixed3 diffuse = _LightColor0.rgb * _Color.rgb * max(0, dot(worldNormal, worldLightDir));
                
                // 3. 利用反射方向来对立方体纹理采样
                fixed3 reflection = texCUBE(_Cubemap, i.worldRefl).rgb * _ReflectColor.rgb;

                UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);

                fixed3 color = ambient + lerp(diffuse, reflection, _ReflectAmount) * atten;

                return fixed4(color, 1.0);
            }
            ENDCG
        }
    }
	FallBack "Reflective/VertexLit"
}
```


### 10.1.4 折射（Refraction）

折射的物理原理比反射复杂一些。我们在初中物理就已经接触过折射的定义：当光线从一种介质（例如空气）斜射入另一种介质（例如玻璃）时，传播方向时，我们可以使用 **斯涅尔定律（Snell's Law）** 来计算反射角。当光从介质1沿着和表面法线夹角为 $\theta_1$ 的方向斜射入介质2时，我们可以使用如下公式计算折射光线与法线的夹角 $\theta_2$ :

$$
\eta_1 \sin \theta_1 = \eta_2 \sin \theta_2
$$

其中， $\eta_1$ 和 $\eta_2$ 分别是两个介质的**折射率（index of refraction）**。折射率是一项重要的物理常数，例如真空的折射率是1，而玻璃的折射率一般是1.5。图10.8给出了这些变量之间的关系。

<center>
<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/10.8.jpg" alt="图10.8 斯涅尔定律" width=300/>
<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/10.9.jpg" alt="图10.9 使用了折射效果的 Teapot 模型" width=450/>
</center>

新建 Shader 命名为 Chapter10-Refraction，并在 Shader 上右键新建材质，将材质赋给 Teapot。

Shader 部分代码：
```
Properties
{
    _Color ("Color", Color) = (1,1,1,1)
    // 1. 声明4个新的属性
    _RefractColor ("Refract Color", Color) = (1,1,1,1)
    _RefractAmount ("Refract Amount", Range(0, 1)) = 0.5
    _RefractRatio ("Refract Ratio", Range(0.1, 1)) = 0.5
    _Cubemap ("Cubemap", Cube) = "_Skybox" {}
}

......

v2f vert (a2v v)
{
    v2f o;

    o.pos = UnityObjectToClipPos(v.vertex);
    o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
    o.worldNormal = normalize(UnityObjectToWorldNormal(v.normal));
    o.worldViewDir = normalize(UnityWorldSpaceViewDir(o.worldPos));

    // 2. 使用 refract 函数计算折射方向
    o.worldRefr = refract(-o.worldViewDir, o.worldNormal, _RefractRatio);
    
    TRANSFER_SHADOW(o);
    
    return o;
}

fixed4 frag (v2f i) : SV_Target
{
    fixed3 worldNormal = i.worldNormal;
    fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
    fixed3 worldViewDir = i.worldViewDir;

    fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

    fixed3 diffuse = _LightColor0.rgb * _Color.rgb * max(0, dot(worldNormal, worldLightDir));
    
    // 3. 利用折射方向来对立方体纹理采样
    fixed3 refraction = texCUBE(_Cubemap, i.worldRefr).rgb * _RefractColor.rgb;

    UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);

    fixed3 color = ambient + lerp(diffuse, refraction, _RefractAmount) * atten;

    return fixed4(color, 1.0);
}
```


### 10.1.5 菲涅尔反射（Fresnel Reflection）

菲涅耳反射(Fresnel reflection)可根据视角方向控制反射程度。通俗地讲，菲涅耳反射描述了一种光学现象，即当光线照射到物体表面上时，一部分发生反射，一部分进入物体内部，发生折射或散射。被反射的光和入射光之间存在一定的比率关系，这个比率关系可以通过菲涅耳等式进行计算。

**Schlick 菲涅尔近似等式**：
   $F_{Schlick}(v, n) = F_0 + (1 - F_0) (1 - (v \cdot n))^5$
其中， $F_0$ 是反射系数，用于控制菲涅尔反射的强度， $v$ 是视角方向， $n$ 是法线方向。


**Empirical 菲涅尔近似等式**： 
   $F_{Empirical}(v, n) = max(0, min(1, bias + scale * (1 - v \cdot n)^{power}))$ 
其中， $bias$ 、 $scale$ 和 $power$ 是控制项。

新建 Shader 命名为 Chapter10-Fresnel，并在 Shader 上右键新建材质，将材质赋给 Teapot 。

Shader 部分代码：
```
Properties
{
    _Color ("Color", Color) = (1,1,1,1)
    // 声明调整 Fresnel 反射的属性
    _FresnelScale ("Fresnel Scale", Range(0, 1)) = 0.5
    _Cubemap ("Cubemap", Cube) = "_Skybox" {}
}

......

fixed4 frag (v2f i) : SV_Target
{
    ......

    fixed3 reflection = texCUBE(_Cubemap, i.worldRefl).rgb;

    // 计算 Fresnel 反射，并与环境光和漫反射光混合
    fixed fresnel = _FresnelScale + (1 - _FresnelScale) * pow(1 - dot(worldViewDir, worldNormal), 5);

    UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos);

    fixed3 color = ambient + lerp(diffuse, reflection, saturate(fresnel)) * atten;

    return fixed4(color, 1.0);
}
```

效果：
![图10.10 使用了菲涅耳反射的Teapot模型](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/10.10.jpg)




## 10.2 渲染纹理

现代的 GPU 允许我们把整个三维场景渲染到一个中间缓冲中，即 **渲染目标纹理(Render Target Texture，RTT)**，而不是传统的帧缓冲或后备缓冲(backbufer)。
与之相关的是 **多重渲染目标(Multiple Render Target，MRT)**，这种技术指的是 GPU允许我们把场景同时渲染到多个渲染目标纹理中，而不再需要为每个渲染目标纹理单独渲染完整的场景。延迟渲染就是使用多重渲染目
标的一个应用。

Unity 为渲染目标纹理定义了一种专门的纹理类型 —— **渲染纹理(Render Texture)**。

使用渲染纹理通常有两种方式：
1. 在 Project 目录下创建一个渲染纹理，然后把某个摄像机的渲染目标设置成该渲染纹理，这样一来该摄像机的渲染结果就会实时更新到渲染纹理中，而不会显示在屏幕上。使用这种方法，我们还可以选择渲染纹理的分辨率、滤波模式等纹理属性。
2. 在屏幕后处理时使用 GrabPass 命令或 OnRenderImage 函数来获取当前屏幕图像，Unity 会把这个屏幕图像放到一张和屏幕分辨率等同的渲染纹理中，下面我们可以在自定义的 Pass 中把它们当成普通的纹理来处理，从而实现各种屏幕特效。


### 10.2.1 镜子效果

新建一个相机，作为镜子的渲染相机，设置好相机的位置、视角，使用一个渲染纹理作为渲染目标，并把该渲染纹理在水平方向上翻转后直接显示到镜子上即可。

没有反射效果，改变视角后就会发现不对，不过可以通过添加脚本根据主相机位置视角来改变渲染相机的位置视角，从而实现镜子效果。


### 10.2.2 玻璃效果

在 Unity Shader 中可以使用 GrabPass 来获取屏幕图像，当我们在 Shader 中定义了一个 GrabPass 后，Unity 会把当前屏幕图的像绘制到一张纹理中，以便我们在后续的 Pass 中访问它。

在使用 GrabPass 时，我们需要额外**小心物体的渲染队列设置**。GrabPass 通常用于渲染透明物体，尽管代码里不包含混合指令，但是仍然要设置透明队列 `"Queue"="Transparent"` 。

使用 GrabPass 来模拟一个玻璃效果的实现：
1. 使用一张法线纹理来修改模型的法线信息；
2. 使用了 10.1 节介绍的反射方法，通过一个Cubemap 来模拟玻璃的反射，
3. 模拟折射时，则使用 GrabPass 获取玻璃后面的屏幕图像；
4. 使用切线空间下的法线对屏幕纹理坐标偏移后，再对屏幕图像进行采样来模拟近似的折射效果。


构建一个测试玻璃效果的场景，为了得到本场景适用的环境映射纹理，我们使用 10.1.2 节中实现的创建 Cubemap 的方法来创建它。

<center>
<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/10.13.jpg" alt="图10.13 玻璃效果" width=450/>
<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/10.14.jpg" alt="图10.14 立方体纹理" width=230/>
</center>

新建 Shader 命名为 Chapter10-GlassRefraction，并在 Shader 上右键新建材质，将材质赋给 Cube。

```
Shader "Unity Shaders Book/Chapter 10/Glass Refration"
{
    Properties
    {
        _MainTex ("Main Tex", 2D) = "white" {}
        _BumpMap ("Normal Map", 2D) = "bump" {}
        _Cubemap ("Environment Map", CUBE) = "_Skybox" {}
        _Distortion ("Distortion", Range(0, 100)) = 10
        _RefractAmount ("Refract Amount", Range(0, 1)) = 0.5
    }
    SubShader
    {
        Tags { "Queue"="Transparent" "RenderType"="Opaque" }

        // 使用 GrabPass 来获取屏幕图像，字符串名称决定了抓取得到的屏幕图像将会被存入那个纹理中
        GrabPass { "_RefractionTex" }

        Pass
        {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            

            #include "UnityCG.cginc"

            sampler2D _MainTex;
            float4 _MainTex_ST;
            sampler2D _BumpMap;
            float4 _BumpMap_ST;
            samplerCUBE _Cubemap;
            float _Distortion;
            fixed _RefractAmount;

            sampler2D _RefractionTex;
            float4 _RefractionTex_TexelSize;

            struct a2v
            {
                float4 vertex : POSITION;
                float2 uv : TEXCOORD0;
                float3 normal : NORMAL;
                float4 tangent : TANGENT;

            };

            struct v2f
            {
                float4 pos : SV_POSITION;
                float4 uv : TEXCOORD0;
                float4 scrPos : TEXCOORD1;
                float4 TtoW0 : TEXCOORD2;
                float4 TtoW1 : TEXCOORD3;
                float4 TtoW2 : TEXCOORD4;
            };

            v2f vert (a2v v)
            {
                v2f o;
                o.pos = UnityObjectToClipPos(v.vertex);
                o.uv.xy = TRANSFORM_TEX(v.uv, _MainTex);
                o.uv.zw = TRANSFORM_TEX(v.uv, _BumpMap);

                o.scrPos = ComputeGrabScreenPos(o.pos);

                float3 worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
                fixed3 worldNormal = UnityObjectToWorldNormal(v.normal);
                fixed3 worldTangent = UnityObjectToWorldDir(v.tangent.xyz);
                fixed3 worldBinormal = cross(worldNormal, worldTangent) * v.tangent.w;

                o.TtoW0 = float4(worldTangent.x, worldBinormal.x, worldNormal.x, worldPos.x);
                o.TtoW1 = float4(worldTangent.y, worldBinormal.y, worldNormal.y, worldPos.y);
                o.TtoW2 = float4(worldTangent.z, worldBinormal.z, worldNormal.z, worldPos.z);

                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                float3 worldPos = float3(i.TtoW0.w, i.TtoW1.w, i.TtoW2.w);
                fixed3 worldViewDir = normalize(UnityWorldSpaceViewDir(worldPos));

                fixed3 bump = UnpackNormal(tex2D(_BumpMap, i.uv.zw));

                float2 offset = bump.xy * _Distortion * _RefractionTex_TexelSize.xy;
                i.scrPos.xy += offset;
                fixed3 refrCol = tex2D(_RefractionTex, i.scrPos.xy / i.scrPos.w).rgb;

                bump = normalize(half3(dot(i.TtoW0.xyz, bump), dot(i.TtoW1.xyz, bump), dot(i.TtoW2.xyz, bump)));
                fixed3 refrDir = reflect(worldViewDir, bump);
                fixed4 texColor = tex2D(_MainTex, i.uv.xy);
                fixed3 reflCol = texCUBE(_Cubemap, refrDir).rgb * texColor.rgb;

                fixed3 finalColor = reflCol * (1 - _RefractAmount) + refrCol * _RefractAmount;

                return fixed4(finalColor, 1.0);
            }
            ENDCG
        }
    }
    FallBack "Diffuse"
}
```

GrabPass 支持两种形式：
* 直接使用 `GrabPass {}` 来抓取当前屏幕图像，并将其存入 `_GrabTexture` 中。当场景中有多个物体使用了这样的形式，Unity 每次会都对屏幕进行一次抓取，分配不同的 `_GrabTexture` 纹理，这样会对性能消耗极大。
* 使用 `GrabPass { "TextureName" }` 来指定一个纹理名称，将抓取到的屏幕图像存入该纹理中。Unity 只会为第一个 `TextureName` 抓取一次屏幕图像，并将其存入该纹理中，其他使用 `TextureName` 的物体都会使用这个纹理。


### 10.2.3 渲染纹理 vs GrabPass

GrabPass 好处在于实现简单，只需要在 Shader 中写几行代码就可以实现屏幕抓取。而渲染纹理需要我们创建一个渲染纹理盒一个额外的相机，将相机的 Render Target 设置为渲染纹理，然后将渲染纹理传递给相应的 Shader。

但从效率上讲，渲染纹理好于 GrabPass ，尤其在移动设备上。渲染纹理可以自定义大小，GrabPass 则只能抓取当前屏幕大小的图像，这意味着在高分辨率的 设备上可能会造成严重的带宽影响。而且在移动设备上，GrabPass 虽然不会重新渲染场景，但往往需要 CPU 直接读取后备缓冲（back buffer）中的数据，破坏 CPU 和 GPU 之间的并行性，这是比较耗时的，甚至在一些移动设备上这是不支持的。

Unity 5 以后引入了 **命令缓冲（Command Buffers）**，可得到类似抓屏的效果，它可以在不透明渲染后把当前的图像复制到临时的渲染目标纹理中，然后在那里进行一些额外的操作，例如模糊等，最后把图像传递给需要使用它的物体进行处理和显示。可参考官方手册（https://docs.unity3d.com/Manual/GraphicsCommandBuffers.html）。



## 10.3 程序纹理（Procedural Texture）

**程序纹理（Procedural Texture）** 指的是那些由计算机生成的图像。使用程序纹理的好处在于我们可以使用各种参数来控制纹理的外观。


### 10.3.1 在 Unity 中实现简单的程序纹理

1. 新建材质，使用第7章的 Shader Chapter7-SingleTexture。
2. 新建立方体，将材质赋给它。
3. 新建 C# 脚本 ProceduralTextureGeneration.cs，将它拖到立方体上。


``` C#
using System.Collections;
using System.Collections.Generic;
using UnityEngine;

// 1. 为了让该脚本能在编辑器下运行，需要添加[ExecuteInEditMode]标签。
[ExecuteInEditMode]
public class ProceduralTextureGeneration : MonoBehaviour
{
    // 2. 声明一个材质，这个材质球将使用该脚本生成的程序纹理。
    public Material material = null;

    // 3. 声明程序纹理使用的各种参数
    #region Material Properties
    // SetProperty 使用了开源插件：https://github.com/LMNRY/SetProperty
    [SerializeField, SetProperty("textureWidth")]
    private int m_textureWidth = 512;
    public int textureWidth
    {
        get { return m_textureWidth; }
        set
        {
            m_textureWidth = value;
            _UpdateMaterial();
        }
    }

    [SerializeField, SetProperty("backgroundColor")]
    private Color m_backgroundColor = Color.white;
    public Color backgroundColor
    {
        get { return m_backgroundColor; }
        set
        {
            m_backgroundColor = value;
            _UpdateMaterial();
        }
    }

    [SerializeField, SetProperty("circleColor")]
    private Color m_circleColor = Color.yellow;
    public Color circleColor
    {
        get { return m_circleColor; }
        set
        {
            m_circleColor = value;
            _UpdateMaterial();
        }
    }

    // 模糊因子，模糊圆形边界
    [SerializeField, SetProperty("blurFactor")]
    private float m_blurFactor = 0.5f;
    public float blurFactor
    {
        get { return m_blurFactor; }
        set
        {
            m_blurFactor = value;
            _UpdateMaterial();
        }
    }

    #endregion

    // 4. 声明一个 Texture2D 类型的变量，用于保存程序纹理。
    private Texture2D m_generatedTexture = null;

    // 5. 在 Start 函数中进行相应的检查，以得到需要使用该程序纹理的材质。
    void Start()
    {
        if (material == null)
        {
            Renderer renderer = GetComponent<Renderer>();
            if (renderer == null)
            {
                Debug.LogWarning("Cannot find Renderer component.");
                return;
            }
            material = renderer.sharedMaterial;
        }

        _UpdateMaterial();
    }

    // 6. _UpdateMaterial 函数用于更新材质球的程序纹理。
    private void _UpdateMaterial()
    {
        if (material != null)
        {
            m_generatedTexture = _GenerateProceduralTexture();
            material.SetTexture("_MainTex", m_generatedTexture);
        }

    }

    // 7. _GenerateProceduralTexture 函数用于生成程序纹理。
    private Texture2D _GenerateProceduralTexture()
    {
        Texture2D proceduralTexture = new Texture2D(textureWidth, textureWidth);

        // 定义圆与圆之间的间距
        float circleInterval = textureWidth / 4.0f;
        // 定义圆的半径
        float radius = textureWidth / 10.0f;
        // 定义模糊系数
        float edgeBlur = 1.0f - blurFactor;

        for (int w = 0; w < textureWidth; w++)
        {
            for (int h = 0; h < textureWidth; h++)
            {
                // 使用背景色进行初始化
                Color pixel = backgroundColor;

                // 画圆
                for (int i = 0; i < 3; i++)
                {
                    for (int j = 0; j < 3; j++)
                    {
                        // 圆心位置
                        Vector2 circleCenter = new Vector2(circleInterval * (i + 1), circleInterval * (j + 1));
                        // 计算当前像素与圆心的距离
                        float distance = Vector2.Distance(new Vector2(w, h), circleCenter) - radius;

                        // 模糊圆的边界
                        Color color = Color.Lerp(circleColor, new Color(pixel.r, pixel.g, pixel.b, 0.0f), Mathf.SmoothStep(0f, 1f, distance * edgeBlur));

                        // 与之前的颜色进行混合
                        pixel = Color.Lerp(pixel, color, color.a);
                    }
                }

                proceduralTexture.SetPixel(w, h, pixel);
            }
        }

        proceduralTexture.Apply();

        return proceduralTexture;
    }

}

```


### 10.3.2 Unity 的程序材质

**程序材质（Procedural Material）** ：Unity 中专门使用程序纹理的材质，它使用的纹理是用 Substance Designer 软件生成的。这些材质都是以 .sbsar 格式保存的，可以直接导入 Unity 编辑器中使用。

当把这些文件导入 Unity 后，Unity 就会生成一个 **程序纹理资源(Procedural MaterialAsset)**。程序纹理资源可以包含一个或多个程序材质，例如图 10.18 中就包含了两个程序纹理——Cereals 和 Cereals1，每个程序纹理使用了不同的纹理参数，因此 Unity 为它们生成了不同的程序纹理，例如 Cereals_Diffus e和 Cereals_1_Diffuse等。

![图10.18 程序纹理资源](https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/10.18.jpg)






图片地址：https://raw.githubusercontent.com/Ineloquent0/notes/main/Shader/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/.jpg