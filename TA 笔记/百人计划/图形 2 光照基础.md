# 总览

```mermaid
graph LR
0[图形部分]
0 --> 1[1.颜色空间]
1 --> 1.1[光线与色彩]
    1.1 --> 1.1.1[光的要素]
    1.1 --> 1.1.2[光源]
    1.1 --> 1.1.3[波长]
    1.1 --> 1.1.4[能量分布]
    1.1 --> 1.1.5[分光光度计]
    1.1 --> 1.1.6[光的传播]
1 --> 1.2[光源接收者]
    1.2 --> 1.2.1[相对亮度感知]
    1.2 --> 1.2.2[人眼HDR]
    1.2 --> 1.2.3[感光细胞]
        1.2.3 --> 1.2.3.1[杆状细胞：感知亮度]
        1.2.3 --> 1.2.3.2[锥状细胞：感知色彩]
    1.2 --> 1.2.4[人眼的本质]
1 --> 1.3[色彩空间的历史]
1 --> 1.4[色彩空间的定义]
    1.4 --> 1.4.1[色域] --> 1.4.1.1[三个基色坐标]
    1.4 --> 1.4.2[Gamma] --> 1.4.2.1[如何对三角形内进行切分]
    1.4 --> 1.4.3[白点] --> 1.4.3.1[色域三角形中心]
1 --> 1.5[Gamma 校正] --> 1.5.1[符合大部分人的灰阶感知的Gamma值]

0 --> 2[2.模型与材质]
2 --> 2.1[模型]
    2.1 --> 2.1.1[模型实现原理] --> 2.1.1.1[顶点着色器 > 图元装配 > 光栅化 > 片元着色器]
    2.1 --> 2.1.2[UV]
    2.1 --> 2.1.3[obj与fbx的区别]
    2.1 --> 2.1.4[模型数据解析]
        2.1.4 --> 2.1.4.1[顶点动画]
        2.1.4 --> 2.1.4.2[纹理动画]
        2.1.4 --> 2.1.4.3[顶点颜色]
        2.1.4 --> 2.1.4.4[顶点法线与面法线]
2 --> 2.2[材质]
    2.2 --> 2.2.1[漫反射]
    2.2 --> 2.2.2[镜面反射]
    2.2 --> 2.2.3[折射]
    2.2 --> 2.2.4[粗糙镜面反射]
    2.2 --> 2.2.5[多层材质]
    2.2 --> 2.2.6[SSS此表面散射]
    2.2 --> 2.2.7[多层皮肤模型]

0 --> 3[3.HLSL 常用函数]
3 --> 3.1[基本数学运算]
    3.1 --> 3.1.1[角度、弧度互换] --> 3.1.1.1[degrees、radians]
    3.1 --> 3.1.2[噪波] --> 3.1.2.1[noise]
    3.1 --> 3.1.3[其他计算]
3 --> 3.8[幂指对函数]
3 --> 3.2[三角函数与双曲函数]
3 --> 3.3[数据范围]
3 --> 3.4[类型判断]
3 --> 3.5[向量与矩阵]
3 --> 3.6[光线运算]
3 --> 3.7[纹理]

0 --> 4[4.传统经验光照模型]
4 --> 4.1[局部光照]
    4.1 --> 4.1.1[漫反射]
    4.1 --> 4.1.2[高光]
    4.1 --> 4.1.3[环境光]
    4.1 --> 4.1.4[自发光]
4 --> 4.2[经典光照模型]
    4.2 --> 4.2.1[Lambert]
    4.2 --> 4.2.2[Phong]
    4.2 --> 4.2.3[Blinn-Phong]
```


# 1. 色彩空间

## 1.1 光线与色彩

### 色彩发送器

**色彩认知：**
光源是出生点，光源发射出光线，光线通过直射反射折射等路径最终进入人眼。但人眼接收到光线后，人眼的细胞产生了一系列化学反应。由此把产生的信号传入大脑，最终大脑对颜色产生了认知感知。

### 光的要素


![光的要素](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240907125332.jpg)

### 光源
光源就是产生光的物体。

### 波长
光理论上讲是无限大的，只是我们人眼可见光是由局限的。

如果没有光，我们就无法在黑暗中看到色彩，光的本质就是一种物理现象，光在没有进入我们的眼睛前，我们对它的认知是一种波长与能量分布。

![光谱](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/2-200624155606257.jpg)

### 能量分布
我们讲光线是一种波，那么既然是真实存在的就会有能量，能量单位就是功率，我们认知的光就会有不同的功率。比如一个光是由多个波长组合起来的波形

那么也就是说我们阐述色彩就用这个波长就可以了，但是这么做实在是太反人类了，我们无法保证能简单描述色彩。于是人们发明了一个叫做分光光度计的东西。

![光的波形](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240907133456.jpg)

### 分光光度计

分光光度计就是用于描述光线的具体能量强度，记得小时候用棱镜分光吗。我们通过分光之后对区间波长进行了感应与测量，最后得知了光谱的分布最终得知光线额能量集中在了550nm附近（上图中绿色地方）

于此我们获得了：
1. 混合波长组成光线，拆分光线，变成光线形成单一波长光 
2. 测量单一波长光的实际所含能量

![分光光度计](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240907133950.jpg)

### 光的传播
回到光线的传播路径上来讨论，我们认知到光是经过了不同路径才进入我们的眼睛中的。
* 直射光：光源直射眼睛
* 折射光：光源穿过物体进入眼睛
* 反射光：光源经过物体表面反射进入眼睛
* 光线追踪：光线弹来弹去，然后我们根据权重确定光线最后进入眼睛中的颜色

下图就是光通过反射之后，在能量上发生的变化，可以明显看到，少了一部分的能量，这是因为一部分的能量被物体吸收了，也就是说每次光经过反射或投射都会或多或少对光的能量分布产生一些影响

简单通过能量分布图分析下右图得出结论： 物体吸收光功率的大部分在600nm左右也就是说物体吸收的光是黄色和绿色的光

<div align=center>
<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908130213.jpg" alt="光通过反射之后，在能量上发生的变化" width="500"/>
<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908130507.jpg" alt="吸收功率谱密度" width="350"/>
</div>


## 1.2 光源接收者

### 相对亮度感知
在某些阴暗的环境下，点亮一盏灯，这时人眼就会觉得非常亮。如果同时点亮1000盏灯，反而觉得只是10倍的亮度，对亮度的认知相当于从 0~1 再从 1~10。

### 人眼 HDR
* 人眼既可以分辨出高亮度的云彩的不同层次区别，还可以分辨出阴影中物不同物体的异同。
* 但是人眼的能力并不能保证这两个功能同时生效。

这样一说，反而就能发现人眼真是个变化莫测的存在，它可能会随着不同的环境，感知到不同的色彩，体验到不同的明暗效果，甚至可能会随着盯着某一个点时间流逝而变化颜色。

### 人眼感光细胞分布
* 杆状细胞：感知亮度
* 锥状细胞：感知色彩

感光细胞（杆状细胞）对亮度特别的敏感，只要有 5~14 个光子打到杆状细胞就会产生神经信号，这也可以解释为什么闪光弹能让人致盲，一部分原因就是因为光实在太亮，直接干涉了人眼最敏感的感光细胞

### 锥状细胞
这种细胞专门用于感知颜色，但是他们还被区分为了 L 细胞，M 细胞，S 细胞。

这三种细胞负责感知的波长不一，如图所示，L 感知红色区间，M 感知绿色区间，S 感知蓝色区间

![锥状细胞](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908132212.jpg)

### 人眼的本质
人眼的本质是光源的接收者。他的作用就是接收外部光线输入，输出神经电信号进入大脑。

### 完整积分公式

$C=\int_{min}^{max}S(λ)I(λ)R(λ)dλ$

这个公式简单分成了四个部分
- C值得是人眼这个函数输出的神经电信号
- S(λ) 表示LMS这三个感官细胞的感知分布
- I(λ)表示光源的功率谱分布
- R(λ)表示反射物体的吸收功率分布


## 1.3 色彩空间的历史

### 19 世纪色彩的猜想
1. 人们有 100 多种感受颜色的细胞
2. 人们有三种，分别是 RGB 三种感色细胞
3. 人们有三种，分别是黑白，红绿，黄蓝感色细胞（是不是很眼熟）

现在这么多年过去了，其中的 2 和 3 这两种猜想都成为了我们当下的色彩视觉模型，也称之**色彩模型**

### 1905 Munsell 色彩系统
美国艺术家 Albert Henry Munsell 利用自己的艺术特长，最早提出了一个色彩系统，后来在 1930 年被优化改良。

Munsell 通过很多色卡来描述色彩，下面旋转角度的是色相，Munsell 垂直的是亮度，从圆心到外部是 Munsell 饱和度。 人们凭借自我主观意识认知与区分色彩就是 HSL (色相、饱和亮度)，这套系统没有过多的物理科学在其中，更多的是一种艺术家的理解与归纳总结规范…

![Munsell 色彩系统](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908133846.jpg)

这及其方便了描述色彩，一个颜色可以通过： `H = 1.6YR, V = 6.3, C = 3.9` 来描述而且也不会有任何的描述与理解偏差。

于是我们方便起见就为一些常用色彩制作了色卡，一个个色卡描述色彩就非常方便。

### 1931 CIE 1931 RGB Color Specification System
科学家们觉得上述的色彩系统还可以，但是不够科学，于是为了以一种科学的方式阐述色彩，于是一个叫 CIE 的机构在 1931 年建立了一套色彩系统， 希望完全客观完全物理的量化色彩。

![CIE 1931 RGB Color Specification System](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908134856.jpg)

#### 色彩匹配方案

CIE 把所有可视波长的光线作为测试光挨个测试了一个遍，最终得到了三条曲线

我们发现 435.8~546.1 nm 这段波长中的红色基色强度是负数。这虽然物理正确，但是一点也没有科学的美感，于是我们进行了归一化，保证色彩在 -1~1 之间。

最终通过计算出 rgb 的基色的强度在当前混色强度的所占比例这样计算后， r' g' b' 都是在 -1~1 之间， 那么我们发现 $r'+g'+b'=1$ ，那么就可以通过其中两个已知数计算出另一个的强度

![三基色强度](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908135031.jpg)

#### 图像可视化

在对数值归一化之后，两个变量就可以代表色彩了，于是我们就通过 r' g' 这两个参数画图

于是画出了一个二维空间，x 轴是 r'，y 轴是 g' 那么我们就可以成功的在色彩科学上真正科学的描述一个颜色

我们可以把任何可见光通过图标的一个点的坐标来表示说明。

![图像可视化](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908135604.jpg)

###  XYZ Color Specification System
上文的 CIE1931RGB 色彩系统已经不错了，但是存在负数，这在计算上非常的麻烦，比如写个乘法，得先计算是正数还是负数。

于是人们就用数学的方式做了一个新的色彩空间。所以 XYZ 色彩空间就是一个中转站，主要目的就是简化计算。

![XYZ Color Specification System](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908135940.jpg)

![XYZ Color Specification System](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/f560ba10-1d3f-4035-bbfb-bb80254a89c7.gif)

#### 如何转换
因为是空间转换所以我们用矩阵的方式进行

$$
\begin{bmatrix}
X \\
Y \\
Z
\end{bmatrix}=
\begin{bmatrix}
2.7689 & 1.7517 & 1.1302 \\
1.0000 & 4.5907 & 0.0601 \\
0.0000 & 0.0565 & 5.5943
\end{bmatrix}
\begin{bmatrix}
R \\
G \\
B
\end{bmatrix}
$$

注： 这里的 RGB 是 CIE 1931RGB 不是 sRGB 中的 RGB 数值。

这个 xyz 矩阵也不太美，于是人们为了计算方便有把xyz矩阵进行了归一化： 
$x = \frac{X}{X+Y+Z}$
$y = \frac{Y}{X+Y+Z}$
$z = \frac{Z}{X+Y+Z} = 1-x-y$

#### 最终效果
那么最终效果就是这张大家应该会比较熟悉的图， 人称**色域马蹄图**

也就是人眼可见范围表示， 但是我们发现图像上面好像没有亮度于是我们就在归一化的基础上，把 XYZ 中的 Y 单独拿出来与 xy 一起组成了 Yxy 色彩空间，其中的 Y 表示亮度 xy 表示色度。

注：这里提一下 这里是 Yxy 色彩空间 Yxy 是由 XYZ 色彩空间衍生

![色域马蹄图](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908202648.jpg)

![0ba21eb7-7d78-45ee-bb32-1267c158dca6](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/0ba21eb7-7d78-45ee-bb32-1267c158dca6.gif)

#### 不足与补充
上述的XYZ色彩空间也不错，但是也有问题，就是色彩的分布不均匀，他们的分布色彩一些地方紧一些地方又很松，举个例子这个图的偏向绿色部分就非常平滑，然后左下角部分坐标变化小，但是色彩变化就很快。

于是我们得想办法再去搞个更不错的色彩空间 gkd gkd

## 1.4 色彩空间的定义

色彩空间至少需要满足三项重要指标：
1. 色域 （三个基色的坐标，由此形成三角形）
2. Gamma （如何对三角形内进行切分）
3. 白点 （色域三角形中心）

![色彩空间](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908205452.jpg)

### Gamma

Gamma 并不是色彩空间，它其实只是如何对色彩进行采样的一种方式

每次对比顶点切割，就会发现切割的方式不同会导致每次对应的色彩不一样，大家通常理解的 Gamma=1 的情况就是指代这样均匀的切分，这样的好处就是方便计算。
而非均匀切割的方式就是 Gamma≠1

![Gamma](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908213713.jpg)


比如我们有个常用的空间 sRGB，那么 sRGB 的构成：
1. 色域： sRGB 首先设定了 RGB 三个基色的坐标
2. 白点： sRGB 也规定了白点位置
3. gamma： sRGB 的 gamma 设定为≈2.2（上右图）也就是说从外而向内切，先切的很细，然后逐渐变粗

大家知道线性的好处 (也就是 gamma=1 的时候)，方便计算，计算机效率高，方便理解，但是计算机储存（不需要花费很多空间去存储亮的区域）与显示器硬件因为早期的性能问题，采用的基本大部分都是 gamma≈2.2 的情况，但是我们目前大部分的机器都已经不是远古版本了，所以 PC 上的大部分游戏都会推荐使用 Linear 线性空间

我们可以自定义色彩空间，换一个色域，换一个白点位置，换一个 gamma 值其实就是一个新的色彩空间了。

所以也可以存在 sRGB D65 linear 这类空间，所以任何色彩空间都可以是 linear 线性的（改 gamma 值就可以去确定），但 linear 本身并不是一个色彩空间，它只是一个 gamma 值

### 1.5 常用的色彩模型和色彩空间

* 色彩模型：使用一定规则描述（排列）颜色的方法
举例：RGB、CMYK、LAB
* 色彩空间：需要至少满足三个指标：色域、白点、gamma
举例：CIE XYZ、 Adobe RGB、 sRGB、Japan Color 2001 Uncoated、US web Coated（后两个是基于CMYK模型建立的）

![常用色彩模型和色彩空间](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908214717.jpg)


### 1.6 色彩空间转换

![色彩空间转换](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240908215113.jpg)


----------------------------------------------------------------------------------


# 2. 模型与材质

## 2.1 模型

### 图形渲染管线

![图形渲染管线](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240909193807.jpg)

### 模型的实现原理
点连接成线，线围成面，组成多边形，至此一个模型空间下的模型形成

![模型的实现原理](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240909194201.png)

### UV
UV 平铺在一个二维坐标系中，模型的每个顶点在三维空间和二维空间中都能一一对应，在二维坐标系中的顶点对应的位置就是顶点的纹理坐标，因此每个顶点都能利用纹理坐标获取到贴图所存储的信息

在建模软件中进行 UV 展开，UV 会放在一个横轴为 U，纵轴为 V，范围为（0~1）的二维坐标系中

### 一个模型包含的信息（以 obj 文件为例）
V：顶点坐标数据（模型空间中单个顶点的 XYZ 坐标）
VT：贴图坐标（水平方向是 U，垂直方向是 V，范围在 0~1 之间）
VN：顶点法线→会决定面的朝向
顶点色：单个顶点的 RGBA 通道颜色信息

![一个模型包含的信息](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240909195906.jpg)

### obj 格式与 fbx 格式的区别

![obj 格式与 fbx 格式的区别](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240909200605.jpg)

参考：https://www.cnblogs.com/kekec/p/12446200.html

## 2.2 材质
在现实世界里，每个物体会对光产生不同的反应：有些物体反射光的时候不会有太多的散射 (Scatter)，因而产生一个较小的高光点而有些物体则会散射很多，产生一个有着更大半径的高光点

![材质](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240909200905.jpg)

### 漫反射
漫反射是最容易模拟的模型。
最简单的 Lambertian 很简单粗暴的认为光线 均匀地反射出去
`Diffuse = BaseColor * LightColor * dot(LightDir, NormalDir)`

![漫反射](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240909201107.png)

### 镜面反射
镜面反射就是将入射光线根据表面法线进行反射，并且只有在反射方向有能量，其他方向能量均为 0
`Specular = LightColor * pow(dot(ReflectDir, ViewDir), x)`

![镜面反射](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240909201444.png)

### 折射
对于玻璃这种电介质，除了反射之外还有根据物体的折射率折射一部分光线进入物体之中反射和折射能量的多少是根据菲尼尔定律决定
```
ReflDir = refract(ViewDir, NormalDir, ration)
ReflColor =  texCUBE(skybox, ReflDir)
```

![折射](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240909201539.png)

### 粗糙镜面反射
法线偏移较小。反射依然集中在一个区域。形成有磨砂质感的金属表面。

![粗糙镜面反射](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240909201609.png)

### 粗糙镜面折射
毛玻璃效果

![粗糙镜面折射](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240909201639.png)

### 多层材质
涂了油漆的地板

![多层材质](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910104620.jpg)

### SSS 次表面散射
多发生在半透明的物体上，如玉石、牛奶、皮肤、蜡烛

光进入皮肤后照亮了毛细血管，因此在明暗交界处更容易看到反射出的红光

![SSS 次表面散射](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910104801.jpg)

### 多层皮肤模型
我们把皮肤看成三层：油脂层（微量、很薄），表皮层，真皮层
* 正是因为有油脂层，油脂层直接把光反射出去，所以皮肤上才会有高光产生
* 没有被反射的光通过折射进入子表面层，光进入这些层之后被部分吸收（获得颜色）和散射
* 再从皮肤中入射点附近的出射点射出
* 这个过程就产生了次表面散射的效果

![多层皮肤模型](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910105740.jpg)

### 改变材质表面
现实世界中不存在完美平滑的表面，因此需要对模型表面的法线进行扰动。
其中一个方法是使用法线贴图。
漫反射，高光，折射，都与法线有关，因此改变法线，就能改变其光照计算结果


## 2.3 模型数据在渲染中的作用

1. 顶点动画：在顶点着色器中，修改模型的顶点位置。进而达到模型运动的效果
2. 纹理动画：在片段着色器中，修改模型的 UV 信息，使得采样贴图时，发生位移而产生运动效果
3. 顶点色：在渲染时，影响输出结果。控制颜色范围

### 纹理动画

在片段着色器中，修改模型的 UV 信息，使得采样贴图时，发生位移而产生运动效果。

UV 坐标动画或 UV 平移的含义是：水平（U）和/或垂直（V）移动纹理的 UV 坐标，以产生复杂动画的错觉。

#### 原理1：利用法线贴图，改变反射与折射的朝向

修改前，使用 1 这个法线，反射出去的就是 1 
修改后，使用 2 这个法线，反射出去的就是 2 
修改的只是法线信息，因此其他数据还是保持修改之前的样子

<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910111137.jpg" alt="改变法线，反射也跟着改变" width="400"/>

#### 原理2：改变UV采样点的位置，产生动画效果

<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910111404.jpg" alt="UV 平移" width="800"/>


### 顶点动画

顶点动画就是在顶点着色器中对纹理的顶点进行进行操作进而产生动画效果。

顶点着色器计算的是模型的每一个顶点，每个顶点的数据是不同的，因此同一个计算公式在不同的顶点上，计算出来的结果也是不同的

在一些三维建模软件中 ，动画的K帧也是一种顶点动画

#### 原理
顶点动画需要一定数量的顶点，效果才会比较明显

一个顶点传入一个顶点着色器，顶点着色器控制顶点位置时所有的顶点都会进行一样的算法。
获取顶点 UV 坐标，控制移动的数值大小 (UV 范围0-1)


### 顶点色
因四边面本质上还是三角面组合而成，所以在绘制时会出现三角形的分界
`FragColor =  FinalColor * VertexColor; `

![绘制顶点色](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910172114.jpg)

#### 原理：通过重心坐标插值计算

**重心坐标**

$(x,y) = \alpha A + \beta B + \gamma C = \alpha + \beta + \gamma = 1$

$\alpha = \frac {-(x - x_B)(y_C - y_B) + (y - y_B)(x_C - x_B)} {-(x_A - x_B)(y_C - y_B) + (y_A - y_B)(x_C - x_B)}$

$\beta = \frac {-(x - x_C)(y_A - y_C) + (y - y_C)(x_A - x_C)} {-(x_B - x_C)(y_A - y_C) + (y_B - y_C)(x_A - x_C)}$

$\gamma = 1 - \alpha - \beta$

<img src="https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910173331.jpg" alt="重心坐标" width="500"/>

插值操作是在光栅化阶段进行的。所以这些 XY 坐标可以理解为屏幕坐标。
点 D 的真实坐标为 (x,y)，重心坐标为 (α,β,γ) 该点是三个顶点直角坐标的线性组合系数之和为1 每个系数都是非负的

#### 重心坐标颜色插值

![重心坐标颜色插值](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910173744.jpg)


### 顶点法线和面法线

![顶点法线和面法线](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910173944.jpg)

效果：
![顶点法线和面法线效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910174139.jpg)

#### 原理：

* **面法线**：未使用平滑时，**三角形三个顶点共用一个法线**。 那么插值时，因为三个顶点的法线相同，所以**插值的结果相同**。
* **顶点法线**：使用平滑后，**一个顶点一个法线**。三角形三个顶点的法线也就不相同。**插值结果也就会不同**。

![顶点法线和面法线](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910174629.jpg)

#### 在模型文件内部存储方式

![在模型文件内部存储方式](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910174906.jpg)

#### 扩展
在 NPR 渲染中。通常在顶点着色器中，将顶点往法线方向偏移。然后再片段着色器中直接输出一个颜色，达到描边的效果。
BackFacing 描边时，线条之间断开就是因为没有使用顶点法线（没有进行平滑着色）

![描边](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240910175217.jpg)


-------------------------------------------------------------------------


# 3. HLSL 常用函数

* 官方文档：
https://learn.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-intrinsic-functions

* 一个实用的函数可视化网站：
https://graphtoy.com/


## 3.1 基本数学运算
 函数 | 说明 
 --- | --- 
 max(x,y)   | 返回 x 和 y 两者中较大的那个数
 min(x,y)   | 返回 x 和 y 两者中较小的那个数
 mul(x,y)   | 两变量相乘，常用于矩阵运算，如果 x 是向量，则被视为行向量；如果 y 是向量，则被视为列向量
 abs(x)     | 取绝对值  
 round(x)   | 返回与 x 最近的整数（四舍五入）
 sqrt(x)    | 返回 x 的平方根  
 rsqrt(x)   | 返回 x 的平方根的倒数  
 degrees(x) | 将弧度转换成角度  
 radians(x) | 将角度转换成弧度  
 noise(x)   | 根据传入的浮点型向量，返回基于一个 Perlin-noise 算法的范围在 -1~1 之间的噪波值  


## 3.2 幂指对函数
 函数 | 说明 
 --- | --- 
 pow(x,y)   | 返回 x 的 y 次幂（x 和 y 均可为常量或变量）  
 exp(x)     | 返回以 e 为底，x 为指数的幂，即 $e^x$ 
 exp2(value x) | 返回以 2 为底，x 为指数的幂，即 $2^x$ 
 ldexp(x,exp) | 返回 x 与 2 的 exp 次方的乘积，即 $x*2^{exp}$ 
 log(x)     | 返回指定值的以 e 为底的对数，即 $lnx$ 
 log10(x)   | 计算以 10 为底的对数，即 $log_{10}x$ 
 log2(x)    | 计算以 2 为底的对数，即 $log_{2}x$ 
 frexp(x,out exp) | 把浮点数 x 分解成尾数和指数， $x=ret*2^{exp}$ <br/> 函数返回值为尾数，exp 为指数（原始浮点数的二进制指数）<br/> 如果 x 参数为 0，则此函数的尾数和指数均返回 0 


## 3.3 三角函数与双曲函数
 函数 | 说明 
 --- | --- 
 asin(x)    | 返回输入值的反正弦值
 acos(x)    | 返回输入值的反余弦值
 atan(x)    | 返回输入值的反正切值
 atan2(y,x) | 返回 y/x 的反正切值
 sin(x)、cos(x)、tan(x)、tan(y/x)     | 正弦、余弦、正切、y/x 的正切
 sincos(x,out s,out c) | 返回 x 的正弦值和余弦值
 sinh(x)    | 返回 x 的双曲正弦值，即 $(e^x-e^{-x})/2$
 cosh(x)    | 返回 x 的双曲余弦值，即 $(e^x+e^{-x})/2$
 tanh(x)    | 返回 x 的双曲正切值，即 $(e^x-e^{-x})/(e^x+e^{-x})$


## 3.4 数据范围类
 函数 | 说明 
 --- | --- 
 ceil(x)    | 返回 >= x 的最小整数（向上取整）
 floor(x)   | 返回 <= x 的最大整数（向下取整）
 step(x,y)  | 如果 x <= y，返回 1（真），否则返回 0
 saturate(x)| 将 x 钳制到 [0,1] 范围之间
 clamp(x,min,max) | 将 x 限制在 [min,max] 范围的值，比 min 小返回 min，比 max 大返回 max
 fmod(x,y)  | 返回 x 对 y 取余的余数
 frac(x)    | 取 x 的小数部分
 modf(x,out ip) | 将 x 分为小数和整数部分（输出的 ip 为整数部分，返回值为小数部分）
 lerp(x,y,s) | 按照 s 在 x 到 y 之间插值，返回 $x*(1-s)+y*s$
 smoothstep(min,max,x) | 如果 x 在 [min,max] 范围内，就返回介于 [0,1] 之间的平滑 Hermite 插值，使用 smoothstep 在两个值直接创建平滑过渡 <br/> eg，平滑地混合两种颜色


## 3.5 类型判断类
 函数 | 说明 
 --- | --- 
 all(x)     | 确定指定量的所有分量是否均为非零，均非零则返回 true，否则返回 false（处理由浮点型、整型、布尔型数据定义的标量、向量或者矩阵）
 clip(x)    | 如果输入值小于零，则丢弃当前像素 常用于判定范围(不仅仅针对 0,返回值为 void) <br/> 常用于 Alpha Test，如果每个分量代表到平面的距离，还可以用来模拟剪切平面
 sign(x)    | 返回 x 的正负性 <br/> 如果 x < 0，返回 -1 <br/> 如果 x = 0，返回 0 <br/> 如果 x > 0，返回 1
 isinf(x)   | 如果 x 参数为 + INF 或 - INF（无穷 + 无穷仍无穷，0x3f3f3f3f），返回 true，否则返回 false
 isfinite(x)| 判断 x 参数是有限的，即有界的，与 isinf(x) 相反
 isnan(x)   | 如果 x 参数为 NAN（非数字），返回 true，否则返回 false


## 3.6 向量和矩阵类
 函数 | 说明 
 --- | --- 
 length(v)  | 返回向量的长度
 normalize(v) | 向量归一化，x/length(x)    方向向量归一化
 distance(a,b) | 返回两个向量之间的距离，不平行的两个向量应该为 0，此处表示为根号下各分量之差的平方和
 dot(a,b)    | 点积
 cross(a,b)  | 叉积
 determinant(m) | 返回指定浮点矩阵的按行列式方式计算的值
 transpose(m) | 返回矩阵 m 的转置矩阵


## 3.7 光线运算类
 函数 | 说明 
 --- | --- 
 reflect(i,n) | 以 i 为入射向量 n 为法线方向的反射光
 refract(i,n,ri) | 以 i 为入射向量 n 为法线方向, ri 为折射率的折射光
 lit(n_dot_l,n_dot_h,m) | 输入标量 (normal,light,半角向量 h,镜面反射系数 m) <br/> 返回光照向量 (环境光，漫反射光，镜面高光反射，1)
 faceforward(n,i,ng) | 得到面向视图方向的曲面法向量，输入输出为同元向量，返回 `-n * sign(dot(i,ng)) (normal,light,normal)`


## 3.8 纹理查找
* 所有的纹理查找函数都可以分为三类：普通的、微分的、投影的

**偏导函数ddx ddy（微分类）**
* 如果函数 ddx 的参数为 myVar，该参数对应的像素点记为 p(i, j)，则 ddx(myVar)  的值为：像素点 p(i+1, j) 的值减去myVar（ddy同理）
* 如果函数 ddx 和 ddy 的输入参数为常数，则函数返回值永远为 0。
* 1.函数 ddx 和 ddy 用于求取相邻像素间某属性的差值；
* 2.函数 ddx 和 ddy 的输入参数通常是纹理坐标；
* 3.函数 ddx 和 ddy 返回相邻像素键的属性差值；偏导数的物理含义是：在某一个方向上的变化快慢。
  * 所以 ddx 求的是 X 方向上，相邻两个像素的某属性值的变化量
  * ddy 求的是 Y方向上，相邻两个像素的某属性值的变化量
* 由于 ddx 和 ddy 指令是作用于像素级的，所以 ddx 和 ddy 函数只被片段程序所支持
* mipmap在选择到底用哪一层mipmap的level时，靠的就是偏导数。

**投影类**
* 投影纹理是指：将纹理当做一张幻灯片投影到场景中，使用投影纹理技术需要计算投影纹理坐标，然后使用投影纹理坐标进行查询。使用投影纹理坐标进行查询的函数就是投影纹理查询函数。

**Mipmap类**
* lod    采样一张mipmap
* bias    偏置后再采样（由t，w决定）
* grad    使用微分来选择mip的层，进行采样

### 1D 纹理查找（几乎不用）
GPU 在 PS 阶段是在屏幕空间 XY 坐标系中对每一个像素去对应的纹理中查找对应的纹素来确定像素的颜色

 函数 | 说明 
 --- | --- 
 tex1D (s, t)    | 普通一维纹理查找 返回纹理采样器 s 在标量 t 位置的 color4
 tex1D (s,t,ddx,ddy) | 使用微分查询一维纹理 t 和 ddxy 均为 vector
 tex1Dlod (s, t) | 使用 LOD 查找纹理 s 在 t.w 位置的 color4
 tex1Dbias (s, t)    | 将 t.w 决定的某个 MIP 层偏置后的一维纹理查找
 tex1Dgrad (s,t,ddx,ddy) | 使用微分并指定 MIP 层的一维纹理查找
 tex1Dproj (s, t)    | 把纹理当做一张幻灯片投影到场景中，先使用投影纹理技术需要计算出投影纹理坐标 t (坐标 t.w 除以透视值)，然后使用投影纹理坐标进行查询


### 2D 纹理查找
函数 | 说明 
--- | --- 
tex2D (s, t)    | 普通二维纹理查找 返回纹理采样器 s 在 vector t 位置的颜色
tex2D (s,t,ddx,ddy) | 使用微分查询二维纹理 t 和 ddxy 均为 vector（只有小于 ddxy 的值才会采样）
tex2Dlod (s, t) | 使用 LOD 查找纹理 s 在 t.w 位置的 color4
tex2Dbias (s, t)    | 将 t.w 决定的某个 MIP 层偏置后的二维纹理查找
tex2Dgrad (s,t,ddx,ddy) | 使用微分并指定 MIP 层的二维纹理查找
tex2Dproj (s, t)    | 把纹理当做一张幻灯片投影到场景中，先使用投影纹理技术需要计算出投影纹理坐标 t (坐标 t.w 除以透视值)，然后使用投影纹理坐标进行查询


### 3D 纹理查找
函数 | 说明 
--- | --- 
tex3D (s, t)    | 普通三维纹理查找 返回纹理采样器 s 在 vector t 位置的颜色
tex3D (s,t,ddx,ddy) | 使用微分查询三维纹理 t 和 ddxy 均为 vector
tex3Dlod (s, t) | 使用 LOD 查找纹理 s 在 t.w 位置的 color4
tex3Dbias (s, t)    | 将 t.w 决定的某个 MIP 层偏置后的三维纹理查找 
tex3Dgrad (s,t,ddx,ddy) | 使用微分并指定 MIP 层的三维纹理查找
tex3Dproj (s, t)    | 把纹理当做一张幻灯片投影到场景中，先使用投影纹理技术需要计算出投影纹理坐标 t (坐标 t.w 除以透视值)，然后使用投影纹理坐标进行查询


### 立体纹理查找
函数 | 说明 
--- | --- 
texCUBE (s,t)   | 返回纹理采样器 s 在 vector t 位置的颜色
texCUBE (s,t,ddx,ddy)   | 使用微分查询立方体维纹理 t 和 ddxy 均为 vector
texCUBEDload (s,t)  | 使用 LOD 查找纹理 s 在 t.w 位置的 color4
texCUBEbias (s,t)   | 将 t.w 决定的某个 MIP 层偏置后的立方体纹理查找
texCUBEgrad (s,t,ddx,ddy)   | 使用微分并指定 MIP 层的立方体纹理查找
texCUBEproj (s,t)   | 使用投影方式的立方体纹理查找


--------------------------------------------------------------------


# 4. 传统经验光照模型

## 4.1 光照模型 illumination model
是一种模拟自然界光照的物理过程的一种计算机模型，即光线与空间中物体表面的交互模型，大致分为两类：
1. 基于物理的光照模型（PBR）（有可依据的公式）
2. 经验模型（进行了一些近似、模拟，所以会不准）

#### 为什么需要光照模型
现实世界光照复杂，使用简化的光照模型对现实世界的光照情况进行模拟

#### 光照模型的发展

![光照模型的发展](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240911205159.jpg)


## 4.2 局部光照模型

### 局部光照的定义
* 只考虑光源的影响，不考虑光线多次反射
* （对应的概念：全局光照=直接光照+间接光照）

![局部和全局光照模型](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240911211456.jpg)

局部光照模型满足叠加原理，可以基本将光线分为四个部分

![局部光照模型](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240911214055.jpg)

### 局部光照模型的组成

局部光照模型满足叠加原理，可以基本将光线分为四个部分：
* 漫反射
* 高光反射
* 环境光
* 自发光

#### 漫反射
* 光线均匀被反射到各个方向
* 漫反射过程中，光线发生了吸收和散射，因此改变颜色和方向
* 漫反射只与光源和表面法线有关

使用 Lambert 余弦定理计算：

![Lambert 余弦定理](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240911212028.jpg)

#### 高光反射
* 描述了光线与物体表面发生的反射（光强不变，方向改变）
* 反射率根据菲涅尔效应决定
* Gloss 影响了高光反射的范围，但高光的亮度是不变的
* 高光反射与观察方向有关

![高光反射](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240911212930.jpg)

#### 环境光

![环境光](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240911213644.jpg)

#### 自发光：物体自身发出的光
物体自身发射的光线，通常作为单独的一项加入光照模型一般使用一张发光贴图描述物体的自发光


## 4.3 经典光照模型

### Lambert 模型
只计算漫反射，没有高光效果
`color = C_light * albedo * dot(normal, light);`

### Phong 模型
`Phong = Ambient + Diffuse + Specular`

使用环境光来模拟间接光照
加上了高光反射（使用反射光线方向和视线方向进行计算）

![Phong 模型](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240911215227.jpg)

### Blinn-Phong 模型
在计算高光反射时，用的是半角向量和法线向量

![Blinn-Phong 模型](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240911215524.jpg)

### Phong 和 Blinn-Phone 模型的区别
Blinn-Phong 模型使用了半角向量与法线的点积代替了反射向量与视线的点积结果。

半角向量的使用带来的变化：
1. 计算更简洁（计算半角向量比计算反射向量更简洁）
2. 半角向量与法线的角度永远不会大于90度（但是反射光线与视线方向的角度会大于90度，导致点乘计算的值钳制在0，出现明显的边缘效果）

![Phong 和 Blinn-Phone 模型的区别](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240911221342.jpg)

### Gourand 模型

* 逐顶点计算
* 镜面高光效果差

![Gourand 模型](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240911221801.jpg)

### Flat 模型

![Flat 模型](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240911222040.jpg)

### 光照模型展示
总结：
* Lambert 模型只考虑表面的漫反射部分
* Phong 模型能够较好的呈现镜面高光的效果，也是四种模型中最接近真实的效果，需要计算较复杂的反射向量
* Blinn-Phong 模型效果与 Phong 模型相近，更偏向艺术性的效果，使用方便计算的半程向量代替较为复杂的反射向量，计算量小于Phong，是效果和效率的最佳选择，也是大多数情况下的默认光照模型
* Gourand 模型计算顶点光照并通过增量法插值计算多边形内部的光强，当顶点密度低时，表现效果很差，对于高光的效果也不尽如意，计算量较小

![光照模型展示](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240911223020.jpg)


-----------------------------------------------------------------


# 5. Gamma 校正

## 5.1 Gamma 校正

### 颜色空间

* 通用：sRGB
* 电影：DCI-P3
* 电视：Rec-709、PAL等
* 印刷：CMYK、Adobe RGB
* 其他

![颜色空间](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/56d2fbac-7cec-48d2-84d4-7bb82e1081ba.jpg)

sRGB 和 Rec-709 能表达的颜色空间范围是差不多的，他的三原色位置是差不多的。它们之间的区别就在于传递函数不同

### 传递函数
把颜色显示到一个电子设备上时，需要把颜色转换成一个视频信号，这时候就需要一个传递函数

一个传递函数分为两部分：
* OETF：光转电传递函数，负责把场景线性光转到非线性视频信号值
* EOTF：电转光传递函数，负责把非线性视频信号值转换成显示光亮度

![传递函数](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922193715.jpg)

### Gamma校正
简单定义：
* $V_{out} = V_{in}^{gamma}$
* **Gamma 是指对线性三色值和非线性视频信号之间进行编码和解码的操作。**
就比如说当相机拍摄到自然中的线性的光信号，传递到电脑中进行存储时，就需要进行一个 Gamma 的编码操作，获得非线性的视频信号；最后通过显示器显示时，又需要将非线性的视频信号还原回一个线性的光信号，这时就需要进行一个 Gamma 的解码操作，最后得到我们所见到的样子（线性的光信号）

![Gamma校正](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/10ef75d8-3fb0-4eb4-83a9-8f6e2cdad18b.jpg)

Gamma 矫正的实例：简单理解为就是线性显示、非线性存储。

![Gamma 校正实例](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922195154.jpg)

* 图像经过 gamma 编码存储在硬盘中，将获取到的物理数据做一次 gamma 值约为 0.45 的映射，这样的过程叫做 gamma 编码。
由曲线可知，此时图像的像素比实际物理像素要更亮
* 在显示图像时，需要将每个像素做一次 gamma 值约为 2.2 的矫正，使最终的结果为正确的物理数据。
经过显示的 gamma 校正之后，之前偏亮的图像亮度降低 


#### 进行 Gamma 矫正的原因
这其实和人眼的特性有关，**人眼对暗部的变化要更加敏感一点**。如果要存储更多的有效信息，就需要更多的位置去存储暗部值，即在存储暗部时用更高精度的值去存储，而对于亮部则可以用相对精度较低的值去存储。

所以，非线性转换的目的主要是为了优化存储空间和带宽，传递函数能够更好地帮我们利用编码空间。


## 5.2 韦伯定律

![感知上的渐变和真实的渐变](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922195906.jpg)

![韦伯定律](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922200334.jpg)

**韦伯定律**：即感觉的差别阈限随原来刺激量的变化而变化，而且表现为一定的规律性，用公式来表示，就是 △Φ/Φ=C，其中 Φ 为原刺激量，△Φ 为此时的差别阈限，C 为常数，又称为韦柏率。

简单来说就是，当所受刺激越大时，需要增加的刺激也要足够大才会让人感觉到明显变化，但是只适用于中等强度的刺激

### 小结
1. 人眼对暗部变化比亮部更加敏感
2. 我们目前所使用的真彩格式 RGBA32，每个颜色通道只有8位用于记录信息，为了合理使用带宽和存储空间，需要进行非线性转换。
3. 目前我们所普遍使用的 sRGB 颜色空间标准，他的传递函数 gamma 值为 2.2(2.4)


### CRT
早期我们使用的图像显示器都是CRT（学名:阴极射线显像管），人们发现这种设备的亮度与电压并不成线性关系，而是 gamma 值约为 2.2 类似幂律的关系。 

![CRT](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922201139.jpg)

#### CRT与转换函数
1. CRT非线性响应的历史原因
2. 人眼对暗部颜色变化更加敏感

![CRT与转换函数](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922201237.jpg)


### 中灰值
**中灰值并非一个明确的值，而是取决于实际的视觉感受**

![纯灰色的条看上去左右部分明暗不同](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922201659.jpg)

![20240922201753](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922201753.jpg)



## 5.3 线性工作流
* 线性工作流就是在生产的各个环节中，正确使用 gamma 编码和 gamma 解码，使得最终得到的颜色数据与最初输入的物理数据保持一致
* 如果使用 Gamma 空间的贴图，在传给着色器前需要从 Gamma 空间转到线性空间，以确保获得正确的计算结果

如果不在线性空间下进行渲染工作：
Gamma 空间中进行亮度计算时，会容易过曝：因为光线信息在经过 Gamma 编码后，他的值比实际上的要大

![Gamma 空间中进行亮度计算容易过曝](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922203151.jpg)

进行颜色混合时，也会让亮度过高，出现 “黑边” 

![颜色重叠区域出现 “黑边”](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922203316.jpg)

进行光照渲染时，如果把中灰色以 0.5 作为实际的物理光强进行计算的话，就会出现如下左图的情况；但是实际上中灰色的物理光强度应该是 0.18

![20240922203803](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922203803.jpg)



## 5.4 Unity 中的颜色空间
通过点击菜单 Edit -> Project Settings -> Player 页签 -> Other Settings 下的 Rendering 部分进行修改，参数 Color Space 可以选择 Gamma 或 Linear

![Unity 中的颜色空间](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922203954.png)

* 当选择 Gamma Space 时，Unity 不会做任何处理
* 当选择 Linear Space 时，引擎的渲染流程在线性空间计算，理想情况下项目使用线性空间的贴图颜色，不需要勾选 sRGB，如果勾选了 sRGB 的贴图，会通过硬件特性采样时进行线性转换。


#### 硬件支持
线性空间需要图形 API 的硬件支持，目前支持的平台有：
1. Windows，Mac OS x 和 Linux
2. Xbox One
3. PS4（新的 PS5 肯定支持）
4. Android
5. IOS
6. WebGL（新的 WebGPU 肯定支持）

#### 硬件特性支持
主要由两个硬件特性来支持：
* sRGB Frame Buffer
    * 将 shader 的计算结果输出到显示器前进行 Gamma 矫正
    * 作为纹理被读取时自动会把存储的颜色从 sRGB 空间转换到线性空间
    * 调用 ReadPixels ()、ReadBackImage () 时，会直接返回 sRGB 空间下的颜色
    * sRGB Frame Buffer 只支持每通道为 8bit 的格式，不支持浮点格式
    * HDR 开启后会先把渲染结果绘制到浮点格式的 Frame Buffer 中，最后绘制到 sRGB Frame Buffer 上输出
* sRGB Sampler
    * 将 sRGB 的贴图进行线性采样的转换

使用硬件特性完成 sRGB 贴图的线性采样和 shader 计算结果的 gamma 矫正，比起在 shader 里对贴图采样和计算结果的矫正要快

## 5.5 资源导出问题

### SP 贴图导出
SP 贴图导出时，线性的颜色值经过了 gamma 变换，颜色被提亮了，所以在 unity 中需要勾选 sRGB 选项，让他在采样时能还原回线性值。

![SP 贴图导出](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922204852.jpg)

### PhotoShop
如果使用线性空间，一般来说 PS 可以什么都不改，导出的贴图只要勾上 sRGB 即可
如果调整 PS 的 gamma 值为 1，导出的贴图在 unity 中也不需要勾选 sRGB 了

![PhotoShop 导出](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922205104.jpg)

* PS 对颜色管理特别精准，Unity 中看到的颜色要经过显示器的 gamma 变换，而 PS 不会，PS 会读取显示器的 Color Profile，反向补偿回去。所以 PS 里使用的是一个真实的颜色值
* PS 有第二个 Color Profile（Document Color Profile）。通常它的默认值就是 sRGB Color Profile，和显示器的 Color Profile 一致，颜色是被这个 Color Profile 压暗了，所以 PS 中看到的结果才和 Unity 的一样（通过一个灰度值来控制颜色的显示，并且这个灰度值和显示器的 gamma 值一致，让我们看着和 unity 一样）

#### 半透明混合
Unity 在进行半透明混合时，会先将它们转换到一个线性空间下，然后再进行混合。但是 PS 中，图层和图层之间做混合的时候，每个上层的图层都会读取他们的 Color Profile，经过一个 Gamma 变换，再做混合，得到的结果就会偏暗一些。

![半透明混合](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240922205515.jpg)


### Unity 中的颜色空间转换函数
Unity CG.cginc 文件中封装的函数
其中，带有 Exact 后缀的的函数计算精确，但消耗高；不带有 Exact 后缀的函数是一种近似解法

``` glsl
inline float GammaToLinearSpaceExact (float value)
{
    if (value <= 0.04045F)
        return value / 12.92F;
    else if (value < 1.0F)
        return pow((value + 0.055F)/1.055F, 2.4F);
    else
        return pow(value, 2.2F);
}

inline half3 GammaToLinearSpace (half3 sRGB)
{
    // Approximate version from http://chilliant.blogspot.com.au/2012/08/srgb-approximations-for-hlsl.html?m=1
    return sRGB * (sRGB * (sRGB * 0.305306011h + 0.682171111h) + 0.012522878h);

    // Precise version, useful for debugging.
    //return half3(GammaToLinearSpaceExact(sRGB.r), GammaToLinearSpaceExact(sRGB.g), GammaToLinearSpaceExact(sRGB.b));
}

inline float LinearToGammaSpaceExact (float value)
{
    if (value <= 0.0F)
        return 0.0F;
    else if (value <= 0.0031308F)
        return 12.92F * value;
    else if (value < 1.0F)
        return 1.055F * pow(value, 0.4166667F) - 0.055F;
    else
        return pow(value, 0.45454545F);
}

inline half3 LinearToGammaSpace (half3 linRGB)
{
    linRGB = max(linRGB, half3(0.h, 0.h, 0.h));
    // An almost-perfect approximation from http://chilliant.blogspot.com.au/2012/08/srgb-approximations-for-hlsl.html?m=1
    return max(1.055h * pow(linRGB, 0.416666667h) - 0.055h, 0.h);

    // Exact version, useful for debugging.
    //return half3(LinearToGammaSpaceExact(linRGB.r), LinearToGammaSpaceExact(linRGB.g), LinearToGammaSpaceExact(linRGB.b));
}
```


---------------------------------------------------------------


# 6. LDR 与 HDR

## 6.1 基本概念
* HDR：High Dynamic Range
* LDR：Low Dynamic Range

动态范围 = 最高亮度 / 最低亮度
将场景中高动态范围的光线信息，转换到显示设备上可显示出来的低动态范围的视频信息，这一过程被称为色调映射（Tone Mapping）

Tips：电脑显示器的最高亮度是由之前经验积累下来的一个，让人眼舒适的，相对统一的亮度。

### LDR
* 通常 LDR 的精度范围是 8 位（2 的 8 次方）
* 0-1 的单通道
* 常用的存储格式为 jpg、png、tga
* 拾色器、一般的图片，电脑屏幕都是 LDR

![拾色器](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240923104735.jpg)

### HDR
* 远高于 8 位的精度
* 单通道的最大值可超过 1
* 常用 HDR 图片存储格式有 hdr、tif、exr、raw
* HDRI、真实世界的光都是 HRD

### 相机记录信息的过程
* 首先，将曝光值进行计算，将曝光值重新映射回相机能够感应的范围内（受到光圈、快门时间，以及传感器灵敏度等的影响）
* 再把值进行输出（线性），存储进数码相机的格式内
* 之后会经过一个线性变换（白平衡、色彩矫正、色调验色以及伽马矫正等这一系列过程），最终会得到一张 LUT 图
* 不同相机厂商 LUT 图的格式是不同的

### 为什么需要 HDR
* LDR 是对现实颜色进行压缩并且呈现出来，具有一定局限性，在进行后期效果调整和后续加工会因为颜色精度不够而难以进行
* HDR 有着更好的色彩，更高的动态范围和更丰富的细节，并且能够有效地防止画面过曝，亮度值超过 1 的颜色也能很好的表现出来。使得像素光亮度变得正常，视觉传达更加真实。

![HDR](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240923105416.jpg)

只有 HDR 才有超过 1 的数值，才有光晕（bloom）的效果, 高质量的 bloom 能体现画面的渲染品质。

![20240923105613](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240923105613.jpg)



## 6.2 在 Unity 中设置 HDR

#### Camera 的 HDR 选项
可以在 Project Setting - Graphics - Tier Settings 中设置是否开启 HDR。

![Camera 的 HDR 选项](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/TA100A2600-4.png)

![Graphics 设置](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240923110844.png)

Unity Camera 基本参数中有 HDR，如果开启的话，Unity 会将场景渲染到 HDR 图像缓冲区，下一步进行后处理，在 Tone mapping 过程中会把 HDR 转换成 LDR，再将 LDR 图像（R8G8B8）发送给显示器

```mermaid
graph LR
A[HDR 图像缓冲区] --> B[后处理] --> C[Tone Mapping] --> D[显示器]
```


#### Lightmap 的 HDR
在 Project Setting - Player - Other Settings 中，可以设置 Lightmap 的编码质量。
将 Lightmap 编码质量设置为 High Quality，将会为 Lightmap 开启 HDR 光照贴图的支持

![Lightmap 的 HDR](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240923112252.png)


#### 拾色器的 HDR
在 Shader 中在颜色属性前添加 `[HDR]` 标签，即可将颜色支持 HDR 。
* 使用 Intensity 滑动条可以调整颜色的强度
* 滑动条每增加 1，提供的光亮增加一倍

### 优缺点
优点：
* 画面中亮度超过 1 的部分不会被截为 1，增加亮部的细节并减少曝光
* 减少画面较暗部分的色阶感（用更大的精度去存储暗部）
* 更好的支持 Bloom 效果

缺点：
* 渲染流程中多了 Tone mapping 这一步，渲染速度慢
* 占据更多显存
* 不支持硬件抗锯齿
* 低端手机不支持 HDR


## 6.3 Bloom
Bloom 流程：渲染出原图后，提取原图中较亮的部分，对提取出来的图片进行高斯模糊，然后再叠加到原图上

![Bloom](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240923115247.jpg)

Unity 中的 Bloom 流程：

![Unity Bloom 流程](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240923115514.jpg)


## 6.4 HDR 与 Tone Mapping

### Tone Mapping 的概念
* 色调映射
* 将 HDR 转化为 LDR
* 如果是线性映射的话效果极差
* 所以一般使用曲线，把亮度区域和阴影区域向中等亮度方向压缩 → S 曲线

![Tone Mapping](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240923115732.jpg)

### Tone Mapping 映射曲线
HDR 的 Tone Mapping 映射曲线会把暗部压得更低一些，亮部也往回缩一点，让整体效果看起来更加真实

![Tone Mapping 映射曲线](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240923121821.png)


#### ACES 映射曲线
* Academy Color Encoding System 学院颜色编码系统
* 最流行、最被广泛使用的 Tonemapping 映射曲线
* 效果：对比度提高，很好地保留暗处和亮处的细节

![ACES 映射曲线](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240923122022.png)


#### 其他类型的Tonemapping曲线

![其他类型的Tonemapping曲线](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240923130059.png)


## 6.5 LUT （Look-Up Table）
LUT （颜色查找表），是一种颜色校正技术，它可以将一组颜色映射到另一组颜色上，用于颜色校正。可以理解为滤镜。

与 Tone mapping 不同的是，LUT 是对 LDR 图进行处理，而 Tone mapping 则是处理 HDR 图

可以调整 RGB 三个通道的 LUT 被称为 3D LUT。
格式有：3DL, CUBE, CSP, ICC 配置文件。

> Tips：可以在 PS 中调整 LUT，导出的 LUT 作为滤镜去调整画面（相当于整个画面的滤镜）

LUT 的效果比较：

![LUT 的效果比较](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240923133215.png)


-------------------------------------------------------------------


# 7. Bump Mapping

## 7.1 Bump Mapping 介绍

### 表达物体细节的三个尺度
* 宏观尺度
    * 覆盖很多个像素
    * 由顶点或三角形或其他的图元来表示的，建模通常就是在宏观尺度上进行处理
* 中观尺度
    * 覆盖几个像素
    * 描述了宏观尺度和微观尺度之间的特征，细节比较复杂，没有办法使用单个三角形来进行渲染，但这些细节又足够大，能够让观察者看出其中的细节
    * 比如：皮肤的褶皱，肌肉组织的细节，砖块之间的缝隙等等。
* 微观尺度
    * 小于一个像素
    * 表现在着色模型中，而着色模型通常在像素着色器中实现。使用纹理贴图作为参数，模拟物体表面围观几何形状的相互作用
    * 比如：高光部分在微观尺度下是光滑的，漫反射部分在微观尺度下是粗糙的

### Bump Mapping 凹凸映射
* 凹凸映射就是模拟中观尺度的常用方法之一，它能让观察者感知到比几何模型的尺度更小的细节。
* 基本思想是将尺度细节相关的信息编码进纹理中，在着色过程中，我们用稍微受到干扰的表面去模拟真实的表面，从而模拟出表面的小尺度的细节。
* 从原理上讲，凹凸贴图映射技术是对物体表面贴图进行变化，然后再进行光照计算的一种技术。例如给法线分量增加噪音，或者在一个保持扰动值的纹理图中进行查找（视差映射贴图，或者浮雕贴图）
* 这是一种提升物体真实感的有效方法，但却不需要额外的提升物体的几何复杂度（不需要添加额外的顶点）。这种方式在提升物体的表面细节或者表面的不规则性方面有显著效果。

![Bump Mapping](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240925104108.jpg)


### 凹凸映射的分类
* Bump Mapping 的种类主要有：法线映射、视差映射、浮雕映射
* 用处广泛，可以用来增加模型细节效果，或者做一些特殊的画面表现效果
* 最常用的是法线映射，一般的增加法线贴图后，会对局部的物体表面进行法线扰动，进而改变明暗关系，从而达到增加表面细节的效果。
* 上述的三种映射都会用到法线贴图

![Bump Mapping 分类](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240925122526.jpg)


## 7.2 Normal Mapping 法线映射

### 法线贴图
* Normal Map 是一张存有物体局部表面法线信息的一张贴图。在计算光照的时候，程序会去读取法线图，并获取到当前像素点的法线信息，结合光线信息进行光照计算。
* 使用法线贴图计算光照，可以让物体表现出更加丰富的细节（小范围的明暗变化），并随着光照方向的变换实时变化。
* 法线贴图一般由高模映射到对应的底模上来生成。但像金属，木头等这些细节丰富的物体，可借助程序化的软件如：Photo Shop，Substance Designer 等生成

![法线贴图](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/3bc8bb17-1853-4aa3-8b4e-57dc073072db.png)


###  切线空间
* 法线的存储，一般会放到模型的切线空间中。
* 切线空间是以物体表面的切线，副切线和法线组成的几何空间
* 切线空间中，坐标原点为顶点位置，顶点法线 **n** 作为 z 轴，切线 **t** 和纹理坐标系一致，副切线 **b** 则由顶点法线和切线叉乘得到
* **计算光照时，需要把光照运算的向量放到统一坐标系下**。读取切线空间法线，需要世界坐标转切线空间的转换矩阵 或 切线空间转世界空间的转换矩阵，将向量统一到同一坐标系后再进行光照操作。

![切线空间](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240925123559.png)


### 世界空间和切线空间的转换 —— TBN矩阵
将世界坐标系下的顶点法线（Normal）和切线（Tangent）以及副切线（Bitangent）作为切线空间坐标系的正交基。并用这三个向量的标准正交基来构建转换矩阵。对应关系为法线作为Z轴，切线作为X轴，副切线作为Y轴。

构建一个3*3的矩阵来做空间向量的坐标系转换。一般的叫该矩阵为 **TBN 矩阵**。

#### 切线空间 → 世界空间
在Unity中，将读取到的切线空间的法线信息右乘TBN矩阵，即可将法线从切线空间转换到世界空间

``` hlsl
float3x3 TBN = float3x3(i.tangentDir, i.biTangentDir, i.normalDir)
float3 worldNormal = normalize(mul(localNormal, TBN));
```

#### 世界空间 → 切线空间
* 因为 TBN 矩阵是一个正交矩阵，所以 TBN 矩阵的逆矩阵就是 TBN 的转置矩阵
* 从世界空间转换到法线空间进行相关处理，只需要顶点右乘 TBN 矩阵的转置矩阵即可

$$
TBN = 
\begin{bmatrix}
T_x & B_x & N_x \\
T_y & B_y & N_y \\
T_z & B_z & N_z \\
\end{bmatrix}
$$

$$
TBN^{-1} = TBN^T = 
\begin{bmatrix}
T_x & T_y & T_z \\
B_x & B_y & B_z \\
N_x & N_y & N_z \\
\end{bmatrix}
$$

### 引入切线空间的好处
实际上法线存在哪个空间下都是可以的，但是实际上我们不仅仅要存储法线信息，更重要的是后续的光照计算。选择哪个坐标系意味着我们需要把光照计算用到的不同信息全部转换到对应的坐标系中。但是，使用切线空间存储法线带来的收益高过空间转换的成本。

优点：
* 自由度高
    * 同一张法线可以作用于不同的模型
    * 如果把法线信息存在模型空间下，得到的则是一个绝对的法线信息，这个法线信息就只是属于一个模型的法线，比如说存到球的模型空间下，法线就无法用于圆环中
* 很方便实现 uv 动画
    * 法线在切线空间中，只是对现有现有法线的扰动。对贴图采样进行偏移时，就可以改动顶点 uv 实现不同的凹凸效果，进而实现 uv 动画。
* 基于同样的原理，可以重用法线贴图
    * 一个立方体一面的法线贴图可以同时用在其他五个面上
* 便于压缩
    * 在切线空间中，法线始终是垂直于表面向外。在归一化的法线向量中，他的值始终是处于0-1之间的，这样的话我们就只用存储副切线和切线，再用 sqrt 算出法线即可
    * 而在模型空间中，法线可以为负，在-1到1之间，这样就不能通过只存储两个值来推导出法线的值，必须要储存三个值（否则无法指明法线的方向，因为作为贴图的颜色通道，只能存0-1的值），这样就无法压缩了。


### Unity 中的法线贴图的压缩格式
* 在 unity 中，非移动平台上，Unity 会把法线贴图转换成 DXRT5nm 格式。这种格式只有两个有效通道 GA 通道，这样可以节省空间
* GA 存储对应法线的 y、x 分量，z 分量需要通过一个简单的运算求得。
* 而移动平台 Unity 使用传统的 RGB 通道

``` hlsl
// DXR5nm
real3 UnpackNormalAG(real4 packedNormal, real scale = 1.0)
{
    real3 normal;
    normal.xy = packedNormal.ag * 2.0 - 1.0;
    normal.z = max(1.0e-16,，sqrt(1.0 - saturate(dot(normal.xy，normal.xy))));
    
    // must scale after reconstruction of normal.z which also
    // mirrors UnpackNormalRGB(). This does imply normal is not returned
    // as a unit length vector but doesn't need it since it will get normalized after TBN transformation.
    // If we ever need to blend contributions with built-in shaders for URP
    // then we should consider using UnpackDerivativeNormalAG() instead like
    // HDRP does since derivatives do not use renormalization and unlike tangent space
    //normals allow you to blend,accumulate and scale contributions correctly.
    normal.xy *= scale;
    return normal;
}

// RGB
real3 UnpackNormalRGB(real4 packedNormal, real scale = 1.0)
{
    real3 normal;
    normal.xyz = packedNormal.rgb * 2.0 - 1.0;
    nromal.xy *= scale;
    return normal;
}
```


## 7.3 Parallax Mapping 视差映射

### 视差映射的概述

* 视差贴图Parallax Mapping，又称为 Offset Mapping，以及virtual displacement mapping)，于2001年由Kaneko引入，由Welsh进行了改进和推广
* 主要为了赋予模型表面遮挡关系的细节。引入了一张高度图
* 可以和法线贴图一起使用，来产生一些真实的效果
* 高度图一般视为顶点位移来使用，此时需要三角形足够多，模型足够精细，否则看起来会有块状
* 如果在有限的三角形面的情况下，怎么办？这就用到了视差映射技术
* 视差映射技术：
    * 核心：改变纹理坐标
    * 需要一张存储模型信息的高度图，利用模型表面高度信息来对纹理进行偏移（例如：低位置的信息被高位置的信息遮挡掉了，所以会采样更高的信息）

![视差映射](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240925133355.jpg)


### 视差映射的实现
* 和法线贴图一样，是欺骗眼睛的做法（只改变纹路，不增加三角形）
* 我们的模型在切线空间下，所有的点都位于切线和副切线组成的平面内（图中0.0点），但实际上物体要有更丰富的细节。例如图中的情况
    * 如果不使用视差贴图，要计算当前视角下，片元A点（黄色）的信息，就是图中的Ha
    * 实际使用视差贴图时，真实的情况应该是视线和A点延长线和物体的交点，也就是B点，相应的就是Hb

![视差映射](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240925134736.png)

**视差映射的具体算法**：如何在知道 A 的 uv 值的情况下，算出 B 的 uv 值
* 知道 AB 两者的偏移量即可
* 偏移量的获得：用近似的方法去求解	
    * 首先拿 A 的高度信息进行采样，得到物体表面距离水平面（0.0）的深度值Ha。
    * 用深度值 Ha 和视线的三角关系算出物体上等比的偏移方向，算出近似的 B 点（可以看到图中近似点 B 和实际点 B 还是有挺大差距的，所以模拟度比较低）
    * 得到偏移之后 B 点的 uv，再去对法线贴图进行采样、计算时，就不会采样 A 点了，而是 B 点

![视差映射](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240925135148.png)

`d = v.xy * ha * scale / v.z`
``` hlsl
float height = 1 - tex2D(_HeightMap, i.uv2.xy).r;
real3 viewDirTS = TransformWorldToTangent(viewDirWS.xyz, T2W);
float2 offset = viewDirTS.xy / viewDirTS.z * height * _HeightScale;
i.uv.xy += offset;
i.uv.zw += offset;
```

**理解**：视差贴图是如何产生遮挡效果的
* 当视线看到的是 A 点这样深度比较大的，那么视差贴图计算出的偏移值也是非常大的，这样 A 点最终被渲染出来的机会就比较小（偏移后就被采样到其他点上了）
* 当视线看到 B 点这样深度比较小的点，计算出来的偏移就比较下，甚至原来点的附近，所以被采样的机会就比较大
* 深度大的点很容易被深度小的点覆盖掉，这样就会表现出遮挡的效果 


### Steep Parallax Mapping 陡峭视差映射
陡峭视差映射也是一个近似的解，但相比于普通的视差映射要精确很多，效果上也更好，并且会对uv坐标进行合理性检查。

陡峭视差映射的基本思想是将深度分为等距的若干层，然后从最顶层进行采样，并且每次沿着视角方向偏移一定值，若当前层的深度大于采样出的深度，则停止检查并返回最后的结果。

![陡峭视差映射](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240925203056.png)


陡峭视差映射的算法：（计算偏移点的过程）
* 首先对A点采样，得到深度大约为0.8的位置，而其对应视线深度为0.0，不符合我们的基本思想，继续采样
* 采样B点，深度为1，视线深度为0.25，不符合，继续采样
* 采样C点，深度大约为0.8，视线深度为0.5，不符合，继续采样
* 采样D点，采样深度为0.5，视线深度约为0.75，符合上述的条件，认为是比较合理的一个偏移点，就返回结果（return）。

``` hlsl
//陡峭视差映射
float2 SteepParallaxMapping(float2 uv, real3 viewDirTS){
    float numLayers = 20.0;
    float layerHeight = 1.0 / numLayers;
    float currentLayerHeight = 0.0;
    float2 offlayerUV = viewDirTS.xy / viewDirTS.z *_HeightScale;
    float2 Stepping = offlayerUV / numLayers;
    float2 currentUV. = uv;
    float2 AddUV = float2(0, 0);
    float currentHeightMapValue = tex2D(_HeightMap, currentUV + AddUV).r;
    for (int i = 0; i < numLayers; i++)
    {
        if (currentLayerHeight > currentHeightMapValue){
            return AddUV;
        }
        AddUV += Stepping;
        currentHeightMapValue = tex2D(_HeightMap，currentUV + AddUuV).r;
        currentLayerHeight += layerHeight;
    }
    return AddUv;
}
```

陡峭视差映射的缺点：
问题在于他的分层机制，如果分的层数过多，步进次数会变多，那么性能开销就会比较大；如果分的层数太少，那么就会有明显的锯齿

优化：可以根据视线v和法线n的角度来做对采样层数的最大值和最小值的阈值的限定


## 7.4 Relief Mapping 浮雕映射

### 浮雕映射的概述
* 浮雕映射是陡峭视差映射的一个改良版本
* 浮雕映射相比于视差映射，能够更精确地计算uv偏移量，更容易提供更多的深度，还可以做自阴影以及闭塞效果

![浮雕映射](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240925204041.jpg)

####  浮雕映射的原理
浮雕映射一般先使用射线步进，再使用二分查找的方法来决定UV偏移量

为什么不直接使用二分查找呢：

![浮雕映射的实现](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240925204821.png)

``` hlsl
//浮雕贴图
float2 ReliefMapping(float2 uv, real3 viewDirTS)
{
    float2 offlayerUV = viewDirTS.xy / viewDirTS.z * _HeightScale;
    float RayNumber = 20;
    float layerHeight = 1.0 / RayNumber;
    float2 SteppingUV = offlayerUV / RayNumber;
    float offlayerUVL = length(offlayerUV);
    float currentLayerHeight = 0;
    
    float2 offuv= float2(0,0);
    for (int i = 0; i < RayNumber; i++)
    {
        offuv += SteppingUV;

        float currentHeight = tex2D(_HeightMap, uv + offuv).r;
        currentLayerHeight += layerHeight;
        if (currentHeight < currentLayerHeight)
        {
            break;
        }
    }

    float2 T0 = uv-SteppingUV, T1 = uv + offuv;

    for (int j = 0;j<20;j++)
    {
        float2 P0 = (T0 + T1) / 2;

        float P0Height = tex2D(_HeightMap, P0).r;

        float P0LayerHeight = length(P0) / offlayerUVL;

        if (P0Height < P0LayerHeight)
        {
            T0 = P0;

        }
        else
        {
            T1= P0;
        }

    }

    return (T0 + T1) / 2 - uv;
}
```

#### 视差闭塞贴图（POM = Parallax  Occlusion Mapping）
相对于浮雕贴图，不同之处在于最后一步
* 浮雕贴图是在确认最后步进之后进行二分查找（在迭代次数比较多的情况下，还是挺耗的）
* 视差闭塞贴图是在最后步进的两端uv值进行采样（下图红色箭头），采样之后再对这两个结果进行插值，插值的结果作为P点最终的偏移值

![视差闭塞贴图](https://raw.githubusercontent.com/Ineloquent0/notes/main/images/20240925205309.png)


优点：
* 相对于浮雕映射，性能更好（最后只做插值，而浮雕要做二分查找）
* 相对于陡视差贴图，精确性更好

要求：
* 因为最后要做插值，所以要求表面是相对比较平滑/连续的，如果有莫名的凸起结果可能会出错





