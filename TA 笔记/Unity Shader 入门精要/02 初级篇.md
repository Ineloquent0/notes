
# 第5章 开始 Unity Shader 学习之旅

## 5.1 本书使用的软件和环境
本书使用的Unity版本是Unity 5.2.1免费版。

本书工程编写的系统环境是Mac OS X 10.9.5。如果读者使用的是其他系统，绝大部分情况也不会有任何问题。但有时会由于图像编程接口的种类和版本不同而有一些差别，这是因为Mac使用的图像编程接口是基于OpenGL的，而其他平台如Windows，可能使用的是DirectX。例如，在OpenGL中，渲染纹理（Render Texture）的(0, 0)点是在左下角，而在DirectX中，(0, 0)点是在左上角。



## 5.2 一个最简单的顶点/片元着色器

### 5.2.1 顶点/片元着色器的基本结构

我们在 3.3 节已经看到了 Unity Shader 的基本结构。它包含了Shader、Properties、SubShader、Fallback 等语义块。顶点/片元着色器的结构与之大体类似，它的结构如下:

``` hlsl
Shader "MyShaderName" {

    Properties {
        // 属性
    }

    SubShader {
        // 针对显卡 A 的 SubShader
        Pass {
            // 设置渲染状态和标签

            // 开始 Cg 代码片段
            CGPROGRAM
            // 该代码片段的编译指令，例如：
            #pragma vertex vert
            #pragma fragment frag
            
            // Cg 代码写在这里

            ENDCG

            // 其他设置

        }
        //其他需要的 Pass
    }
    SubShader {
        // 针对显卡 B 的 SubShader
    }

    // 上述 SubShader 都失败后用于回调的 Unity Shader
    Fallback "VertexLit"
}
```

其中，最重要的部分是Pass语义块，我们绝大部分的代码都是写在这个语义块里面的。下面我们就来创建一个最简单的顶点/片元着色器：
1. 新建一个场景，把它命名为Scene_5_2。去掉天空盒，在菜单栏中选择 Window > Lighting > Skybox 把该项设置为None。(Unity 2023 是 Window > Rendering > Lighting > Environment > Skybox Material)
2. 新建一个 Unity Shader，把它命名为 Chapter5-SimpleShader。
3. 新建一个材质，把它命名为 SimpleShaderMat。把第2步中新建的 Unity Shader 赋给它。
4. 新建一个球体，拖曳它的位置以便在Game视图中可以合适地显示出来。把第3步中新建的材质拖曳给它。
5. 双击打开第2步中创建的 Unity Shader。删除里面的所有代码，把下面的代码粘贴进去:

``` hlsl
Shader "Unity Shaders Book/Chapter 5/Simple Shader"{ 
    // Properties 语义并不是必需的

    SubShader { 
        Pass{
            CGPROGRAM

            // 告诉 Unity 哪个函数是顶点着色器，哪个函数是片元着色器
            // #pragma vertex name
            // #pragma fragment name
            #pragma vertex vert
            #pragma fragment frag

            // 顶点着色器函数
            float4 vert(float4 v : POSITION): SV_POSITION { 
                // 把顶点坐标从模型空间转换到裁剪空间
                // return mul (UNITY_MATRIX_MVP, v);
                return UnityObjectToClipPos (v);
            }

            // 片元着色器函数
            fixed4 frag(): SV_Target { 
                return fixed4(1.0, 1.0, 1.0, 1.0);
            }

            ENDCG
        }
    }
}
```

保存并返回 Unity 查看结果：

![图5.2 用一个最简单的顶点/片元着色器得到一个白色的球](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/5.2.jpg)


我们具体看一下 vert 函数的定义：

``` hlsl
float4 vert(float4 v : POSITION): SV_POSITION { 
    // return mul (UNITY_MATRIX_MVP, v);
    return UnityObjectToClipPos (v);
}
```

POSITION 和 SV_POSITION 是 Cg/HLSL 中的语义，这些语义将告诉系统需要哪些输入值，以及输出的是什么。
在这里 POSITION 将告诉 Unity 把模型的顶点坐标填充到输入参数 v 中，SV_POSITION 将告诉 Unity 顶点着色器的输出是裁剪空间中的顶点坐标。


然后，我们再来看一下 frag 函数：

``` hlsl
// 片元着色器函数
fixed4 frag(): SV_Target { 
    return fixed4(1.0, 1.0, 1.0, 1.0);
}
```

在本例中，frag 函数没有任何输入。它的输出是一个 fixed4 类型的变量，并且使用了 SV_Target 语义进行限定。SV_Targer 也是 HLSL 中的一个系统语义，它等同于告诉渲染器，把用户的输出颜色存储到一个渲染目标(render target)中，这里将输出到默认的帧缓存中。片元着色器中的代码很简单，返回了一个表示白色的 fixed4 类型的变量。片元着色器输出的颜色的每个分量范围在[0, 1]，其中(0,0,0)表示黑色，而(1,1,1)表示白色。


### 5.2.2 模型数据从哪里来？

如果我们想要得到更多模型数据，我们就需要定义一个结构体作为输入参数。

``` hlsl
Shader "Unity Shaders Book/Chapter 5/Simple Shader"{ 
    SubShader { 
        Pass{
            CGPROGRAM

            #pragma vertex vert
            #pragma fragment frag

            // 使用一个结构体来定义顶点着色器的输入
            struct a2v {
                // POSITION 语义告诉Unity，用模型空间的顶点坐标填充 vertex 变量
                float4 vertex : POSITION;
                // NORMAL 语义告诉Unity，用模型空间的法线方向填充 normal 变量
                float3 normal : NORMAL;
                // TEXCOORD0 语义告诉Unity，用模型的第一套纹理坐标填充 texcoord 变量
                float4 texcoord : TEXCOORD0;
            };

            float4 vert(a2v v): SV_POSITION { 
                // 使用 v.vertex 来访问模型空间的顶点坐标
                // return mul(UNITY_MATRIX_MVP, v.vertex);
                return UnityObjectToClipPos (v.vertex);
            }

            fixed4 frag(): SV_Target { 
                return fixed4(1.0, 1.0, 1.0, 1.0);
            }

            ENDCG
        }
    }
}
```

对于顶点着色器的输入，Unity 支持的语义有：
* POSITION: 顶点位置
* TANGENT：切线
* NORMAL：法线
* TEXCOORD0：纹理坐标
* TEXCOORD1
* TEXCOORD2
* TEXCOORD3
* COLOR：顶点颜色
等等...


### 5.2.3 顶点着色器和片元着色器之间如何通信

我们希望从顶点着色器输出一些数据到片元着色器，这就涉及到顶点着色器和片元着色器之间的通信。
为此，我们需要再定义一个新的结构体：

``` hlsl
Shader "Unity Shaders Book/Chapter 5/Simple Shader"{ 
    SubShader { 
        Pass{
            CGPROGRAM

            #pragma vertex vert
            #pragma fragment frag

            struct a2v {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
                float4 texcoord : TEXCOORD0;
            };

            struct v2f {
                // SV_POSITION 语义告诉 Unity，pos 里包含了顶点在裁剪空间中的位置
                float4 pos : SV_POSITION;
                // COLOR0 语义可以用于存储颜色信息
                fixed3 color : COLOR0;
            };

            v2f vert(a2v v) { 
                // 声明输出结构
                v2f o;
                o.pos = UnityObjectToClipPos(v.vertex);
                // v.normal 包含了顶点的法线方向，其分量范围在[-1, 1]
                // 下面代码把分量范围映射到了 [0, 1]
                // 存储到 o.color 中传递给片元着色器
                o.color =  v.normal * 0.5 + fixed3(0.5, 0.5, 0.5);
                return o;
            }

            fixed4 frag(v2f i): SV_Target { 
                // 将插值后的 i.color 显示到屏幕上
                return fixed4(i.color, 1.0);
            }

            ENDCG
        }
    }
}
```


### 5.2.4 如何使用属性

我们可以定义一些属性，让用户可以调整着色器的一些参数。

``` hlsl
Shader "Unity Shaders Book/Chapter 5/Simple Shader"{ 
    Properties { 
        // 声明一个 Color 类型的属性
        _Color ("Color Tint", Color) = (1.0, 1.0, 1.0, 1.0)
    }
    SubShader { 
        Pass{
            CGPROGRAM

            #pragma vertex vert
            #pragma fragment frag

            // 在 CG 代码中，我们需要定义一个与属性名称和类型都匹配的变量
            fixed4 _Color;

            struct a2v {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
                float4 texcoord : TEXCOORD0;
            };

            struct v2f {
                float4 pos : SV_POSITION;
                fixed3 color : COLOR0;
            };

            v2f vert(a2v v) {
                v2f o;
                o.pos = UnityObjectToClipPos(v.vertex);
                o.color =  v.normal * 0.5 + fixed3(0.5, 0.5, 0.5);
                return o;
            }

            fixed4 frag(v2f i): SV_Target { 
                fixed3 c = i.color;
                // 使用 _Color 属性来控制输出颜色
                c *= _Color.rgb;
                return fixed4(c, 1.0);
            }

            ENDCG
        }
    }
}
```

ShaderLab 属性类型和 Cg 变量类型的匹配关系：

| ShaderLab 属性类型 | Cg 变量类型 |
| --- | --- |
| Color, Vector | float4, half4, fixed4 |
| Range, Float | float, half, fixed |
| 2D           | sampler2D |
| 3D           | sampler3D |
| Cube         | samplerCUBE |



## 5.3 Unity 提供的内置文件和变量
为了方便开发者的编码过程，Unity 提供了很多内置文件，这些文件包含了很多提前定义的函数、变量和宏等。如果读者在学习他人编写的 Unity Shader 代码时，遇到了一些从未见过的变量、函数，而又无法找到对应的声明和定义，那么很有可能就是这些代码使用了 Unity 内置文件提供的函数和变量。

### 5.3.1 内置的包含文件
**包含文件（include file）**，是类似于C++中头文件的一种文件。在Unity中，它们的文件后缀是．cginc。在编写Shader时，我们可以使用#include指令把这些文件包含进来，这样我们就可以使用Unity为我们提供的一些非常有用的变量和帮助函数。例如：

```
CGPROGRAM
// ...
#include "UnityCG.cginc"
// ...
ENDCG
```

那么，这些文件在哪里呢?我们可以在官方网站(https://unity3d.com/cn/get-unity/download/archive)上选择下载 > 内置着色器 来直接下载这些文件（2023年：https://unity.com/cn/releases/editor/archive 上选择 See all > Other installs > Shaders）。图5.3 显示了由官网压缩包得到的文件。

![图5.3 Unity 的内置着色器](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/5.3.jpg)

我们也可以在Unity的安装目录下找到 CGIncludes文件夹，在Mac上位于：/Applications/Unity/Unity.app/Contents/CGIncludes；在Windows上位于：Unity的安装路径/Data/CGIncludes。

表5.2 Unity 中一些常用的包含文件：
 文件名 | 描述
 --- | ---
 UnityCG.cginc              | 包含了最常用的帮助函数、宏和结构体等
 UnityShaderVariables.cginc | 在编译 Unity Shader 时，会被自动包含进来。包含了许多内置的全局变量，如 UNITY_MATRIX_MVP 等
 Lighting.cginc             | 包含了各种内置的光照模型，如果编写的是 Surface Shader 的话，会自动包含进来
 HLSLSupport.cginc          | 在编译 Unity Shader 时，会被自动包含进来。声明了很多用于跨平台编译的宏和定义

表5.3 UnityCG.cginc 中一些常用的结构体
 名称 | 描述 | 包含的变量
 --- | --- | ---
 appdata_base   | 可用于顶点着色器的输入 | 顶点位置、顶点法线、第一组纹理坐标
 appdata_tan    | 可用于顶点着色器的输入 | 顶点位置、顶点切线、顶点法线、第一组纹理坐标
 appdata_full   | 可用于顶点着色器的输入 | 顶点位置、顶点切线、顶点法线、四组(或更多)纹理坐标
 appdata_img    | 可用于顶点着色器的输入 | 顶点位置、第一组纹理坐标
 v2f_img        | 可用于顶点着色器的输出 | 裁剪空间中的位置、第一组纹理坐标


表5.4 UnityCG.cginc 中一些常用的帮助函数
函数名 | 描述
--- | ---
float3 WorldSpaceViewDir (float4 v) | 输入一个模型空间中的顶点位置，返回世界空间中从该点到摄像机的观察方向
float3 ObjSpaceViewDir (float4 v)   | 输入一个模型空间中的顶点位置，返回模型空间中从该点到摄像机的观察方向
float3 WorldSpaceLightDir (float4 v) | 仅可用于前向渲染中。输入一个模型空间中的顶点位置，返回世界空间中从该点到光源的光照方向。没有被归一化
float3 ObjSpaceLightDir (float4 v)  | 仅可用于前向渲染中。输入一个模型空间中的顶点位置，返回模型空间中从该点到光源的光照方向、没有被归一化
float3 UnityObjectToWorldNormal (float3 norm)  | 把法线方向从模型空间转换到世界空间中
float3 UnityObjectToWorldDir (float3 dir)      | 把方向矢量从模型空间变换到世界空间中
float3 UnityWorldToObjectDir (float3 dir)      | 把方向矢量从世界空间变换到模型空间中

我们建议读者在 UnityCG.cginc 文件找到这些函数的定义，并尝试理解它们。一些函数我们完全可以自己实现，例如 UnityObjectToWorldDir 和 UnityWorldTo0bjectDir，这两个函数实际上就是对方向矢量进行了一次坐标空间变换。而UnityCGcginc文件可以帮助我们提高代码的复用率。UnityCGcginc还包含了很多宏，在后面的学习中，我们就会遇到它们。


### 5.3.2 内置的变量
Unity 提供了用于访问时间、光照、雾效和环境光等目的的变量。这些内置变量大多位于 UnityShaderVariables.cginc 中，与光照有关的内置变量还会位于 Lighting.cginc、AutoLight.cginc 等文件中。当我们在后面的学习中遇到这些变量时,再进行详细的讲解。



## 5.4 Unity 提供的 Cg/HLSL 语义

### 5.4.1 什么是语义

**语义（semantics）** 实际上就是一个赋给Shader输入和输出的字符串，这个字符串表达了这个参数的含义。通俗地讲，这些语义可以让Shader知道从哪里读取数据，并把数据输出到哪里，它们在CG/HLSL 的Shader流水线中是不可或缺的。需要注意的是，Unity 并没有支持所有的语义。

通常情况下，这些输入输出变量并不需要有特别的意义，也就是说，我们可以自行决定这些变量的用途。例如在上面的代码中，顶点着色器的输出结构体中我们用 COLOR0 语义去描述color变量。color 变量本身存储了什么，Shader 流水线并不关心。

而 Unity 为了方便对模型数据的传输，对一些语义进行了特别的含义规定。例如，在顶点着色器的输入结构体a2f用 TEXCOORD0 来描述 texcoord，Unity 会识别 TEXCOORD0 语义，以把模型的第一组纹理坐标填充到 texcoord 中。需要注意的是，即便语义的名称一样，如果出现的位置不同，含义也不同。例如，在输入结构体 a2f 中， TEXCOORD0 有特别的含义，即把模型的第一组纹理坐标存储在该变量中，而在输出结构体 v2f 中，TEXCOORD0 修饰的变量含义就可以由我们来决定。

在 DirectX 10 以后，有了一种新的语义类型，就是**系统数值语义(system-value semantics)**。
这类语义是以 SV 开头的,SV 代表的含义就是**系统数值(system-value)**。这些语义在渲染流水线中有特殊的含义。用这些语义描述的变量是不可以随便赋值的，因为流水线需要使用它们来完成特定的目的，例如渲染引擎会把用 SV_POSITION 修饰的变量经过光栅化后显示在屏幕上。

一些 Shader 会使用 POSITION 而非 SV_POSITION 来修饰顶点着色器的输出。SV_POSITION 是 DirectX 10 中引入的系统数值语义，在绝大多数平台上，它和 POSITION 语义是等价的，但在某些平台（例如索尼 PS4）上必须使用 SV_POSITION 来修饰顶点着色器的输出，否则无法让 Shader 正常工作。同样的例子还有 COLOR 和 SV_Target。因此，**为了让我们的 Shader 有更好的跨平台性，对于这些有特殊含义的变量我们最好使用以 SV 开头的语义进行修饰。**


### 5.4.2 Unity 支持的语义

表5.5 从应用阶段传递模型数据给顶点着色器时 Unity 支持的常用语义
 语义 | 描述
 --- | ---
 POSITION   | 模型空间中的顶点位置，通常是 float4 类型
 NORMAL     | 顶点法线，通常是 float3 类型
 TANGENT    | 顶点切线，通常是 float4 类型
 TEXCOORDn, 如 TEXCOORD0 、 TEXCOORD1 等 | 该顶点的纹理坐标，TEXCOORD0 表示第一组纹理坐标，依此类推。通常是 float2 或 float4 类型
 COLOR      | 顶点颜色，通常是 fixed4 或 float4 类型

其中 TEXCOORDn 中 n 的数目是和 Shader Model 有关的，例如一般在 Shader Model 2（即 Unity 默认编译到的 Shader Model 版本）和 Shader Model 3 中，n 等于 8，而在 Shader Model 4 和 Shader Model 5 中，n 等于 16 。通常情况下，一个模型的纹理坐标组数一般不超过2，即我们往往只使用 TEXCOORD0 和 TEXCOORD1。在 Unity 内置的数据结构体 appdata_full 中，它最多使用了6个坐标纹理组。


表5.6 从顶点着色器传递数据给片元着色器时 Unity 使用的常用语义
 语义 | 描述
 --- | ---
 SV_POSITION    | 裁剪空间中的顶点坐标，结构体中必须包含一个用该语义修饰的变量。等同于 DirectX 9 中的 POSITION，但最好使用 SV_POSITION
 COLORO         | 通常用于输出第一组顶点颜色，但不是必需的
 COLOR1         | 通常用于输出第二组顶点颜色，但不是必需的
 TEXCOORD0～TEXCOORD7 | 通常用于输出纹理坐标，但不是必需的

上面的语义中，除了 SV_POSITION 是有特别含义外，其他语义对变量的含义没有明确要求，也就是说，我们可以存储任意值到这些语义描述变量中。通常，如果我们需要把一些自定义的数据从顶点着色器传递给片元着色器，一般选用 TEXCOORD0 等。


表5.7 片元着色器输出时 Unity 支持的常用语义
 语义 | 描述
 --- | ---
 SV_Target     | 输出值将会存储到渲染目标（render target）中。等同于 DirectX 9 中的 COLOR，但最好使用 SV_Target



### 5.4.3 如何定义复杂的变量类型
上面提到的语义绝大部分用于描述标量或矢量类型的变量，例如 fixed2、float、float4、fixed4 等。下面的代码给出了一个使用语义来修饰不同类型变量的例子:

``` hlsl
struct v2f{
    float4 pos : SV_POSITION;
    fixed3 color0 : COLOR0;
    fixed4 color1 : COLOR1;
    half value0 : TEXCOORDO;
    float2 valuel : TEXCOORD1;
};
```

一个语义可以使用的寄存器只能处理4个浮点值(float)。因此，如果我们想要定义矩阵类型，如 float3×4、float4×4 等变量就需要使用更多的空间。一种方法是，把这些变量拆分成多个变量，例如对于 float4×4 的矩阵类型，我们可以拆分成 4 个 float4 类型的变量，每个变量存储了矩阵中的一行数据。


## 5.5 程序员的烦恼：Debug

### 5.5.1 使用假彩色图像

**假彩色图像（false-color image）** 指的是用假彩色技术生成的一种图像。与假彩色图像对应的是照片这种**真彩色图像（true-color image）**。一张假彩色图像可以用于可视化一些数据，主要思想是，我们可以把需要调试的变量映射到[0,1]之间，把它们作为颜色输出到屏幕上，然后通过屏幕上显示的像素颜色来判断这个值是否正确。

作为实例，下面我们会使用假彩色图像的方式来可视化一些模型数据，如法线、切线、纹理坐标、顶点颜色，以及它们之间的运算结果等。我们使用的代码如下:

``` hlsl
Shader "Unity Shaders Book/Chapter 5/False Color"
{
    SubShader
    {
        Pass
        {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag

            #include "UnityCG.cginc"

            struct v2f
            {
                float4 pos : SV_POSITION;
                fixed4 color : COLOR0;
            };

            sampler2D _MainTex;
            float4 _MainTex_ST;

            v2f vert (appdata_full v)
            {
                v2f o;
                o.pos = UnityObjectToClipPos(v.vertex);

                // 可视化法线方向
                o.color = fixed4(v.normal * 0.5 + fixed3(0.5, 0.5, 0.5), 1.0);

                // 可视化切线方向
                o.color = fixed4(v.tangent.xyz * 0.5 + fixed3(0.5, 0.5, 0.5), 1.0);

                // 可视化副切线方向
                fixed3 bitangent = cross(v.normal, v.tangent.xyz) * v.tangent.w;
                o.color = fixed4(bitangent * 0.5 + fixed3(0.5, 0.5, 0.5), 1.0);

                // 可视化第一组纹理坐标
                o.color = fixed4(v.texcoord.xy, 0.0, 1.0);

                // 可视化第二组纹理坐标
                o.color = fixed4(v.texcoord1.xy, 0.0, 1.0);

                // 可视化第一组纹理坐标的小数部分
                o.color =  frac(v.texcoord);
                if(any(saturate(v.texcoord) - v.texcoord)){
                    o.color.b = 0.5;
                }
                o.color.a = 1.0;

                // 可视化第二组纹理坐标的小数部分
                o.color =  frac(v.texcoord1);
                if(any(saturate(v.texcoord1) - v.texcoord1)){
                    o.color.b = 0.5;
                }
                o.color.a = 1.0;

                // 可视化顶点颜色
                o.color = v.color;

                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                return i.color;
            }
            ENDCG
        }
    }
}
```

在上面的代码中，我们使用了Unity内置的一个结构体——appdata_full，appdata_full 几乎包含了所有的模型数据。我们可以在 UnityCG.cginc 文件中找到它的定义：

``` hlsl
struct appdata_full
{
    float4 vertex   : POSITION;
    float4 tangent  : TANGENT;
    float3 normal   : NORMAL;
    float4 texcoord : TEXCOORD0;
    float4 texcoord1 : TEXCOORD1;
    float4 texcoord2 : TEXCOORD2;
    float4 texcoord3 : TEXCOORD3;
#if defined(SHADER_API_XBOX360)
    half4 texcoord4 : TEXCOORD4;
    half4 texcoord5 : TEXCOORD5;
#endif
    fixed4 color    : COLOR;
};
```

![图5.4 使用假彩色对 Unity Shader 进行调试](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/5.4.jpg)

为了可以得到某点的颜色值，我们可以使用类似颜色拾取器的脚本得到屏幕上某点的 RGBA 值，从而推断出该点的调试信息。在本书的附带工程中，读者可以找到这样一个简单的实例脚本: Assets -> Scripts -> Chapter5 -> ColorPicker.cs。把该脚本拖曳到一个摄像机上，单击运行后，可以用鼠标单击屏幕,以得到该点的颜色值，如图 5.5 所示。

![图5.5 使用颜色拾取器来查看调试信息](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/5.5.jpg)


### 5.5.2 利用神器：Visual Studio
Visual Studio 作为 Windows 系统下的开发利器，在 Visual Studio 2012 版本中也提供了对 Unity Shader 的调试功能——Graphics Debugger。

通过 Graphics Debugger，我们不仅可以查看每个像素的最终颜色、位置等信息，还可以对顶点着色器和片元着色器进行单步调试。具体的安装和使用方法可以参见 Unity 官网文档中使用 Visual Studio 对 DirectX 11 的 Shader 进行调试一文(https://docs.unity3d.com/Manual/SL-DebuggingD3D11ShadersWithVS.html)。
当然，本方法也有一些限制。例如，我们需要保证 Unity运行在 DirectX 11 平台上，而且 GraphicsDebugger本身存在一些bug。


### 5.5.3 最新利器：帧调试器

Unity 5 引入了新的针对渲染的调试器——**帧调试器（Frame Debugger）**。帧调试器可以用于查看渲染该帧时进行的各种渲染事件(event)，这些事件包含了 Draw Call 序列，也包括了类似清空帧缓存等操作。可以在 *Window - Frame Debugger* 菜单中打开帧调试器窗口。

帧调试器窗口大致可分为3个部分:
* 最上面的区域可以开启/关闭(单击 Enable 按钮)帧调试功能，当开启了帧调试时，通过移动窗口最上方的滑动条(或单击前进和后退按钮)，我们可以重放这些渲染事件；
* 左侧的区域显示了所有事件的树状图，在这个树状图中，每个叶子节点就是一个事件，而每个父节点的右侧显示了该节点下的事件数目我们可以从事件的名字了解这个事件的操作，例如以 Draw 开头的事件通常就是一个 Draw Call；
* 当单击了某个事件时，在右侧的窗口中就会显示出该事件的细节，例如几何图形的细节以及使用了哪个 Shader 等。

同时在 Game 视图中我们也可以看到它的效果。如果该事件是一个 DrawCall 并且对应了场景中的一个  GameObject，那么这个 GameObject 也会在 Hierarchy 视图中被高亮显示出来，图 5.7 显示了单击渲染某个对象的深度图事件的结果。

![图5.7 单击Knot的深度图渲染事件，在Game视图会显示该事件的效果，在Hierarchy视图中会高亮显示Knot对象，在帧调试器的右侧窗口会显示出该事件的细节](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/5.7.jpg)

Unity 5 提供的帧调试器实际上并没有实现一个真正的帧拾取（frame capture）的功能，而是仅仅使用停止渲染的方法来查看渲染事件的结果。例如，如果我们想要查看第4个 Draw Call 的结果，那么帧调试器就会在第4个 Draw Call 调用完毕后停止渲染。这种方法虽然简单，但得到的信息也很有限。



## 5.6 小心：渲染平台的差异
Unity的优点之一是其强大的跨平台性——写一份代码可以运行在很多平台上。绝大多数情况下，Unity为我们隐藏了这些细节，但有些时候我们需要自己处理它们。本节给出了一些常见的因为平台不同而造成的差异。

### 5.6.1 渲染纹理的坐标差异

OpenGL 和 DirectX 的屏幕空间坐标的差异：在水平方向上，两者的数值变化方向是相同的，但在竖直方向上，两者是相反的。在 OpenGL（OpenGLES 也是）中，(0，0)点对应了屏幕的左下角，而在 DirectX（Meta1 也是）中，(0，0)点对应了左上角。

![图5.8 OpenGL和DirectX使用了不同的屏幕空间坐标](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/5.8.jpg)

大多数情况下，这样的差异并不会对我们造成任何影响。但当我们要使用渲染到纹理技术，把屏幕图像渲染到一张渲染纹理中时，如果不采取行任何措施的话，就会出现纹理翻转的情况。幸运的是，Unity 在背后为我们处理了这种翻转问题——当在 DirectX 平台上使用渲染到纹理技术时，Unity 会为我们翻转屏幕图像纹理，以便在不同平台上达到一致性。

在一种特殊情况下 Unity 不会为我们进行这个翻转操作，这种情况就是我们开启了抗锯齿(在 Edit - Project Settings - Quality - Anti Aliasing 中开启)并在此时使用了渲染到纹理技术。在这种情况下，Unity 首先渲染得到屏幕图像，再由硬件进行抗锯齿处理后，得到一张渲染纹理来供我们进行后续处理。此时，在 DirectX 平台下，我们得到的输入屏幕图像并不会被 Unity 翻转，也就是说，此时对屏幕图像的采样坐标是需要符合 DirectX 平台规定的。

如果我们的屏幕特效只需要处理一张渲染图像，我们仍然不需要在意纹理的翻转问题，如果我们需要同时处理多张渲染图像（前提是开启了抗锯齿），例如需要同时处理屏幕图像和法线纹理，这些图像在竖直方向的朝向就可能是不同的（只有在DirectX这样的平台上才有这样的问题）。这种时候，我们就需要自己在顶点着色器中翻转某些渲染纹理(例如深度纹理或其他由脚本传递过来的纹理)的纵坐标，使之都符合DirectX平台的规则。例如:

``` hlsl
#if UNITY_UV_STARTS_AT_TOP // 判断当前平台是否是 DirectX 类型的平台
if (_MainTex_TexelSize.y < 0)
    uv.y = 1-uv.y;
#endif
```


### 5.6.2 Shader 的语法差异

读者在 Windows 平台下编译某些在 Mac 平台下工作良好的 Shader 时，可能会看到类似下面 的报错信息：
```
incorrect number of arguments to numeric-type constructor (compiling for d3dll)
```
或者
```
output parameter 'o' not completely initialized (compiling for d3dll)
```
上面的报错都是因为DirectX 9/11对Shader的语义更加严格造成的。例如，造成第一个报错 信息的原因是，Shader中可能存在下面这样的代码：
```
// v是float4类型，但在它的构造器中我们仅提供了一个参数
float4 v = float4(0.0);
```

在 OpenGL 平台上，上面的代码是合法的，它将得到一个4个分量都是 0.0 的 float4 类型的变量。 但在 DirectX 11 平台上，我们必须提供和变量类型相匹配的参数数目。也就是说，我们应该写成： 
```
float4 v = float4(0.0, 0.0, 0.0, 0.0);
```

而对于第二个报错信息，往往是出现在表面着色器中。表面着色器的顶点函数有一个使用了 out 修饰符的参数。如果出现这样的报错信息，可能是因为我们在顶 点函数中没有对这个参数的所有成员变量都进行初始化。我们应该使用类似下面的代码来对这些 参数进行初始化：
``` hlsl
void vert (inout appdata_full v, out Input o) {
    //使用Unity内置的 UNITY_INITIALIZE_OUTPUT 宏对输出结构体o进行初始化
    UNITY_INITIALIZE_OUTPUT(Input o);
    // ...
}
```

DirectX 9/11 也不支持在顶点着色器中使用 tex2D 函数。因为在顶点着色器阶段 Shader 无法得到 UV 偏导，而 tex2D 函数需要这样的偏导信息(这和纹理采样时使用的数学运算有关)。如果我们的确需要在顶点着色器中访问纹理，需要使用 tex2Dlod 函数来替代，如：
```
tex2Dlod(tex，float4(uv，0, 0)).
```

而且我们还需要添加 #pragma target 3.0，因为 tex2Dlod 是 Shader Model 3.0 中的特性。


### 5.6.3 Shader 的语义差异

一些语义在某些平台下是等价的，例如 SV_POSITION 和 POSITION。但在另一些平台上，这些语义是不等价的。为了让Shader能够在所有平台上正常工作，我们应该尽可能使用下面的语义来描述 Shader 的输入输出变量。
* 使用 SV_POSITION 来描述顶点着色器输出的顶点位置。
* 使用 SV_Target 来描述片元着色器的输出颜色。


### 5.6.4 其他平台差异

本书只给出了一些最常见的平台差异造成的问题，还有一些差异不再列举。如果读者发现一些 Shader 在平台A下工作良好，而在平台B下出现了问题，可以去 Unity 官方文档(https://docs.unity3d.com/Manual/SL-PlatformDifferences.html)中寻找更多的资料。



## 5.7 Shader 整洁之道

### 5.7.1 float、half、fixed

表5.8 Cg/HLSL 中 3 种精度的数值类型

| 类型 | 精度 |
| --- | --- |
| float | 最高精度，通常32位存储 |
| half  | 中等精度，通常16位存储，精度范围 -60000 ~ +60000 |
| fixed | 最低精度，通常11位存储，精度范围 -2.0 ~ +2.0 |

上面的精度范围并不是绝对正确的，尤其是在不同平台和 GPU 上，它们实际的精度可能和上面给出的范围不一致。通常来讲。
* 大多数现代的桌面GPU 会把所有计算都按最高的浮点精度进行计算，也就是说，float、half、fixed在这些平台上实际是等价的。
* 但在移动平台的GPU上，它们的确会有不同的精度范围，而且不同精度的浮点值的运算速度也会有所差异。因此，我们应该确保在真正的移动平台上验证我们的 Shader 。
* fixed 精度实际上只在一些较旧的移动平台上有用，在大多数现代的GPU上，它们内部把 fixed 和 half 当成同等精度来对待。

一个基本建议是，尽可能使用精度较低的类型，因为这可以优化 Shader 的性能，这一点在移动平台上尤其重要。
从它们大体的值域范围来看，我们可以使用 fixed 类型来存储颜色和单位矢量，如果要存储更大范围的数据可以选择 half 类型，最差情况下再选择使用 float。如果我们的目标平台是移动平台，一定要确保在真实的手机上测试我们的 Shader，这一点非常重要。


### 5.7.2 规范语法
在5.6.2节，我们提到 DirectX 平台对 Shader 的语义有更加严格的要求。这意味着，如果我们要发布到 DirectX 平台上就需要使用更严格的语法。例如，使用和变量类型相匹配的参数数目来对变量进行初始化。

### 5.7.3避免不必要的计算
如果我们毫无节制地在Shader（尤其是片元着色器）中进行了大量计算，那么我们可能很快就会收到 Unity 的错误提示：
 `temporary register limit of 8exceeded`
或
 `Arithmetic instruction limit of 64 exceeded; 65 arithmetic instructions needed to compileprogram`

出现这些错误信息大多是因为我们在Shader 中进行了过多的运算，使得需要的临时寄存器数目或指令数目超过了当前可支持的数目。读者需要知道，不同的 Shader Target、不同的着色器阶段，我们可使用的临时寄存器和指令数目都是不同的。

通常，我们可以通过指定更高等级的Shader Target来消除这些错误。表5.9 给出了 Unity 目前支持的 Shader Target。

| 指令 | 描述 |
| --- | --- |
| #pragma target 2.0 | 默认的 Shader Target 等级。相当于 Direct3D 9 上的 Shader Model 2.0，不支持对顶点纹理的采样，不支持显式的 LOD 纹理采样等 |
| #pragma target 3.0 | 相当于 Direct3D 9 上的 Shader Model 3.0，支持对顶点纹理的采样等 |
| #pragma target 4.0 | 相当于 Direct3D 10 上的 Shader Model 4.0，支持几何着色器等 |
| #pragma target 5.0 | 相当于 Direct3D 11 上的 Shader Model 5.0 |


**什么是 Shader Model ？**

Shader Model 是由微软提出的一套规范，通俗地理解就是它们决定了 Shader 中各个特性（feature）的能力（capability）。这些特性和能力体现在 Shader 能使用的运算指令数目、寄存器个数等各个方面。Shader Model 等级越高，Shader 的能力就越大。

虽然更高等级的 Shader Target 可以让我们使用更多的临时寄存器和运算指令，但一个更好的方法是尽可能减少 Shader 中的运算，或者通过预计算的方式来提供更多的数据。


### 5.7.4 慎用分支和循环语句

如果我们在Shader中使用了大量的流程控制语句，那么这个 Shader的性能可能会成倍下降。一个解决方法是，我们应该尽量把计算向流水线上端移动，例如把放在片元着色器中的计算放到顶点着色器中，或者直接在CPU中进行预计算，再把结果传递给Shader。

当然，有时我们不可避免地要使用分支语句来进行运算，那么一些建议是:
* 分支判断语句中使用的条件变量最好是常数，即在 Shader运行过程中不会发生变化;
* 每个分支中包含的操作指令数尽可能少;
* 分支的嵌套层数尽可能少。


### 5.7.5 不要除以 0 
除以 0 会导致 Shader 结果不可预测，有些会得到白色，有些会得到黑色，有些平台上 Shader 可能会直接崩溃。

一个解决方法是，对那些除数可能为0的情况，强制截取到非0范围。在一些资料中，读者可能也会看到使用 if 语句来判断除数是否为0的例子。另一个方法是，使用一个很小的浮点值来代替 0，例如 0.000001。


## 5.8 扩展阅读

读者可以在《GPU精粹2》中的GPU流程控制一章^[1]^中更加深入地了解为什么流程控制语句在GPU上会影响性能。在5.7.3节我们提到了Shader中临时寄存器数目和运算指令都有限制，实际上Shader Model对顶点着色器和片元着色器中使用的指令数、临时寄存器、常量寄存器、输入/输出寄存器、纹理等数目都进行了规定。读者可以在Wiki的相关资料^[2]^和HLSL 的手册^[3]^中找到更多的内容。

[1] Mark Harris, Ian Buck. "GPU Flow-Control Idioms." In GPU Gems 2.中译本: GPU精粹 2: 高性能图形芯片和通用计算编程技巧，法尔译，清华大学出版社，2007年。
[2] High-Level Shading Language，Wiki(https://en.wikipedia.org/wiki/High-Level_Shading_Language)。
[3] Shader Models vs Shader Profiles，HLSL手册(https://msdn.microsoft.com/en-us/librarylwindows/desktop/bb509626(v=vs.85).aspx)。



----------------------------------------------------------------------



# 第6章 Unity 中的基础光照

## 6.1 我们是如何看到这个世界的

通常来讲，我们要模拟真实的光照环境来生成一张图像，需要考虑3种物理现象。
* 首先，光线从**光源（light source）** 中被发射出来。
* 然后，光线和场景中的一些物体相交：一些光线被物体吸收了，而另一些光线被散射到其他方向。
* 最后，摄像机吸收了一些光，产生了一张图像。

### 6.1.1 光源

在实时渲染中，我们通常把光源当成一个没有体积的点，用 $l$ 来表示它的方向。在光学里我们使用**辐照度（irradiance）** 来描述光源的能量分布。我们可以使用光源方向 $l$ 和表面法线 $n$ 之间的夹角的余弦值来得到辐照度。

![图6.1 在左图中，光是垂直照射到物体表面，因此光线之间的垂直距离保持不变；而在右图中，光是斜着照射到物体表面，在物体表面光线之间的距离是d/cosθ，因此单位面积上接收到的光线数目要少于左图](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/6.1.jpg)

因为辐照度是和照射到物体表面时光线之间的距离 $d/ \cos \theta$ 成反比的, 因此辐照度就和 $\cos \theta$ 成正比。 $\cos \theta$ 可以使用光源方向 $l$ 和表面法线 $n$ 的点积来得到。这就是使用点积来计算辐照度的由来。


### 6.1.2 吸收和散射

光线由光源发射出来后，就会与一些物体相交。通常，相交的结果有两个：**散射（scattering）** 和 **吸收（absorption）**。

散射只改变光线的方向，但不改变光线的密度和颜色。而吸收只改变光线的密度和颜色，但不改变光线的方向。

光线在物体表面经过散射后，有两种方向：
* 一种将会散射到物体内部，这种现象被称为**折射（refraction）** 或 **透射（transmission）**；
* 另一种将会散射到外部，这种现象被称为**反射（reflection）**。

对于不透明物体，折射进入物体内部的光线还会继续与内部的颗粒进行相交，其中一些光线最后会重新发射出物体表面，而另一些则被物体吸收。那些从物体表面重新发射出的光线将具有和入射光线不同的方向分布和颜色。图6.2 给出了这样的一个例子。

![图6.2 散射时，光线会发生折射和反射现象。对于不透明物体，折射的光线会在物体内部继续传播，最终有一部分光线会重新从物体表面被发射出去](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/6.2.jpg)

为了区分这两种不同的散射方向，我们在光照模型中使用了不同的部分来计算它们：
* **高光反射（specular）** 部分表示物体表面是如何反射光线的；
* **漫反射（diffuse）** 部分则表示有多少光线会被折射、吸收和散射出表面。

根据入射光线的数量和方向，我们可以计算出射光线的数量和方向，我们通常使用**出射度(exitance)** 来描述它。辐照度和出射度之间是满足线性关系的，而它们之间的比值就是材质的漫反射和高光反射属性。

在本章中，我们假设漫反射部分是没有方向性的，也就是说，光线在所有方向上是平均分布的。同时,我们也只考虑某一个特定方向上的高光反射。


### 6.1.3 着色

**着色（shading）** 指的是，根据材质属性（如漫反射属性等）、光源信息（如光源方向、辐照度等），使用一个等式去计算沿某个观察方向的出射度的过程。我们也把这个等式称为**光照模型（Lighting Model）**。


### 6.1.4 BRDF 光照模型

当给定模型表面上的一个点时，BRDF包含了对该点外观的完整的描述。在图形学中，**BRDF（Bidirectional Reflectance Distribution Function）** 大多使用一个数学公式来表示，并且提供了一些参数来调整材质属性。通俗来讲，当给定入射光线的方向和辐照度后，BRDF 可以给出在某个出射方向上的光照能量分布。

本章涉及的 BRDF 都是对真实场景进行理想化和简化后的模型，也就是说，它们并不能真实地反映物体和光线之间的交互，这些光照模型被称为是经验模型。

计算机图形学的第一定律：如果它看起来是对的，那么它就是对的。



## 6.2 标准光照模型

虽然光照模型有很多种类，但在早期的游戏引擎中往往只使用一个光照模型，这个模型被称为标准光照模型。实际上，在BRDF理论被提出之前，标准光照模型就已经被广泛使用了。

> 在1975年，著名学者裴祥风（Bui Tuong Phong）提出了标准光照模型背后的基本理念。标准光照模型只关心直接光照（direct light），也就是那些直接从光源发射出来照射到物体表面后，经过物体表面的一次反射直接进入摄像机的光线。

它把进入到摄像机内的光线分为4个部分，每个部分使用一种方法来计算它的贡献度：

* **自发光（emissive）**，本书使用 $c_{emissive}$ 来表示。这个部分用于描述当给定一个方向时，一个表面本身会向该方向发射多少辐射量。需要注意的是，如果没有使用全局光照（global illumination）技术，这些自发光的表面并不会真的照亮周围的物体，而是它本身看起来更亮了而已。

* **高光反射（specular）** ，本书使用 $c_{specular}$ 来表示。这个部分用于描述当光线从光源照射到模型表面时，该表面会在完全镜面反射方向散射多少辐射量。

* **漫反射（diffuse）**，本书使用 $c_{diffuse}$ 来表示。这个部分用于描述，当光线从光源照射到模型表面时，该表面会向每个方向散射多少辐射量。

* **环境光（ambient）**，本书使用 $c_{ambient}$ 来表示。它用于描述其他所有的间接光照。
通常是一个全局变量，即场景中的所有物体都使用这个环境光。

### 6.2.3 漫反射

因为反射完全随机，可以认为在任何反射方向上的分布都是一样的，因此入射光线的角度很重要。

漫反射光照符合 **兰伯特定律（Lambert's law）** ：反射光线的强度与表面法线和光源方向之间夹角的余弦值成正比。

$$
c_{diffuse} = (c_{light} \cdot m_{diffuse}) max(0, \hat{n} \cdot \hat{l})
$$

其中，$c_{light}$ 是光源颜色，$m_{diffuse}$ 是材质的漫反射颜色，$\hat{n}$ 是表面法线，$\hat{l}$ 是指向光源的单位矢量。max函数防止物体被从后面来的光源照亮。max 防止点乘结果为负值，这可以防止物体被从后面来的光源照亮。


### 6.2.4 高光反射

计算高光反射需要知道表面法线 $\hat n$ 、视角方向 $\hat v$ 、光源方向 $\hat l$ 、反射方向 $\hat r$ 。

反射方向可以由表面法线和光源方向计算：$ \hat r = 2(\hat n \cdot \hat l) \hat n - \hat l$ 。

利用Phong模型来计算高光反射：

$$
c_{specular} = (c_{light} \cdot m_{specular}) max(0, \hat{v} \cdot \hat{r})^{m_{gloss}}
$$

其中，$c_{light}$ 是光源颜色，$m_{specular}$ 是材质的高光反射颜色，$m_{gloss}$ 是材质的**光泽度（gloss）**，也被称为**反光度（shininess）**。它用于控制高光区域的“亮点”有多宽， $m_{gloss}$ 越大，亮点就越小。

Blinn模型引入了一个新的矢量 $\hat h$ ，它是通过对 $\hat v$ 和 $\hat l$ 取平均后再归一化得到的： $\hat h = \frac {\hat v + \hat l} {|\hat v + \hat l|}$ 。

Blinn 模型的公式如下：

$$
c_{specular} = (c_{light} \cdot m_{specular}) max(0, \hat n \cdot \hat h)^{m_{gloss}}
$$

在硬件实现时，如果摄像机和光源距离模型足够远的话，Blinn 模型会快于 Phong 模型，这是因为，此时可以认为 $\hat v$ 和 $\hat l$ 都是定值，因此 $\hat h$ 将是一个常量。但是，当 $\hat v$ 或者 $\hat l$ 不是定值时，Phong 模型可能反而更快一些。


### 6.2.5 逐像素还是逐顶点

**逐像素光照（per-pixel lighting）** ：在片元着色器中计算。在逐像素光照中，我们会以每个像素为基础，得到它的法线（可以是对顶点法线插值得到的，也可以是从法线纹理中采样得到的），然后进行光照模型的计算。这种在面片之间对顶点法线进行插值的技术被称为 **Phong 着色（Phong shading）** ，也被称为 Phong 插值或法线插值着色技术。这不同于我们之前讲到的 Phong 光照模型。

**逐顶点光照（per-vertex lighting）** ：在顶点着色器中计算。也被称为 **高洛德着色（Gouraud shading）。在逐顶点光照中，我们在每个顶点上计算光照，然后会在渲染图元内部进行线性插值，最后输出成像素颜色。由于点数目往往远小于像素数目，因此逐顶点光照的计算量往往要小于逐像素光照。
但是，由于逐顶点光照依赖于线性插值来得到像素光照，因此，当光照模型中有非线性的计算（例如计算高光反射时）时，逐顶点光照就会出问题。在后面的章节中，我们将会看到这种情况。而且，由于逐顶点光照会在渲染图元内部对顶点颜色进行插值，这会导致渲染图元内部的颜色总是暗于顶点处的最高颜色值，这在某些情况下会产生明显的棱角现象。


### 6.2.6 总结

虽然标准光照模型仅仅是一个经验模型，也就是说，它并不完全符合真实世界中的光照现象。但由于它的易用性、计算速度和得到的效果都比较好，因此仍然被广泛使用。

标准光照模型有很多不同的叫法。例如，一些资料中称它为Phong光照模型，因为裴祥风（Bui Tuong Phong）首先提出了使用漫反射和高光反射的和来对反射光照进行建模的基本思想，并且提出了基于经验的计算高光反射的方法（用于计算漫反射光照的兰伯特模型在那时已经被提出了）。而后，由于Blinn的方法简化了计算而且在某些情况下计算更快，我们把这种模型称为 **Blinn-Phong 光照模型** 。

局限: 首先，有很多重要的物理现象无法用Blinn-Phong模型表现出来，例如 **菲涅耳反射（Fresnel reflection）**。其次，Blinn-Phong 模型是 **各项同性（isotropic）** 的，也就是说，当我们固定视角和光源方向旋转这个表面时，反射不会发生任何改变。但有些表面是具有 **各向异性（anisotropic）** 反射性质的，例如拉丝金属、毛发等。


## 6.3 Unity 中的环境光和自发光

Unity 中的环境光可以在 Window - Rendering - Lighting - Environment 中设置。在 Shader 中，我们只需要通过 Unity 的内置变量 UNITY_LIGHTMODEL_AMBIENT 就可以得到环境光的颜色和强度信息。

计算自发光只需要在片元着色器输出最后的颜色之前，把材质的自发光颜色添加到输出颜色上


## 6.4 在 Unity Shader 中实现漫反射光照模型

漫反射计算公式： $c_{diffuse} = (c_{light} \cdot m_{diffuse}) max(0, \hat{n} \cdot \hat{l})$

为了防止点积结果为负值，我们需要使用 max 操作，而 CG 提供了这样的函数。在本例中，使用 CG 的另一个函数可以达到同样的目的，即 saturate 函数。

> 函数：saturate(x)
> 参数：x：为用于操作的标量或矢量，可以是float、float2、float3等类型。
> 描述：把x截取在[0,1]范围内，如果x是一个矢量，那么会对它的每一个分量进行这样的操作。


### 6.4.1 实践: 逐顶点光照

![图6.6 逐顶点的漫反射光照效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/6.6.jpg)


准备工作：
1. 在 Unity 中新建一个场景 Scene_6_4，去掉天空盒；
2. 新建 Shader 命名为 Chapter6-DiffuseVertexLevel；
3. 在 Shader 上右键，新建材质；
4. 在场景中新建一个胶囊体，将材质赋给该胶囊体；
5. 保存场景。

Shader 实现：

``` hlsl
// 1. 为 Shader 起名
Shader "Unity Shaders Book/Chapter 6/Diffuse Vertex-Level"
{
    Properties
    {
        // 2. 控制材质的漫反射颜色
        _Diffuse ("Diffuse", Color) = (1,1,1,1)
    }
    SubShader
    {
        // 3. 在 SubShader 中定义 Pass 语义块。因为顶点/片元着色器的代码需要写在 Pass 语义块中。
        // 在 Pass 的第一行指明该 Pass 的光照模式
        Pass
        {
            Tags {"LightMode"="ForwardBase"}

            CGPROGRAM

            // 4. 告诉 Unity 顶点着色器和片元着色器的函数名
            #pragma vertex vert
            #pragma fragment frag
            
            // 5. 为了使用 Unity 内置变量，如 _LightColor0，需要包含 Lighting.cginc 文件
            #include "Lighting.cginc"

            // 6. 为了在 Shader 中使用 Properties 语义块中声明的属性
            // 我们需要定义一个和该属性类型相匹配的变量
            fixed4 _Diffuse;
            
            // 7. 定义顶点着色器的输入和输出结构体（输出结构体也是片元着色器的输入结构体）
            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
            };

            struct v2f
            {
                float4 pos : SV_POSITION;
                fixed3 color : COLOR;
            };

            // 8. 实现逐顶点的漫反射光照
            v2f vert (a2v v)
            {
                v2f o;
                // 把顶点位置从模型空间转换到裁剪空间
                o.pos = UnityObjectToClipPos(v.vertex);
                
                // 通过Unity内置变量 UNITY_LIGHTMODEL_AMBIENT 得到环境光部分
                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

                // 将法线转换到世界空间（新版Unity中 '_World2Object' 会被替换为 'unity_WorldToObject'）
                fixed3 worldNormal = normalize(mul(v.normal, (float3x3)unity_WorldToObject));
                // 获取世界空间光源方向
                fixed3 worldLight = normalize(_WorldSpaceLightPos0.xyz);
                // 计算漫反射光照
                fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal, worldLight));
                
                // 计算最终颜色
                o.color = ambient + diffuse;

                return o;
            }

            // 9. 由于所有计算都在顶点着色器中完成了，所以片元着色器中只需要把顶点颜色输出即可
            fixed4 frag (v2f i) : SV_Target
            {
                return fixed4(i.color, 1.0);
            }
            ENDCG
        }
    }

    // 10. 最后，我们需要把回调 Shader 设置为 Diffuse
    FallBack "Diffuse"
}
```


### 6.4.2 实践: 逐像素光照

逐像素光照可以得到更平滑的效果：

![图6.7 逐像素的漫反射光照效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/6.7.jpg)

准备工作：
1. 使用上一节中新建的场景
2. 新建 Shader 命名为 Chapter6-DiffusePixelLevel；
3. 在 Shader 上右键，新建材质；
4. 在场景中新建一个胶囊体，将材质赋给该胶囊体；

逐像素和逐顶点 Shader 实现非常相似，因此我们首先把 6.4.1 中的代码复制过来，然后进行修改。

Shader 实现：

``` hlsl
Shader "Unity Shaders Book/Chapter 6/Diffuse Pixel-Level"
{
    // ......
            // 1. 修改顶点着色器的输入结构体
            struct v2f
            {
                float4 pos : SV_POSITION;
                float3 worldNormal : TEXCOORD0;
            };

            // 2. 顶点着色器不需要计算光照模型，只需要把世界空间下的法线传递给片元着色器即可
            v2f vert (a2v v)
            {
                v2f o;
                // 把顶点位置从模型空间转换到裁剪空间
                o.pos = UnityObjectToClipPos(v.vertex);
                
                // 将法线转换到世界空间（新版Unity中 '_World2Object' 会被替换为 'unity_WorldToObject'）
                o.worldNormal = mul(v.normal, (float3x3)unity_WorldToObject);

                return o;
            }

            // 3. 片元着色器需要计算漫反射光照模型
            fixed4 frag (v2f i) : SV_Target
            {
                // 通过Unity内置变量 UNITY_LIGHTMODEL_AMBIENT 得到环境光部分
                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

                // 世界空间法线
                fixed3 worldNormal = normalize(i.worldNormal);
                // 获取世界空间光源方向
                fixed3 worldLight = normalize(_WorldSpaceLightPos0.xyz);
                // 计算漫反射光照
                fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal, worldLight));
                
                fixed3 color = ambient + diffuse;

                return fixed4(color, 1.0);
            }
    // ......
}
```


### 6.4.3 半兰伯特模型

在 6.4.1 小节中，我们使用的漫反射光照模型也被称为 **兰伯特光照模型** ，因为它符合兰伯特定律——在平面某点漫反射光的光强与该反射点的法向量和入射光角度的余弦值成正比。

然而，兰伯特光照模型存在一些问题：在光照无法到达的区域，模型的外观通常是全黑的，没有任何明暗变化。为了解决这个问题，Valve公司在开发游戏《半条命》时提出了一种技术，由于该技术是在原兰伯特光照模型的基础上进行了一个简单的修改，因此被称为 **半兰伯特（Half Lambert）光照模型** 。

广义的半兰伯特光照模型的公式： 

$$
c_{diffuse} = (c_{light} \cdot m_{diffuse}) (\alpha (\hat{n} \cdot \hat{l}) + \beta)
$$

可以看出，与原兰伯特模型相比，半兰伯特光照模型没有使用 max 操作来防止 $\hat{n} 和 \hat{l}$ 的点积为负值， 而是对其结果进行了一个 α 倍的缩放再加上一个 β 大小的偏移。绝大多数情况下，α 和 β 的均值为 0.5，即公式为：

$$
c_{diffuse} = (c_{light} \cdot m_{diffuse}) (0.5 (\hat{n} \cdot \hat{l}) + 0.5)
$$

通过这样的方式，我们可以把 $\hat{n} \cdot \hat{l}$ 的结果范围 从 [-1, 1] 映射到 [0, 1] 范围内。

对 6.4.2 小节中的逐像素光照模型进行修改，我们可以得到半兰伯特光照模型的实现：

新建 Shader 命名为 Chapter6-HalfLambert ，将 6.4.2 中的代码复制过来，然后进行修改：

``` hlsl
Shader "Unity Shaders Book/Chapter 6/Half Lambert"
{
    // ......
            fixed4 frag (v2f i) : SV_Target
            {
                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

                fixed3 worldNormal = normalize(i.worldNormal);
                
                fixed3 worldLight = normalize(_WorldSpaceLightPos0.xyz);
                // 半兰伯特光照模型
                fixed halfLambert = dot(worldNormal, worldLight) * 0.5 + 0.5;
                
                fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * halfLambert;
                
                fixed3 color = ambient + diffuse;

                return fixed4(color, 1.0);
            }
    // ......
}
```


逐顶点漫反射光照、逐像素漫反射光照、半兰伯特光照的对比效果：

![图6.8 逐顶点漫反射光照、逐像素漫反射光照、半兰伯特光照的对比效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/6.8.jpg)



## 6.5 在 Unity Shader 中实现高光反射光照模型

基本光照模型中高光反射部分计算公式：

$$
c_{specular} = (c_{light} \cdot m_{specular}) max(0, \hat{v} \cdot \hat{r})^{m_{gloss}}
$$

反射方向 $\hat{r}$ 由法线 $\hat{n}$ 和光源方向 $\hat{l}$ 计算得出： $\hat{r} = \hat{l} - 2(\hat{n} \cdot \hat{l}) \hat{n}$

上述公式很简单，但 CG 提供了计算反射方向的函数 reflect 。

> 函数：reflect(i, n)
> 参数：i：光线入射方向；n：法线方向。可以是float、float2、float3等类型。
> 描述：当给定入射方向 i 和法线方向 n 时，返回反射方向。


### 6.5.1 实践: 逐顶点光照

逐顶点的高光反射光照效果：

![图6.10 逐顶点的高光反射光照效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/6.10.jpg)

准备工作：
1. 新建场景 Scene_6_5，去掉天空盒；
2. 新建 Shader 命名为 Chapter6-SpecularVertexLevel；
3. 在 Shader 上右键，新建材质；
4. 在场景中新建一个胶囊体，将材质赋给该胶囊体；
5. 保存场景。

Shader 实现：

``` hlsl
Shader "Unity Shaders Book/Chapter 6/Specular Vertex-Level"
{
    Properties
    {
        _Diffuse ("Diffuse", Color) = (1,1,1,1)
        _Specular ("Specular", Color) = (1,1,1,1)
        _Gloss ("Gloss", Range(0, 128)) = 40
    }
    SubShader
    {
        Pass
        {
            Tags {"LightMode"="ForwardBase"}

            CGPROGRAM

            #pragma vertex vert
            #pragma fragment frag

            #include "Lighting.cginc"

            fixed4 _Diffuse;
            fixed4 _Specular;
            float _Gloss;

            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
            };

            struct v2f
            {
                float4 pos : SV_POSITION;
                fixed3 color : COLOR;
            };

            v2f vert (a2v v)
            {
                v2f o;
                
                o.pos = UnityObjectToClipPos(v.vertex);
                
                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

                fixed3 worldNormal = normalize(mul(v.normal, (float3x3)unity_WorldToObject));
                
                fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz);
                
                fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal, worldLightDir));
                
                // 反射方向
                fixed3 reflectDir = normalize(reflect(-worldLightDir, worldNormal));
                // 观察方向
                fixed3 viewDir = normalize(_WorldSpaceCameraPos.xyz - mul(_Object2World, v.vertex).xyz);
                // 计算高光反射光照
                fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(saturate(dot(reflectDir, viewDir)), _Gloss);

                // 计算最终颜色
                o.color = ambient + diffuse + specular;

                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                return fixed4(i.color, 1.0);
            }

            ENDCG
        }
    }
    // 回调设置为内置的 Specular
    FallBack "Specular"
}
```


### 6.5.2 实践: 逐像素光照

逐像素的高光反射光照效果：

![图6.11 逐像素的高光反射光照效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/6.11.jpg)

新建 Shader 命名为 Chapter6-SpecularPixelLevel，将 6.5.1 中的代码复制过来，然后进行修改：

``` hlsl
Shader "Unity Shaders Book/Chapter 6/Specular Pixel-Level"
{
    // ......
            // 1. 修改顶点着色器的输出结构体
            struct v2f
            {
                float4 pos : SV_POSITION;
                float3 worldNormal : TEXCOORD0;
                float3 worldPos : TEXCOORD1;
            };

            // 2. 顶点着色器计算世界空间法线、世界空间位置
            v2f vert (a2v v)
            {
                v2f o;
                
                o.pos = UnityObjectToClipPos(v.vertex);
                
                o.worldNormal = mul(v.normal, (float3x3)unity_WorldToObject);
                o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;

                return o;
            }

            // 3. 片元着色器计算关键的光照模型
            fixed4 frag (v2f i) : SV_Target
            {
                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

                fixed3 worldNormal = normalize(i.worldNormal);
                
                fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz);
                
                fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal, worldLightDir));
                
                // 反射方向
                fixed3 reflectDir = normalize(reflect(-worldLightDir, worldNormal));
                // 观察方向
                fixed3 viewDir = normalize(_WorldSpaceCameraPos.xyz - i.worldPos);
                // 计算高光反射光照
                fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(saturate(dot(reflectDir, viewDir)), _Gloss);

                // 计算最终颜色
                fixed3 color = ambient + diffuse + specular;

                return fixed4(color, 1.0);
            }

    // ......
}
```


### 6.5.3 Blinn-Phong 光照模型

在 6.5.2 小节中，我们给出了 Phong 光照模型在 Unity 中的实现，我们之前还提到另一种高光反射的实现方法—— Blinn-Phong 光照模型。Blinn 模型没有使用反射方向，而是引入了一个新的矢量 $\hat{h}$ ，它是通过对 $\hat v$ 和 $\hat l$ 取平均后再归一化得到的： $\hat h = \frac {\hat v + \hat l} {|\hat v + \hat l|}$ 。

Blinn-Phong 光照模型的公式：

$$
c_{specular} = (c_{light} \cdot m_{specular}) max(0, (\hat n \cdot \hat h))^{m_{gloss}}
$$

新建 Shader 命名为 Chapter6-BlinnPhong ，将 6.5.2 中的代码复制过来，然后进行修改：

``` hlsl
Shader "Unity Shaders Book/Chapter 6/Blinn-Phong"
{
    // ......
    
            fixed4 frag (v2f i) : SV_Target
            {
                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

                fixed3 worldNormal = normalize(i.worldNormal);
                
                fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz);
                
                fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal, worldLightDir));
                

                fixed3 reflectDir = normalize(reflect(-worldLightDir, worldNormal));

                fixed3 viewDir = normalize(_WorldSpaceCameraPos.xyz - i.worldPos.xyz);
                // 计算半角向量
                fixed3 halfDir = normalize(worldLightDir + viewDir);
                // 计算高光反射光照
                fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);


                fixed3 color = ambient + diffuse + specular;

                return fixed4(color, 1.0);
            }
    // ......
}
```

逐顶点高光反射光照、逐像素高光反射光照、Blinn-Phong 光照模型的对比效果：

![图6.12 逐顶点高光反射光照、逐像素高光反射光照、Blinn-Phong 光照模型的对比效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/6.12.jpg)



## 6.6 使用 Unity 内置的函数

表6.1 UnityCG.cginc 中一些常用的帮助函数

 函数名  | 描述 
------------- | -------------
float3 WorldSpaceViewDir (float4 v) | 输入一个模型空间中的顶点位置，返回世界空间中从该点到摄像机的观察方向。内部实现使用了 UnityWorldSpaceViewDir 函数
float3 UnityWorldSpaceViewDir (float4 v) | 输入一个世界空间中的顶点位置，返回世界空间中从该点到摄像机的观察方向
float3 ObjSpaceViewDir (float4 v) | 输入一个模型空间中的顶点位置,返回模型空间中从该点到摄像机的观察方向
float3 WorldSpaceLightDir (float4 v) | 仅可用于前向渲染中。输入一个模型空间中的顶点位置，返回世界空间中从该点到光源的光照方向。内部实现使用了UnityWorldSpaceLightDir函数。没有被归一化
float3 UnityWorldSpaceLightDir (float4 v) | 仅可用于前向渲染中。输入一个世界空间中的顶点位置，返回世界空间中从该点到光源的光照方向。没有被归一化
float3 ObiSpaceLightDir (float4 v) | 仅可用于前向渲染中。输入一个模型空间中的顶点位置，返回模型空间中从该点到光源的光照方向。没有被归一化
float3 UnityObjectToWorldNormal (float3 norm) | 把法线方向从模型空间转换到世界空间中
float3 UnityObjectToWorldDir (float3 dir) | 把方向矢量从模型空间变换到世界空间中
float3 UnityWorldToObjectDir (float3 dir) | 把方向矢量从世界空间变换到模型空间中

需要注意的是，这些函数都没有保证得到的方向矢量是单位矢量，因此，我们需要在使用前把它们归一化。

计算光源方向的3个函数：WorldSpaceLightDir、UnityWorldSpaceLightDir 和 ObjSpaceLightDir 中，Unity 帮我们处理了不同种类光源的情况。需要注意的是，这3个函数仅可用于前向渲染。这是因为只有在前向渲染时，这3个函数里使用的内置变量 WorldSpaceLightPos0等才会被正确赋值。


下面使用 Unity 内置函数改写之前的 Shader：

新建 Shader 命名为 Chapter6-BlinnPhongUseBuildInFunction ，Chapter6-BlinnPhong 中的代码复制过来，然后进行修改：

``` hlsl
Shader "Unity Shaders Book/Chapter 6/Blinn-Phong Use Build-In Function"
{
    // ......
            v2f vert (a2v v)
            {
                v2f o;
                
                o.pos = UnityObjectToClipPos(v.vertex);
                
                // 使用内置函数来计算世界空间下的法线方向
                o.worldNormal = UnityObjectToWorldNormal(v.normal);
                o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;

                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

                fixed3 worldNormal = normalize(i.worldNormal);
                
                // 使用内置函数来计算世界空间下的光照方向
                fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
                
                fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal, worldLightDir));
                
                fixed3 reflectDir = normalize(reflect(-worldLightDir, worldNormal));
                // 使用内置函数来计算视角方向
                fixed3 viewDir = normalize(UnityWorldSpaceViewDir(i.worldPos));

                fixed3 halfDir = normalize(worldLightDir + viewDir);
                
                fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);

                fixed3 color = ambient + diffuse + specular;

                return fixed4(color, 1.0);
            }
    // ......
}
```


---------------------------------------------------------------------------------



# 第7章 基础纹理

纹理最初的目的就是使用一张图片来控制模型的外观。使用 **纹理映射（texture mapping）** 技术，我们可以把一张图“黏”在模型表面，逐**纹素（texel）**（纹素的名字是为了和像素进行区分）地控制模型的颜色。

在美术人员建模的时候，通常会在建模软件中利用纹理展开技术把**纹理映射坐标（texture-mapping coordinates）** 存储在每个顶点上。纹理映射坐标定义了该顶点在纹理中对应的2D坐标。通常，这些坐标使用一个二维变量(u, v)来表示，其中u是横向坐标，而v是纵向坐标。因此，纹理映射坐标也被称为UV坐标

UV坐标通常都被归一化到[0, 1]范围内。纹理采样时使用的纹理坐标不一定是在[0, 1]范围内的，与之关系紧密的是纹理的平铺模式，他将决定渲染引擎在遇到不在[0, 1]范围内的纹理坐标时如何进行采样。

OpenGL 里纹理空间的原点位于左下角，DirectX 中原点位于左上角。Unity 使用的纹理空间是符合 OpenGL 标准的。


## 7.1 单张纹理

我们通常会使用一张纹理来代替物体的漫反射颜色。


### 7.1.1 实践

我们仍然使用 Blinn-Phong 光照模型来计算光照，准备工作如下：
1. 新建场景 Scene_7_1，去掉天空盒。
2. 新建 Shader 命名为 Chapter7-SingleTexture。
3. 在 Shader 上右键新建材质。
4. 在场景中新建一个胶囊体，并把上面新建的材质赋给该胶囊体。
5. 保存场景。

Shader 代码如下：

``` hlsl
// 1. 为 Shader 起名
Shader "Unity Shaders Book/Chapter 7/Single Texture"
{
    Properties
    {
        _Color ("Color Tint", Color) = (1,1,1,1)
        // 2. 添加一个纹理属性
        _MainTex ("Main Texture", 2D) = "white" {}
        _Specular ("Specular", Color) = (1,1,1,1)
        _Gloss ("Gloss", Range(0, 128)) = 40
    }
    SubShader
    {
        // 3. 定义 Pass 语义块，指明该 Pass 的光照模式
        Pass
        {
            Tags {"LightMode"="ForwardBase"}

            CGPROGRAM

            // 4. 告诉 Unity 顶点着色器和片元着色器的函数名
            #pragma vertex vert
            #pragma fragment frag
            
            // 5. 为了使用 Unity 内置变量，如 _LightColor0，需要包含 Lighting.cginc 文件
            #include "Lighting.cginc"

            // 6. 声明和属性类型相匹配的变量
            fixed4 _Color;

            sampler2D _MainTex;
            // 纹理名_ST 用于获取纹理的缩放和偏移值，_ST.xy 存储的是缩放值，_ST.zw 存储的是偏移值
            float4 _MainTex_ST;

            fixed4 _Specular;
            float _Gloss;

            // 7. 定义顶点着色器的输入和输出结构体
            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
                float4 texcoord : TEXCOORD0;
            };

            struct v2f
            {
                float4 pos : SV_POSITION;
                float3 worldNormal : TEXCOORD0;
                float3 worldPos : TEXCOORD1;
                float2 uv : TEXCOORD2;
            };

            // 8. 定义顶点着色器
            v2f vert (a2v v)
            {
                v2f o;
                
                o.pos = UnityObjectToClipPos(v.vertex);
                
                o.worldNormal = UnityObjectToWorldNormal(v.normal);

                o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;

                o.uv = v.texcoord.xy * _MainTex_ST.xy + _MainTex_ST.zw;
                // 或者使用 Unity 内置函数
                // o.uv = TRANSFORM_TEX(v.texcoord, _MainTex);

                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                fixed3 worldNormal = normalize(i.worldNormal);
                fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));
                
                // 9. 在计算漫反射时使用纹理中的纹素值
                fixed3 albedo = tex2D(_MainTex, i.uv).rgb * _Color.rgb;
                fixed3 diffuse = _LightColor0.rgb * albedo * saturate(dot(worldNormal, worldLightDir));
                
                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

                fixed3 reflectDir = normalize(reflect(-worldLightDir, worldNormal));
                fixed3 viewDir = normalize(UnityWorldSpaceViewDir(i.worldPos));
                fixed3 halfDir = normalize(worldLightDir + viewDir);
                fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);

                fixed3 color = ambient + diffuse + specular;

                return fixed4(color, 1.0);
            }
            ENDCG
        }
    }
    // 10. 为 Shader 设置合适的 Fallback 
    FallBack "Specular"
}
```


### 7.1.2 纹理的属性

当我们在 Unity 中导入一张纹理资源后，可以在它的材质面板上调整其属性。
官方手册：https://docs.unity3d.com/cn/current/Manual/class-TextureImporter.html

![图7.4 纹理的属性](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/7.4.jpg)

* Texture Type：选择要创建的纹理类型。
* Texture Shape：在该区域中选择形状并设置特定于该形状的属性。
* Wrap Mode：设置纹理的平铺方式。
    * Repeat：舍弃整数部分，使用小数部分采样，纹理会不断重复的平铺。
    * Clamp：大于 1 时截取到 1，小于 0 时截取到 0。纹理会在边缘被拉伸。
    ![图7.5 Wrap Mode决定了当纹理坐标超过[0, 1]范围后将会如何被平铺](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/7.5.jpg)
* Filter Mode：当纹理拉伸时采用哪种滤波模式。
    * Point：最近邻滤波，在放大或缩小时，它的采样像素数目通常只有一个，图像看起来有种像素风的效果。
    * Bilinear：双线性插值，对于每个目标像素，它会找到4个邻近像素，然后对它们进行线性插值混合后得到最终像素。
    * Trilinear：三线性插值，和Bilinear一样的，只是Trilinear还会在多级渐远纹理之间进行混合。如果一张纹理没有使用多级渐远纹理技术，那么Trilinear得到的结果是和Bilinear就一样的。
    ![图7.7 在放大纹理时，分别使用三种Filter Mode得到的结果](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/7.7.jpg)

纹理缩小的过程比放大更加复杂一些，此时原纹理中的多个像素将会对应一个目标像素。
纹理缩放更加复杂的原因在于我们往往需要处理抗锯齿问题，一个最常使用的方法就是使用**多级渐远纹理（mipmapping）** 技术。多级渐远纹理技术将原纹理提前用滤波处理来得到很多更小的图像，形成了一个图像金字塔，每一层都是对上一层图像降采样的结果。这样在实时运行时，就可以快速得到结果像素，例如当物体远离摄像机时，可以直接使用较小的纹理。但缺点是需要使用一定的空间用于存储这些多级渐远纹理，通常会多占用33%的内存空间。

![图7.8 在Advanced模式下可以设置多级渐远纹理的相关属性](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/7.8.jpg)

![图7.9 从上到下： Point滤波 + 多级渐远纹理技术，Bilinear滤波 + 多级渐远纹理技术，Trilinear滤波 + 多级渐远纹理技术](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/7.9.jpg)

**纹理的最大尺寸（Max Size）和 纹理模式（Format）**

如果导入纹理超过了 Max Size 限制，Unity 会把该纹理缩放为这个最大分辨率。如果使用了非 2 的幂大小（Non Power of Two, NPOT）的分辨率的纹理，那么这些纹理会占用更多的内存空间，而且 GPU 读取该纹理的速度也会有所下降。有些平台甚至不支持 NPOT 纹理，这时 Unity 内部会把纹理缩放成最近的 2 的幂大小。出于性能和空间的考虑，我们应该尽量使用 2 的幂大小的纹理。

Format 决定了 Unity 内部使用哪种格式来存储该纹理。使用的纹理格式精度越高（例如 Truecolor），占用的内存空间越大，但效果也越好。当游戏使用了大量 Truecolor 纹理时，内存可能会迅速增加，因此对于一些不需要使用很高精度的纹理（例如漫反射颜色纹理），我们应该尽量使用压缩格式。



## 7.2 凹凸映射

**凹凸映射（bump mapping）** 的目的是使用一张纹理来修改模型表面的法线，以便为模型提供更多的细节。这种方法不会真的改变模型的顶点位置，只是让模型看起来好像是“凹凸不平”的，但可以从模型的轮廓处看出“破绽”。

有两种主要的方法可以用来进行凹凸映射

* 使用一张 **高度纹理（height map）** 来模拟 **表面位移（displacement）**，然后得到一个修改后的法线值，这种方法也被称为 **高度映射（height mapping）**。
> 高度图中存储的是强度值（intensity），它用于表示模型表面局部的海拔高度。
> ![图7.11 高度图示意图](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/7.11.jpg)

* 使用一张 **法线纹理（normal map）** 来直接存储表面法线，这种方法又被称为 **法线映射（normal mapping）**。

法线纹理中存储的就是表面的法线方向。由于法线方向的分量范围在[-1,1]，而像素的分量范围为[0,1]，因此我们需要做一个映射，通常使用的映射就是: $ pixel = (normal+1)/2 $。

我们在Shader中对法线纹理进行纹理采样后，还需要对结果进行一次反映射的过程，以得到原先的法线方向。反映射的过程实际就是使用上面映射函数的逆函数: $normal = pixel × 2 - 1$

由于方向是相对于坐标空间来说的，法线纹理中存储的法线方向在哪个坐标空间中呢?
* **模型空间的法线纹理（object-space normal map）**： 对于模型顶点自带的法线，它们是定义在模型空间中的，因此一种直接的想法就是将修改后的模型空间中的表面法线存储在一张纹理中。
* **切线空间的法线纹理（tangent-space normal map）**： 在实际制作中，我们往往会采用模型顶点的 **切线空间（tangent space）** 来存储法线。这种法线纹理其实就是存储了每个点在各自的切线空间中的法线扰动方向。切线空间的原点就是该顶点本身，而 z 轴是顶点的法线方向（n），x 轴是顶点的切线方向（t），而 y 轴可由法线和切线叉积而得，也被称为是副切线（bitangent，b）或副法线，如图7.12所示

![图7.12 模型顶点的切线空间。其中，原点对应了顶点坐标，x轴是切线方向（t），y轴是副切线方向（b），z轴是法线方向（n）](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/7.12.jpg)

![图7.13 左图：模型空间下的法线纹理。右图：切线空间下的法线纹理](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/7.13.jpg)


模型空间存储法线的优点如下：
* 实现简单，更加直观。我们甚至都不需要模型原始的法线和切线等信息，也就是说，计算更少。
* 在纹理坐标的缝合处和尖锐的边角部分，可见的突变（缝隙）较少，即可以提供平滑的边界。这是因为模型空间下的法线纹理存储的是同一坐标系下的法线信息，因此在边界处通过插值得到的法线可以平滑变换。

但使用切线空间有更多优点：
* **自由度很高**：模型空间下的法线纹理记录的是绝对法线信息，仅可用于创建它时的那个模型，而应用到其他模型上效果就完全错误了。而切线空间下的法线纹理记录的是相对法线信息，这意味着，即便把该纹理应用到一个完全不同的网格上，也可以得到一个合理的结果。
* **可进行 UV 动画**：比如，我们可以移动一个纹理的 UV 坐标来实现一个凹凸移动的效果（水或者熔岩等效果）。
* **可以重用法线纹理**：比如，一个砖块，我们仅使用一张法线纹理就可以用到所有的6个面上。原因同上。
* **可压缩**：由于切线空间下的法线纹理中法线的Z方向总是正方向，因此我们可以仅存储XY方向，而推导得到Z方向。而模型空间下的法线纹理由于每个方向都是可能的，因此必须存储3个方向的值，不可压缩。

切线空间在很多情况下都优于模型空间，因此，在本书中，我们使用的也是切线空间下的法线纹理。


### 7.2.3 实践

我们需要在计算光照模型中统一各个方向矢量所在的坐标空间。由于法线纹理中存储的法线是切线空间下的方向，因此我们通常有两种方法：
* 在切线空间下进行光照计算，此时我们需要把光照方向、视角方向变换到切线空间下。
* 在世界空间下进行光照计算，此时我们需要把采样得到的法线方向变换到世界空间下，再和世界空间下的光照方向和视角方向进行计算。

从效率上来说，第一种方法往往要优于第二种方法，因为我们可以在顶点着色器中就完成对光照方向和视角方向的变换，而第二种方法由于要先对法线纹理进行采样，所以变换过程必须在片元着色器中实现，这意味着我们需要在片元着色器中进行一次矩阵操作。

但从通用性角度来说，第二种方法要优于第一种方法，因为有时我们需要在世界空间下进行一些计算，例如在使用 Cubemap 进行环境映射时，我们需要使用世界空间下的反射方向对 Cubemap 进行采样。如果同时需要进行法线映射，我们就需要把法线方向变换到世界空间下。

#### 1. 在切线空间下计算

基本思路是：在片元着色器中通过纹理采样得到切线空间下的法线，然后再与切线空间下的视角方向、光照方向等进行计算得到最终的光照结果。

新建 Shader 命名为 Chapter7-NormalMapTangentSpace ：

``` hlsl
// 1. 为 Shader 起名
Shader "Unity Shaders Book/Chapter 7/Normal Map In Tangent Space"
{
    Properties
    {
        _Color ("Color Tint", Color) = (1,1,1,1)
        _MainTex ("Main Texture", 2D) = "white" {}
        // 2. 添加一个法线纹理属性，以及控制凹凸程度的属性
        _BumpMap ("Normal Map", 2D) = "bump" {}
        _BumpScale ("Bump Scale", Float) = 1.0
        _Specular ("Specular", Color) = (1,1,1,1)
        _Gloss ("Gloss", Range(8.0, 256)) = 20
    }
    SubShader
    {
        // 3. 定义 Pass 语义块，指明该 Pass 的光照模式
        Pass
        {
            Tags {"LightMode"="ForwardBase"}

            CGPROGRAM

            // 4. 告诉 Unity 顶点着色器和片元着色器的函数名
            #pragma vertex vert
            #pragma fragment frag
            
            // 5. 为了使用 Unity 内置变量，如 _LightColor0，需要包含 Lighting.cginc 文件
            #include "Lighting.cginc"

            // 6. 声明和属性类型相匹配的变量
            fixed4 _Color;

            sampler2D _MainTex;
            // 纹理名_ST 用于获取纹理的缩放和偏移值，_ST.xy 存储的是缩放值，_ST.zw 存储的是偏移值
            float4 _MainTex_ST;

            sampler2D _BumpMap;
            float4 _BumpMap_ST;
            float _BumpScale;

            fixed4 _Specular;
            float _Gloss;

            // 7. 切线空间由顶点法线和切线构建出的一个坐标空间，因此我们需要得到顶点的切线信息
            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
                float4 tangent : TANGENT;
                float4 texcoord : TEXCOORD0;
            };

            // 8. 我们需要在顶点着色器中计算切线空间下的光照和视角方向，
            // 因此我们需要添加两个变量存储变换后的光照和视角方向
            struct v2f
            {
                float4 pos : SV_POSITION;
                float4 uv : TEXCOORD0;
                float3 lightDir : TEXCOORD1;
                float3 viewDir : TEXCOORD2;
            };

            // 9. 定义顶点着色器
            v2f vert (a2v v)
            {
                v2f o;
                
                o.pos = UnityObjectToClipPos(v.vertex);

                o.uv.xy = v.texcoord.xy * _MainTex_ST.xy + _MainTex_ST.zw;
                o.uv.zw = v.texcoord.xy * _BumpMap_ST.xy + _BumpMap_ST.zw;
                
                // // 计算副切线
                // float3 binormal = cross(normalize(v.normal), normalize(v.tangent.xyz)) * v.tangent.w;
                // // 构造一个矩阵，将向量从模型空间变换到切线空间
                // float3x3 rotation = float3x3(v.tangent.xyz, binormal, v.normal);
                // 或者直接使用 Unity 内置宏 TANGENT_SPACE_ROTATION 直接计算得到 rotation 变换矩阵
                // 它的实现和上述代码完全一样。
                TANGENT_SPACE_ROTATION;
                
                // 使用 Unity 内置函数 ObjSpaceLightDir 和 ObjSpaceViewDir 来得到模型空间下的光照和视角方向
                // 再利用变换矩阵把他们从模型空间变换到切线空间
                o.lightDir = mul(rotation, ObjSpaceLightDir(v.vertex)).xyz;
                o.viewDir = mul(rotation, ObjSpaceViewDir(v.vertex)).xyz;
                return o;
            }

            // 10. 片元着色器中只需要采样得到切线空间下的法线方向，再在切线空间下进行光照计算即可
            fixed4 frag (v2f i) : SV_Target
            {
                fixed3 tangentLightDir = normalize(i.lightDir);
                fixed3 tangentViewDir = normalize(i.viewDir);
                
                // 获取法线纹理中的纹素
                fixed4 packedNormal = tex2D(_BumpMap, i.uv.zw);
                fixed3 tangentNormal;
                // // 如果没有在 Unity 里把法线纹理的类型设置为 Normal map，则需要手动反转法线方向
                // tangentNormal.xy = (packedNormal.xy * 2 - 1) * _BumpScale;
                // tangentNormal.z = sqrt(1 - saturate(dot(tangentNormal.xy, tangentNormal.xy)));
                // 如果纹理类型设置为 Normal map，则可以用 Unity 内置函数 UnpackNormal 来得到正确的法线方向
                tangentNormal = UnpackNormal(packedNormal);
                tangentNormal.xy *= _BumpScale;
                tangentNormal.z = sqrt(1 - saturate(dot(tangentNormal.xy, tangentNormal.xy)));

                fixed3 albedo = tex2D(_MainTex, i.uv.xy) * _Color.rgb;

                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo;
                
                fixed3 diffuse = _LightColor0.rgb * albedo * max(0, dot(tangentNormal, tangentLightDir));
                
                fixed3 halfDir = normalize(tangentLightDir + tangentViewDir);
                fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(tangentNormal, halfDir)), _Gloss);

                fixed3 color = ambient + diffuse + specular;

                return fixed4(color, 1.0);
            }
            ENDCG
        }
    }
    // 11. 为 Shader 设置合适的 Fallback 
    FallBack "Specular"
}
```

#### 2. 在世界空间下计算

基本思路是：在顶点着色器中计算从切线空间到世界空间的变换矩阵，并把它传递给片元着色器。

新建 Shader 命名为 Chapter7-NormalMapWorldSpace ，将上面 shader 中的代码粘贴进去，并进行修改：

``` hlsl
    // ......
            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
                float4 tangent : TANGENT;
                float4 texcoord : TEXCOORD0;
            };

            // 1. 修改顶点着色器输出结构体，使它包含从切线空间到世界空间的变换矩阵
            struct v2f
            {
                float4 pos : SV_POSITION;
                float4 uv : TEXCOORD0;
                // 一个插值寄存器最多只能存储float4大小的变量，对于矩阵这样的变量，可以按行拆成多个变量存储
                // 为了充分利用插值寄存器的存储空间，我们把世界空间下的顶点位置存储在这些变量的w分量中
                float4 TtoW0 : TEXCOORD1;
                float4 TtoW1 : TEXCOORD2;
                float4 TtoW2 : TEXCOORD3;
            };

            // 2. 修改顶点着色器，计算从切线空间到世界空间的变换矩阵
            v2f vert (a2v v)
            {
                v2f o;
                
                o.pos = UnityObjectToClipPos(v.vertex);

                o.uv.xy = v.texcoord.xy * _MainTex_ST.xy + _MainTex_ST.zw;
                o.uv.zw = v.texcoord.xy * _BumpMap_ST.xy + _BumpMap_ST.zw;
                
                float3 worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
                fixed3 worldNormal = UnityObjectToWorldNormal(v.normal);
                fixed3 worldTangent = UnityObjectToWorldDir(v.tangent.xyz);
                fixed3 worldBinormal = cross(worldNormal, worldTangent) * v.tangent.w;
                
                // 计算从切线空间到世界空间的变换矩阵
                // 将顶点位置存储在这些变量的w分量中
                o.TtoW0 = float4(worldTangent.x, worldBinormal.x, worldNormal.x, worldPos.x);
                o.TtoW1 = float4(worldTangent.y, worldBinormal.y, worldNormal.y, worldPos.y);
                o.TtoW2 = float4(worldTangent.z, worldBinormal.z, worldNormal.z, worldPos.z);
                
                return o;
            }

            // 3. 修改片元着色器，在世界空间下进行光照计算
            fixed4 frag (v2f i) : SV_Target
            {
                // 获取世界空间下的顶点位置
                float3 worldPos = float3(i.TtoW0.w, i.TtoW1.w, i.TtoW2.w);
                // 计算世界空间下的光源和视角方向
                fixed3 lightDir = normalize(UnityWorldSpaceLightDir(worldPos));
                fixed3 viewDir = normalize(UnityWorldSpaceViewDir(worldPos));

                // 获取切线空间下的法线
                fixed3 bump = UnpackNormal(tex2D(_BumpMap, i.uv.zw));
                bump.xy *= _BumpScale;
                bump.z = sqrt(1.0 - saturate(dot(bump.xy, bump.xy)));
                // 将切线空间下的法线变换到世界空间下
                bump = normalize(half3(dot(i.TtoW0.xyz, bump), dot(i.TtoW1.xyz, bump), dot(i.TtoW2.xyz, bump)));
                
                fixed3 albedo = tex2D(_MainTex, i.uv.xy) * _Color.rgb;

                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo;
                
                fixed3 diffuse = _LightColor0.rgb * albedo * max(0, dot(bump, lightDir));
                
                fixed3 halfDir = normalize(lightDir + viewDir);
                fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(bump, halfDir)), _Gloss);

                fixed3 color = ambient + diffuse + specular;

                return fixed4(color, 1.0);
            }
    // ......
```


### 7.2.4 Unity 中的法线纹理类型

当我们在 Unity 中将法线纹理 Texture Type 设置为 Normal map 时，可以让 Unity 根据不同平台对纹理进行压缩，再通过 UnpackNormal 函数来针对不同的压缩格式对法线纹理进行正确的采样。我们可以在 UnityCG.cginc 文件中找到 UnpackNormal 函数的内部实现：

``` hlsl
inline fixed3 UnpackNormalDXT5nm(fixed4 packednormal)
{
    fixed3 normal;
    normal.xy = packednormal.xy * 2 - 1;
    normal.z = sqrt(1 - saturate(dot(normal.xy, normal.xy)));
    return normal;
}

inline fixed3 UnpackNormal(fixed4 packednormal)
{
#if defined(UNITY_NO_DXT5nm)
    return packednormal.xyz * 2 - 1;
#else
    return UnpackNormalDXT5nm(packednormal);
#endif
}

```

当我们把纹理类型设置成 Normal map 后，有一个复选框是 Creat from Grayscale，这个是用于从高度图中生成法线纹理的。高度图本身记录的是相对高度，是一张灰度图，白色表示相对更高，黑色表示相对更低。

![图7.17 当勾选了Create from Grayscale后，Unity会根据高度图来生成一张切线空间下的法线纹理](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/7.17.jpg)

当勾选了 Create from Grayscale 后，会多出两个选项：
* Bumpiness：用于控制凹凸程度
* Filtering：决定我们使用哪种方式计算凹凸程度
   * Smooth：生成后的法线纹理会比较平滑
   * Sharp：使用 Sobel 滤波来生成法线



## 7.3 渐变纹理

我们可以使用渐变纹理来控制漫反射光照的结果（通过这种方法我们可以实现一些风格化的效果）。

![图7.18 使用不同的渐变纹理控制漫反射光照，左下角给出了每张图使用的渐变纹理](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/7.18.jpg)

新建 Shader 命名为 Chapter7-RampTexture ：

``` hlsl
Shader "Unity Shaders Book/Chapter 7/Ramp Texture"
{
    Properties
    {
        _Color ("Color Tint", Color) = (1,1,1,1)
        // 渐变纹理
        _RampTex ("Ramp Tex", 2D) = "white" {}
        _Specular ("Specular", Color) = (1,1,1,1)
        _Gloss ("Gloss", Range(8.0, 256)) = 20
    }
    SubShader
    {
        Pass
        {
            Tags { "LightMode"="ForwardBase" }

            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            
            #include "Lighting.cginc"

            fixed4 _Color;
            sampler2D _RampTex;
            float4 _RampTex_ST;
            fixed4 _Specular;
            float _Gloss;

            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
                float4 texcoord : TEXCOORD0;
            };

            struct v2f
            {
                float4 pos : SV_POSITION;
                float3 worldNormal : TEXCOORD0;
                float3 worldPos : TEXCOORD1;
                float2 uv : TEXCOORD2;
            };

            sampler2D _MainTex;
            float4 _MainTex_ST;

            v2f vert (a2v v)
            {
                v2f o;

                o.pos = UnityObjectToClipPos(v.vertex);
                
                o.worldNormal = UnityObjectToWorldNormal(v.normal);
                o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;

                o.uv = TRANSFORM_TEX(v.texcoord, _RampTex);

                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                fixed3 worldNormal = normalize(i.worldNormal);
                fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));

                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;

                // 使用渐变纹理控制漫反射光照颜色
                // fixed halfLambert = 0.5 * dot(worldNormal, worldLightDir) + 0.5;
                fixed lambert = dot(worldNormal, worldLightDir);
                fixed3 diffuseColor = tex2D(_RampTex, fixed2(lambert, 0)).rgb * _Color.rgb;

                fixed3 diffuse = _LightColor0.rgb * diffuseColor;
                
                fixed3 viewDir = normalize(UnityWorldSpaceViewDir(i.worldPos));
                fixed3 halfDir = normalize(worldLightDir + viewDir);
                fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss);

                return fixed4(ambient + diffuse + specular, 1.0);
            }
            ENDCG
        }
    }
    Fallback "Specular"
}

```


## 7.4 遮罩纹理

**遮罩纹理（mask texture）** 允许我们可以保护某些区域，使他们免于某些修改。例如：有时我们希望模型表面某些区域的反光强烈一些，而某些区域弱一些。

使用遮罩纹理的流程一般是：通过采样得到遮罩纹理的纹素值，然后使用其中某个（或某几个）通道的值（例如texel.r）来与某种表面属性进行相乘，这样，当该通道的值为0时，可以保护表面不受该属性的影响。总而言之，使用遮罩纹理可以让美术人员更加精准（像素级别）地控制模型表面的各种性质。

![图7.20 使用高光遮罩纹理。从左到右：只包含漫反射，未使用遮罩的高光反射，使用遮罩的高光反射](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/7.20.jpg)

新建 Shader 命名为 Chapter7-MaskTexture ：

``` hlsl
Shader "Unity Shaders Book/Chapter 7/Mask Texture"
{
    Properties
    {
        _Color ("Color Tint", Color) = (1,1,1,1)
        _MainTex ("Main Texture", 2D) = "white" {}
        _BumpMap ("Normal Map", 2D) = "bump" {}
        _BumpScale ("Bump Scale", Float) = 1.0
        // 声明遮罩纹理
        _SpecularMask ("Specular Mask", 2D) = "white" {}
        // 声明高光颜色和高光强度属性
        _SpecularScale ("Specular Scale", Float) = 1.0
        _Specular ("Specular", Color) = (1,1,1,1)
        _Gloss ("Gloss", Range(8.0, 256)) = 20
    }
    SubShader
    {
        Pass
        {
            Tags {"LightMode"="ForwardBase"}

            CGPROGRAM

            #pragma vertex vert
            #pragma fragment frag
            
            #include "Lighting.cginc"

            fixed4 _Color;

            sampler2D _MainTex;
            // 纹理名_ST 用于获取纹理的缩放和偏移值，_ST.xy 存储的是缩放值，_ST.zw 存储的是偏移值
            float4 _MainTex_ST;

            sampler2D _BumpMap;
            // float4 _BumpMap_ST;
            float _BumpScale;

            sampler2D _SpecularMask;
            // float4 _SpecularMask_ST;
            float _SpecularScale;
            fixed4 _Specular;

            float _Gloss;

            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
                float4 tangent : TANGENT;
                float4 texcoord : TEXCOORD0;
            };

            struct v2f
            {
                float4 pos : SV_POSITION;
                float2 uv : TEXCOORD0;
                float3 lightDir : TEXCOORD1;
                float3 viewDir : TEXCOORD2;
            };

            v2f vert (a2v v)
            {
                v2f o;
                
                o.pos = UnityObjectToClipPos(v.vertex);

                o.uv.xy = v.texcoord.xy * _MainTex_ST.xy + _MainTex_ST.zw;
                
                // // 计算副切线
                // float3 binormal = cross(normalize(v.normal), normalize(v.tangent.xyz)) * v.tangent.w;
                // // 构造一个矩阵，将向量从模型空间变换到切线空间
                // float3x3 rotation = float3x3(v.tangent.xyz, binormal, v.normal);
                // 或者直接使用 Unity 内置宏 TANGENT_SPACE_ROTATION 直接计算得到 rotation 变换矩阵
                // 它的实现和上述代码完全一样。
                TANGENT_SPACE_ROTATION;
                
                // 使用 Unity 内置函数 ObjSpaceLightDir 和 ObjSpaceViewDir 来得到模型空间下的光照和视角方向
                // 再利用变换矩阵把他们从模型空间变换到切线空间
                o.lightDir = mul(rotation, ObjSpaceLightDir(v.vertex)).xyz;
                o.viewDir = mul(rotation, ObjSpaceViewDir(v.vertex)).xyz;
                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                fixed3 tangentLightDir = normalize(i.lightDir);
                fixed3 tangentViewDir = normalize(i.viewDir);
                
                // 如果纹理类型设置为 Normal map，则可以用 Unity 内置函数 UnpackNormal 来得到正确的法线方向
                fixed3 tangentNormal = UnpackNormal(tex2D(_BumpMap, i.uv));
                tangentNormal.xy *= _BumpScale;
                tangentNormal.z = sqrt(1 - saturate(dot(tangentNormal.xy, tangentNormal.xy)));

                fixed3 albedo = tex2D(_MainTex, i.uv).rgb * _Color.rgb;

                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo;
                
                fixed3 diffuse = _LightColor0.rgb * albedo * max(0, dot(tangentNormal, tangentLightDir));
                
                fixed3 halfDir = normalize(tangentLightDir + tangentViewDir);

                // 获取高光遮罩纹理（遮罩纹理实际只需要占一个通道）
                fixed specularMask = tex2D(_SpecularMask, i.uv).r * _SpecularScale;
                fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(tangentNormal, halfDir)), _Gloss);
                specular *= specularMask;

                fixed3 color = ambient + diffuse + specular;

                return fixed4(color, 1.0);
            }
            ENDCG
        }
    }
    FallBack "Specular"
}
```

在真实的游戏制作过程中，遮罩纹理已经不止限于保护某些区域使它们免于某些修改，而是可以存储任何我们希望逐像素控制的表面属性。通常，我们会充分利用一张纹理的RGBA四个通道，用于存储不同的属性。例如，我们可以把高光反射的强度存储在R通道，把边缘光照的强度存储在G通道，把高光反射的指数部分存储在B通道，最后把自发光强度存储在A通道。



-------------------------------------------------------------------------------------



# 第8章 透明效果

**深度缓冲（depth buffer，也被称为z-buffer）** ：它可以决定物体的哪些部分会被渲染在前面，哪些部分会被其它物体遮挡。基本思想是：根据深度缓存中的值来判断该片元与摄像机的距离，当渲染一个片元时，需要把它的深度值和已经存在于深度缓冲中的值进行比较（如果开启了深度测试），如果新的深度值比已存在的深度值小，则该片元应该覆盖掉此时颜色缓冲中的像素值，并更新深度值，如果新的深度值比已存在的深度值大，则丢弃该片元。

在 Unity 中，我们通常使用两种方法来实现透明效果：
* **透明度测试（Alpha Test）**：只要一个片元的透明的不满足条件（通常是小于某个阈值），那么它对应的片元就会被舍弃。不需要关闭深度写入。被舍弃的片元将不会再进行任何处理，也不会对颜色缓冲产生任何影响；未被舍弃的就会按照普通的不透明物体的处理方式来处理它。效果就是，要么完全透明，要么完全不透明。
* **透明度混合（Alpha Blending）**：这种方法可以得到真正的半透明效果。它会使用当前片元的透明度作为混合因子，与已经存储在颜色缓冲中的颜色值进行混合，得到新的颜色。
透明度混合需要关闭深度写入，这使得我们要非常小心物体的渲染顺序；但没有关闭深度测试，当使用透明度混合渲染一个片元时，还是会比较它的深度值与当前深度缓冲中的深度值，如果它的深度值距离摄像机更远，那么就不会再进行混合操作。
因此，当一个不透明物体出现在一个透明物体的前面，而我们先渲染了不透明物体，它仍然可以正常地遮挡住透明物体。对于透明度混合来说深度缓冲是只读的。


## 8.1 为什么渲染顺序很重要

对于透明度混合技术，需要关闭深度写入。如果不关闭深度写入，一个半透明表面背后的表面本来是可以透过它被我们看到的，但由于深度测试时判断结果是该半透明表面距离摄像机更近，导致后面的表面将会被剔除，我们也就无法透过半透明表面看到后面的物体了。

渲染引擎一般都会先对物体进行排序，再渲染。常用的方法是：
1. 先渲染所有不透明物体，并开启它们的深度测试和深度写入。
2. 把半透明物体按它们距离摄像机的远近进行排序，然后按照从后往前的顺序渲染这些半透明物体，并开启它们的深度测试，但关闭深度写入。

但是，深度缓冲中的值其实是像素级别的，即每个像素有个深度值，但是现在我们对单个物体级别进行排序，这意味着排序结果是，要么物体A全部在B前面渲染，要么A全部在B后面渲染。但如果存在循环重叠的情况，那么使用这种方法就永远无法得到正确的结果。

![图8.3 循环重叠的半透明物体总是无法得到正确的半透明效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/8.3.jpg)

这种问题的解决方法通常是分割网格。为了减少错误排序的情况，我们可以尽可能让模型是凸面体,并且考虑将复杂的模型拆分成可以独立排序的多个子模型等。其实就算排序错误结果有时也不会非常糟糕，如果我们不想分割网格，可以试着让透明通道更加柔和，使穿插看起来并不是那么明显。我们也可以使用开启了深度写入的半透明效果来近似模拟物体的半透明（详见 8.5 节）。


## 8.2 Unity Shader 的渲染顺序

Unity为了解决渲染顺序的问题提供了**渲染队列（render queue）**，可以使用SubShader的Queue标签来决定我们的模型将归于哪个渲染队列。

Unity在内部使用一系列整数索引来表示每个渲染队列，且索引号越小表示越早被渲染。在Unity 5中，Unity提前定义了5个渲染队列（与Unity 5之前的版本相比多了一个AlphaTest渲染队列），在每个队列中间我们可以使用其他队列。

表8.1  Unity 提前定义的渲染队列
 名称  | 队列索引号 | 描述
 ---- | ---- | ----
 Background | 1000 | 这个渲染队列会在任何其他队列之前被渲染，我们通常使用该队列来渲染那些需要绘制在背景上的物体
 Geometry | 2000 | 默认的渲染队列，大多数物体都使用这个队列。不透明物体使用这个队列
 AlphaTest | 2450 | 需要透明度测试的物体使用这个队列。在Unity5中它从Geometry 队列中被单独分出来，这是因为在所有不透明物体渲染之后再渲染它们会更加高效
 Transparent | 3000 | 这个队列中的物体会在所有Geometry和AlphaTest 物体渲染后，再按从后往前的顺序进行渲染。任何使用了透明度混合(例如关闭了深度写入的Shader)的物体都应该使用该队列
 Overlay | 4000 | 该队列用于实现一些叠加效果。任何需要在最后渲染的物体都应该使用该队列

通过透明度测试实现透明效果，代码中应该包含类似下面的代码：

``` hlsl
SubShader
{
    Tags {"Queue"="AlphaTest"}
    Pass
    {
        // ...
    }
}
```

通过透明度混合来实现透明效果，代码中应该包含类似下面的代码：

``` hlsl
SubShader
{
    Tags {"Queue"="Transparent"}
    Pass
    {
        // 关闭深度写入，如果写在SubShader中意味着该SubShader下的所有Pass都会关闭深度写入
        ZWrite Off 
        // ...
    }
}
```


## 8.3 透明度测试

透明度测试（Alpha Test）：只要一个片元的透明的不满足条件（通常是小于某个阈值），那么它对应的片元就会被舍弃。被舍弃的片元将不会再进行任何处理，也不会对颜色缓冲产生任何影响；未被舍弃的就会按照普通的不透明物体的处理方式来处理它。

在 Unity 中，我们会在片元着色器中使用 clip 函数来进行透明度测试。clip 是 CG 中的一个函数，它的定义如下：
> 函数：`void clip(float x); void clip(float2 x); void clip(float3 x); void clip(float4 x);`
  参数：裁剪时使用的标量或矢量条件
  描述：如果给定参数的任何一个分量是负数，就会舍弃掉当前像素的输出颜色。它等同于下面代码：
```
void clip(float4 x)
{
    if(any(x < 0)) 
        discard;
}
```


新建 Shader 命名为 Chapter8-AlphaTest ：

``` hlsl
Shader "Unity Shaders Book/Chapter 8/Alpha Test"
{
    Properties
    {
        _Color ("Color", Color) = (1,1,1,1)
        _MainTex ("Main Texture", 2D) = "white" {}
        // 控制透明度测试的阈值
        _Cutoff ("Alpha Cutoff", Range(0,1)) = 0.5
    }
    SubShader
    {
        // Queue: 渲染队列，透明的测试使用的渲染队列名为 AlphaTest
        // IgnoreProjector: 是否忽略投影，这里设置为 True
        // RenderType: 渲染类型，让Unity把这个Shader归入到提前定义的组中
        Tags { "Queue" = "AlphaTest" "IgnoreProjector" = "True" "RenderType" = "TransparentCutout" }

        Pass
        {
            // LightMode: 用于定义该Pass在Unity的光照流水线中的角色，
            // 只有定义了正确的LightMode，才能正确得到一些Unity的内置光照变量，如 _LightColor0
            Tags { "LightMode" = "ForwardBase" }

            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            
            #include "Lighting.cginc"

            fixed4 _Color;
            sampler2D _MainTex;
            float4 _MainTex_ST;
            fixed _Cutoff;

            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
                float4 texcoord : TEXCOORD0;
            };

            struct v2f
            {
                float4 pos : SV_POSITION;
                float3 worldNormal : TEXCOORD0;
                float3 worldPos : TEXCOORD1;
                float2 uv : TEXCOORD2;
            };

            v2f vert (a2v v)
            {
                v2f o;
                o.pos = UnityObjectToClipPos(v.vertex);
                
                o.worldNormal = UnityObjectToWorldNormal(v.normal);
                o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
                o.uv = TRANSFORM_TEX(v.texcoord, _MainTex);
                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                fixed3 worldNormal = normalize(i.worldNormal);
                fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));

                fixed4 texColor = tex2D(_MainTex, i.uv);

                // Alpha Test
                clip(texColor.a - _Cutoff);
                // // clip 等同于
                // if (texColor.a < _Cutoff)
                //     discard;

                fixed3 albedo = texColor.rgb * _Color.rgb;
                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo;
                fixed3 diffuse = _LightColor0.rgb * albedo * max(0, dot(worldNormal, worldLightDir));

                fixed3 color = ambient + diffuse;

                return fixed4(color, 1.0);
            }
            ENDCG
        }
    }
    Fallback "Transparent/Cutout/VertexLit"
}
```

效果：

![图8.7 随着Alpha cutoff参数的增大，更多的像素由于不满足透明度测试条件而被剔除](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/8.7.jpg)


## 8.4 透明度混合

透明度混合（Alpha Blending）：这种方法可以得到真正的半透明效果。它会使用当前片元的透明度作为混合因子，与已经存储在颜色缓冲中的颜色值进行混合，得到新的颜色。但是，由于透明度混合需要关闭深度写入，这使得我们要非常小心物体的渲染顺序。

为了进行混合，我们需要使用 Unity 提供的混合命令——Blend。Blend 是 Unity 提供的设置混合模式的命令。想要实现半透明的效果就需要把当前自身的颜色和已经存在于颜色缓冲中的颜色值进行混合，混合时使用的函数就是由该指令决定的。

表8.2 ShaderLab 的 Blend 命令
 语义 | 描述
 ---- | ----
 Blend Off | 关闭混合
 Blend SrcFactor DstFactor | 开启混合，并设置混合因子。源颜色（该片元产生的颜色）会乘以 SrcFactor，而目标颜色（已经存在于颜色缓存的颜色）会乘以 DstFactor，然后把两者相加后再存入颜色缓冲中
 Blend SrcFactor DstFactor SrcFactorA DstFactorA | 和上面几乎一样，只是使用不同的因子来混合透明通道
 BlendOp BlendOperation | 并非是把源颜色和目标颜色简单相加后混合，而是使用 BlendOperation 对它们进行其他操作

在本节里，我们使用 Blend SrcFactor DstFactor 来进行混合。这个命令在设置混合因子的同时也开启了混合模式。

我们把源颜色的混合因子 SrcFactor 设为 SrcAlpha，目标颜色的混合因子 DstFactor 设为 OneMinusSrcAlpha。那么，经过混合后新的颜色是：

$$
DstColor_{new} = SrcAlpha \times SrcColor + (1 - SrcAlpha) \times DstColor_{old}
$$

通常，透明度混合使用的就是这样的混合命令。

新建 Shader 命名为 Chapter8-AlphaBlend ：

``` hlsl
Shader "Unity Shaders Book/Chapter 8/Alpha Blend"
{
    Properties
    {
        _Color ("Color", Color) = (1,1,1,1)
        _MainTex ("Main Texture", 2D) = "white" {}
        _AlphaScale ("Alpha Scale", Range(0,1)) = 1
    }
    SubShader
    {
        // 修改 SubShader 使用的标签
        Tags { "Queue" = "Transparent" "IgnoreProjector" = "True" "RenderType" = "Transparent" }

        Pass
        {
            Tags { "LightMode" = "ForwardBase" }

            // 我们还需要在Pass中为透明度混合进行合适的混合状态设置
            ZWrite Off
            Blend SrcAlpha OneMinusSrcAlpha

            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            
            #include "Lighting.cginc"

            fixed4 _Color;
            sampler2D _MainTex;
            float4 _MainTex_ST;
            fixed _AlphaScale;

            struct a2v
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
                float4 texcoord : TEXCOORD0;
            };

            struct v2f
            {
                float4 pos : SV_POSITION;
                float3 worldNormal : TEXCOORD0;
                float3 worldPos : TEXCOORD1;
                float2 uv : TEXCOORD2;
            };

            v2f vert (a2v v)
            {
                v2f o;
                o.pos = UnityObjectToClipPos(v.vertex);
                
                o.worldNormal = UnityObjectToWorldNormal(v.normal);
                o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
                o.uv = TRANSFORM_TEX(v.texcoord, _MainTex);
                return o;
            }

            // 修改片元着色器
            fixed4 frag (v2f i) : SV_Target
            {
                fixed3 worldNormal = normalize(i.worldNormal);
                fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));

                fixed4 texColor = tex2D(_MainTex, i.uv);

                fixed3 albedo = texColor.rgb * _Color.rgb;
                fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo;
                fixed3 diffuse = _LightColor0.rgb * albedo * max(0, dot(worldNormal, worldLightDir));

                return fixed4(ambient + diffuse, texColor.a * _Color.a * _AlphaScale);
            }
            ENDCG
        }
    }
    FallBack "Transparent/VertexLit"
}
```

效果：

![图8.9 随着Alpha Scale参数的增大，模型变得越来越透明](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/8.9.jpg)


当模型本身有复杂的遮挡关系或是包含了复杂的非凸网格的时候，就会有各种各样因为排序错误而产生的错误的透明效果。

![图8.10 当模型网格之间有互相交叉的结构时，往往会得到错误的半透明效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/8.10.jpg)

这时，我们可以想办法重新利用深度写入，让模型可以像半透明物体一样进行淡入淡出，这就是我们下面要讲的内容。



## 8.5 开启深度写入的半透明效果

使用两个 Pass 来渲染模型：
* 第一个 Pass 开启深度写入，但不输出颜色，他的目的仅仅是为了把该模型的深度值写入深度缓冲中；
* 第二个 Pass 进行正常的透明度混合，由于上一个 Pass 已经得到了逐像素的正确的深度信息，该 Pass 就可以按照像素级别的深度排序结果进行透明渲染。

但这种方法的缺点在于，多使用一个 Pass 会对性能造成一定的影响。

新建 Shader 命名为 Chapter8-AlphaBlendZWrite ， 将上一节的代码复制过来，稍做修改：

``` hlsl
Shader "Unity Shaders Book/Chapter 8/Alpha Blend ZWrite"
{
    Properties
    {
        _Color ("Color", Color) = (1,1,1,1)
        _MainTex ("Main Texture", 2D) = "white" {}
        _AlphaScale ("Alpha Scale", Range(0,1)) = 1
    }
    SubShader
    {
        Tags { "Queue" = "Transparent" "IgnoreProjector" = "True" "RenderType" = "Transparent" }

        Pass{
            ZWrite On
            ColorMask 0
        }

        Pass
        {
            // 和 8.4 节同样的代码
        }
    }
    FallBack "Transparent/VertexLit"
}
```

ColorMask: 用于设置颜色通道的写掩码（write mask）。0 表示不写入任何颜色通道，即不会输出任何颜色。它的语义如下：
> `ColorMask RGB | A | 0 | 其他任何R、G、B、A的组合`

效果：

![图8.11 开启了深度写入的半透明效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/8.11.jpg)

可以看出，使用这种方法，我们仍然可以实现模型与它后面的背景混合的效果，但模型内部之间不会有任何真正的半透明效果。


## 8.6 ShaderLab 的混合命令

当片元着色器产生一个颜色的时候，可以选择与颜色缓存中的颜色进行混合。这样一来，混合就和两个操作有关：
* **源颜色（source color）**：用 S 表示，由片元着色器产生的颜色值；
* **目标颜色（destination color）**：用 D 表示，从颜色缓冲中读取到的颜色值。

对他们进行混合后得到的输出颜色，可以用 O 表示，它会重新写入到颜色缓冲中。

想要使用混合，我们必须首先开启它。在 Unity 中，当我们使用 Blend（Blend Off 命令除外）命令时，除了设置混合状态外也开启了混合。但是，在其他图形 API 中我们是需要手动开启的。例如在 OpenGL 中，我们需要使用 glEnabIe(GL_BLEND) 来开启混合。但在 Unity 中，它已经在背后为我们做了这些工作。


### 8.6.1 混合等式和参数

在 2.3.8 节中我们提到过，混合是一个逐片元的操作，而且它不是可编程的，但却是高度可配置的。也就是说，我们可以设置混合时使用的运算操作、混合因子等来影响混合。

现在，我们已知两个操作数：源颜色 S 和目标颜色 D，想要得到输出颜色 O 就必须使用一个等式来计算。我们把这个等式称为**混合等式（blendequation）**。

当进行混合时，我们需要使用两个混合等式：一个用于混合RGB通道，一个用于混合A通道。当设置混合状态时，我们实际上设置的就是混合等式中的操作和因子。在默认情况下，混合等式使用的操作都是加操作（我们也可以使用其他操作），我们只需要再设置一下混合因子即可。由于需要两个等式（分别用于混合RGB 通道和 A通道），每个等式有两个因子（一个用于和源颜色相乘,一个用于和目标颜色相乘），因此一共需要4个因子。

表8.3 ShaderLab 中设置混合因子的命令
 命令 | 描述
 ---- | ----
 Blend SrcFactor DstFactor | 开启混合，并设置混合因子。源颜色（该片元产生的颜色）会乘以 SrcFactor，而目标颜色（已经存在于颜色缓存的颜色）会乘以 DstFactor，然后把两者相加后再存入颜色缓冲中
 Blend SrcFactor DstFactor SrcFactorA DstFactorA | 和上面几乎一样，只是使用不同的因子来混合透明通道

可以发现，第一个命令只提供了两个因子，这意味着将使用同样的混合因子来混合 RGB 通道和 A通道，即此时 SrcFactorA 将等于 SrcFactor，DstFactorA 将等于 DstFactor。下面就是使用这些因子进行加法混合时使用的混合公式：

$$
O_{rgb} = SrcFactor \times S_{rgb} + DstFactor \times D_{rgb} \\
O_{a} = SrcFactorA \times S_{a} + DstFactorA \times D_{a}
$$

表8.4 ShaderLab 中的混合因子
 参数 | 描述
 ---- | ----
 One    | 因子为1
 Zero   | 因子为0
 SrcColor | 因子为源颜色值。当用于混合 RGB 的混合等式时，使用 SrcColor 的 RGB 分量作为混合因子；当用于混合 A 的混合等式时，使用 SrcColor 的 A 分量作为混合因子
 SrcAlpha | 因子为源颜色的透明度值（A通道）
 DstColor | 因子为源颜色值。当用于混合 RGB 通道的混合等式时，使用 DstColor 的 RGB 分量作为混合因子；当用于混合 A 通道的混合等式时，使用 DstColor 的 A 分量作为混合因子。
 DstAlpha | 因子为源颜色的透明度值（A通道）
 OneMinusSrcColor | 因子为(1-源颜色)。当用于混合 RGB 的混合等式时，使用结果的 RGB 分量作为混合因子；当用于混合 A 的混合等式时，使用结果的 A 分量作为混合因子
 OneMinusSrcAlpha | 因子为(1-源颜色的透明度值)
 OneMinusDstColor | 因子为(1-目标颜色)。当用于混合 RGB 的混合等式时，使用结果的 RGB 分量作为混合因子；当用于混合A的混合等式时，使用结果的A分量作为混合因子
 OneMinusDstAlpha | 因子为(1-目标颜色的透明度值)


使用上面的指令进行设置时，RGB 通道的混合因子和 A 通道的混合因子都是一样的，有时我们希望可以使用不同的参数混合 A 通道，这时就可以利用 `Blend SrcFactor DstFactor, SrcFactorA DstFactorA` 指令。例如，如果我们想要在混合后，输出颜色的透明度值就是源颜色的透明度，可以使用下面的命令：

```
Blend SrcAlpha OneMinusSrcAlpha, One Zero
```


### 8.6.2 混合操作

在上面涉及的混合等式中，当把源颜色和目标颜色与它们对应的混合因子相乘后，我们都是把它们的结果加起来作为输出颜色的。也可以使用减法，我们可以使用 ShaderLab 的 `BlendOp BlendOperation` 命令，即混合操作命令。

表8.5 ShaderLab 中的混合操作
 操作 | 描述
 ---- | ----
 Add    | 将混合后的源颜色和目标颜色相加。默认的混合操作。使用的混合等式是：<br/> $O_{rgb} = SrcFactor \times S_{rgb} + DstFactor \times D_{rgb}$ <br/> $O_{a} = SrcFactorA \times S_{a} + DstFactorA \times D_{a}$
 Sub    | 将混合后的源颜色减去混合后的目标颜色。使用的混合等式是：<br/> $O_{rgb} = SrcFactor \times S_{rgb} - DstFactor \times D_{rgb}$ <br/> $O_{a} = SrcFactorA \times S_{a} - DstFactorA \times D_{a}$
 RevSub | 将混合后的目标颜色减去混合后的源颜色。使用的混合等式是：<br/> $O_{rgb} = DstFactor \times D_{rgb} - SrcFactor \times S_{rgb}$ <br/> $O_{a} = DstFactorA \times D_{a} - SrcFactorA \times S_{a}$
 Min    | 使用源颜色和目标颜色中较小的值，是逐分量比较的。使用的混合等式是：<br/> $O_{rgba} = (min(S_r, D_r), min(S_g, D_g), min(S_b, D_b), min(S_a, D_a))$
 Max    | 使用源颜色和目标颜色中较大的值，是逐分量比较的。使用的混合等式是：<br/> $O_{rgba} = (max(S_r, D_r), max(S_g, D_g), max(S_b, D_b), max(S_a, D_a))$
 其他逻辑操作 | 仅在 DirectX 11.1 中支持

混合操作命令通常是与混合因子命令一起工作的。但需要注意的是，当使用 Min 或 Max 混合操作时，混合因子实际上是不起任何作用的，它们仅会判断原始的源颜色和目标颜色之间的比较结果。



### 8.6.3 常见的混合类型

通过混合操作和混合因子命令的组合，我们可以得到一些类似 Photoshop 混合模式中的混合效果：

```
// 正常（Normal），即透明度混合
Blend SrcAlpha OneMinusSrcAlpha

// 柔和相加（Soft Additive）
Blend OneMinusDstColor One

// 正片叠底（Multiply），即相乘
Blend DstColor SrcColor

// 两倍相乘（2x Multiply）
Blend DstColor SrcColor

// 变暗（Darken）
BlendOp Min
Blend One One

// 变亮（Lighten）
BlendOp Max
Blend One One

// 滤色（Screen）
Blend OneMinusDstColor One
// 等同于
Blend One OneMinusSrcColor

// 线性减淡（Linear Dodge）
Blend One One
```

![图8.12 不同混合状态设置得到的效果](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/8.12.jpg)

新建 Shader 命名为 Chapter8-BlendOperations ：

``` hlsl
Shader "Unity Shaders Book/Chapter 8/Blend Operations" {
	Properties {
		_Color ("Color Tint", Color) = (1, 1, 1, 1)
		_MainTex ("Main Tex", 2D) = "white" {}
		_AlphaScale ("Alpha Scale", Range(0, 1)) = 1

        [Enum(UnityEngine.Rendering.BlendMode)]
        _SrcFactor ("SrcFactor", int) = 0
        [Enum(UnityEngine.Rendering.BlendMode)]
        _DstFactor ("DstFactor", int) = 0
        [Enum(UnityEngine.Rendering.BlendOp)]
        _BlendOp ("BlendOp", int) = 0
	}
	SubShader {
		Tags {"Queue"="Transparent" "IgnoreProjector"="True" "RenderType"="Transparent"}
		
		Pass {
			Tags { "LightMode"="ForwardBase" }
			
			ZWrite Off
			
            BlendOp [_BlendOp]
			Blend [_SrcFactor] [_DstFactor]
			
			CGPROGRAM
			
			#pragma vertex vert
			#pragma fragment frag
			
			#include "Lighting.cginc"
			
			fixed4 _Color;
			sampler2D _MainTex;
			float4 _MainTex_ST;
			fixed _AlphaScale;
			
			struct a2v {
				float4 vertex : POSITION;
				float3 normal : NORMAL;
				float4 texcoord : TEXCOORD0;
			};
			
			struct v2f {
				float4 pos : SV_POSITION;
				float2 uv : TEXCOORD0;
			};
			
			v2f vert(a2v v) {
			 	v2f o;
			 	o.pos = UnityObjectToClipPos(v.vertex);

			 	o.uv = TRANSFORM_TEX(v.texcoord, _MainTex);
			 	
			 	return o;
			}
			
			fixed4 frag(v2f i) : SV_Target {				
				fixed4 texColor = tex2D(_MainTex, i.uv);
			 	
				return fixed4(texColor.rgb * _Color.rgb, texColor.a * _Color.a * _AlphaScale);
			}
			
			ENDCG
		}
	} 
	FallBack "Transparent/VertexLit"
}
```



## 8.7 双面渲染的透明效果

默认情况下渲染引擎剔除了物体背面（相对于摄像机的方向）的渲染图元，而只渲染了物体的正面。如果我们想要得到双面渲染的效果，可以使用 Cull 指令来控制需要剔除哪个面的渲染图元。在 Unity 中，Cull 指令的语法如下：
```
Cull Back | Front | Off
```

* Back：剔除背面渲染图元
* Front：剔除正面渲染图元
* Off：不剔除任何渲染图元


### 8.7.1 透明度测试的双面渲染

新建 Shader 命名为 Chapter8-AlphaTestBothSided，与8.3节中的 Chapter8-AlphaTest 几乎完全一样，只是在 Pass 中增加了 Cull 指令：

```
    // ......
        Pass
        {
            Tags { "LightMode" = "ForwardBase" }

            Cull Off 

            // ......
        }
    // ......
```

效果：

![图8.13 双面渲染的透明度测试的物体](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/8.13.jpg)


### 8.7.2 透明混合的双面渲染

和透明度测试相比，想要让透明度混合实现双面渲染会更复杂一些，这是因为透明度混合需要关闭深度写入，我们需要小心地控制渲染顺序来得到正确的深度关系。

为此，我们选择把双面渲染的工作分成两个 Pass——第一个 Pass 只渲染背面，第二个 Pass 只渲染正面，由于 Unity 会顺序执行 SubShader 中的各个 Pass，因此我们可以保证背面总是在正面被渲染之前渲染，从而可以保证正确的深度渲染关系。

新建 Shader 命名为 Chapter8-AlphaBlendBothSided，对 8.4 节中的 Chapter8-AlphaBlend ，做些改动：

``` hlsl
Shader "Unity Shaders Book/Chapter 8/Alpha Blend Both Sided"
{
    Properties
    {
        _Color ("Color", Color) = (1,1,1,1)
        _MainTex ("Main Texture", 2D) = "white" {}
        _AlphaScale ("Alpha Scale", Range(0,1)) = 1
    }
    
    // 多个 Pass 使用相同的代码
    CGINCLUDE

    #include "Lighting.cginc"

    fixed4 _Color;
    sampler2D _MainTex;
    float4 _MainTex_ST;
    fixed _AlphaScale;

    struct a2v
    {
        float4 vertex : POSITION;
        float3 normal : NORMAL;
        float4 texcoord : TEXCOORD0;
    };

    struct v2f
    {
        float4 pos : SV_POSITION;
        float3 worldNormal : TEXCOORD0;
        float3 worldPos : TEXCOORD1;
        float2 uv : TEXCOORD2;
    };

    v2f vert (a2v v)
    {
        v2f o;
        o.pos = UnityObjectToClipPos(v.vertex);
        
        o.worldNormal = UnityObjectToWorldNormal(v.normal);
        o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz;
        o.uv = TRANSFORM_TEX(v.texcoord, _MainTex);
        return o;
    }

    // 修改片元着色器
    fixed4 frag (v2f i) : SV_Target
    {
        fixed3 worldNormal = normalize(i.worldNormal);
        fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));

        fixed4 texColor = tex2D(_MainTex, i.uv);

        fixed3 albedo = texColor.rgb * _Color.rgb;
        fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo;
        fixed3 diffuse = _LightColor0.rgb * albedo * max(0, dot(worldNormal, worldLightDir));

        return fixed4(ambient + diffuse, texColor.a * _Color.a * _AlphaScale);
    }
    ENDCG

    SubShader
    {
        // 修改 SubShader 使用的标签
        Tags { "Queue" = "Transparent" "IgnoreProjector" = "True" "RenderType" = "Transparent" }

        Pass
        {
            Tags { "LightMode" = "ForwardBase" }

            Cull Front 

            ZWrite Off
            Blend SrcAlpha OneMinusSrcAlpha

            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            
            ENDCG
        }
        
        Pass
        {
            Tags { "LightMode" = "ForwardBase" }

            Cull Back 

            ZWrite Off
            Blend SrcAlpha OneMinusSrcAlpha

            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            
            ENDCG
        }
    }
    FallBack "Transparent/VertexLit"
}
```

效果：

![图8.14 双面渲染的透明混合的物体](https://raw.githubusercontent.com/Ineloquent0/notes/main/TA%20%E7%AC%94%E8%AE%B0/Unity%20Shader%20%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81/images/8.14.jpg)


